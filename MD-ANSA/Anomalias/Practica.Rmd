---
title: "Practica"
author: "Ignacio Vellido"
date: "12/9/2020"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    toc: true
    highlight: github
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)

library(ggplot2)   # Gr?ficos
library(fitdistrplus)  # Ajuste de una distribución -> denscomp 
library(reshape)   # melt
library(ggbiplot)  # biplot
library(tidyverse)   
library(outliers)  # Grubbs
library(MVN)       # mvn: Test de normalidad multivariante  
library(CerioliOutlierDetection)  #MCD Hardin Rocke
library(mvoutlier) # corr.plot 
library(DMwR)      # lof
library(cluster)   # PAM
```

```{r include=FALSE}
# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada

###########################################################################
# Funciones utilizadas a lo largo del curso
###########################################################################

# rm(list=ls()) 


###########################################################################
# Realiza un plot de todos los registros
# Permite cambiar el color con el que se visualiza un conjunto de registros. 
# Los registros que se muestran con otro color se especifican en el par?metro
# claves.a.mostrar 

plot_2_colores = function (datos, 
                           claves.a.mostrar, 
                           titulo = "",
                           colores = c("black", "red")){
  
  num.datos = nrow(as.matrix(datos))
  seleccionados =  rep(FALSE, num.datos)
  seleccionados[claves.a.mostrar] = TRUE
  colores.a.mostrar = rep(colores[1], num.datos)
  colores.a.mostrar [seleccionados] = colores[2]
  
  plot(datos, col=colores.a.mostrar, main = titulo)
}



###########################################################################
# Funci?n an?loga a son_outliers_IQR, salvo que devuelve un vector
# de claves en vez de un vector de bools

claves_outliers_IQR = function(datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  son.outliers.IQR = son_outliers_IQR(datos, ind.columna, coef)
  return (which(son.outliers.IQR  == TRUE))
}



###########################################################################
# Calcula los outliers IQR con respecto a una columna 
# Devuelve un vector de bools indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a la columna ind.columna
# coef es 1.5 para los outliers normales y hay que pasarle 3 para los outliers extremos

son_outliers_IQR = function (datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  cuartil.primero = quantile(columna.datos)[2]  
  #quantile[1] es el m?nimo y quantile[5] el m?ximo.
  cuartil.tercero = quantile(columna.datos)[4] 
  iqr = cuartil.tercero - cuartil.primero
  extremo.superior.outlier = (iqr * coef) + cuartil.tercero
  extremo.inferior.outlier = cuartil.primero - (iqr * coef)
  son.outliers.IQR  = columna.datos > extremo.superior.outlier |
    columna.datos < extremo.inferior.outlier
  return (son.outliers.IQR)
}


###########################################################################
# Calcula los outliers IQR con respecto a ALGUNA columna
# Devuelve un vector de claves indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a ALGUNA columna
# coef es 1.5 para los outliers normales y  3 para los outliers extremos

claves_outliers_IQR_en_alguna_columna = function(datos, coef = 1.5){
  df.clave.columnas = data.frame()
  claves.outliers =  sapply(1:ncol(datos), 
                               function(x) claves_outliers_IQR(datos, x, coef)
  )
  claves.outliers.en.alguna.columna = unlist(claves.outliers)
  return (claves.outliers.en.alguna.columna)
}




#######################################################################
# Devuelve los nombres de aquellas filas especificadas en el par?metro claves
# filas es un vector de bools 

nombres_filas = function (datos, claves) {
  num.claves = length(claves)
  nombres.filas = row.names(as.data.frame(datos))[claves]
  
  return (nombres.filas)
}




#######################################################################
# funci?n base para diag_caja_outliers_IQR y diag_caja

diag_caja_grafico_base = function(datos, indice.columna){
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  nombre.columna = colnames(datos)[indice.columna]
  ggboxplot = ggplot(data = as.data.frame(datos), 
                     aes(x=factor(""), 
                         y = datos[,indice.columna]) , 
                     environment = environment()) + 
              xlab(nombre.columna) + ylab("") 
  return (ggboxplot)
}

#######################################################################
# Muestra un diagrama de caja
# Calcula los outliers IQR y los muestra como puntos en rojo en un BoxPlot

diag_caja_outliers_IQR = function (datos, ind.columna, coef.IQR = 1.5){
  # Si quisi?semos l?neas horizontales en los l?mites de las cajas
  # habr?a que a?adir 
  # + stat_boxplot(geom = 'errorbar')   
  
   outliers.IQR = son_outliers_IQR(datos, ind.columna, coef = coef.IQR)
   ggboxplot =  diag_caja_grafico_base(datos, ind.columna) + 
                stat_boxplot(coef = coef.IQR) +
                geom_boxplot(coef = coef.IQR, outlier.colour = "red") 
                # Importante: geom_boxplot debe ir despu?s de stat_boxplot
   
   return (ggboxplot)
}



#######################################################################
# Muestra un diagrama de caja
# Tambi?n muestra las etiquetas de los registros indicados en 
# el par?metro claves.a.mostrar 

diag_caja = function (datos, ind.columna, claves.a.mostrar = c()){
  num.filas = nrow(datos)
  num.claves = length(claves.a.mostrar)
  nombres.filas = vector (mode = "character", length = num.filas)
  nombres.filas = rep("", num.filas)
  nombres.claves = nombres_filas(datos, claves.a.mostrar)

  for (i in num.claves)
    nombres.filas[claves.a.mostrar[i]]  = nombres.claves[i]
  

  ggboxplot = diag_caja_grafico_base(datos, ind.columna) + 
    geom_boxplot(outlier.shape = NA) + # Para que no imprima los outliers IQR calculados dentro del mismo geom_boxplot
    geom_text(aes(label = nombres.filas)) 
  
  return (ggboxplot)
}






#######################################################################
# Muestra de forma conjunta todos los diagramas de caja de las variables de datos
# Para ello, normaliza previamente los datos.
# Tambi?n muestra las etiquetas de los registros indicados en claves.a.mostrar
# Requiere reshape

diag_caja_juntos = function (datos, titulo = "", claves.a.mostrar = c()){  
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  
  # Para hacerlo con ggplot, lamentablemente hay que construir antes una tabla 
  # que contenga en cada fila el valor que a cada tupla le da cada variable 
  # -> paquete reshape->melt
  
  # Por ejemplo, si tenemos el siguiente data frame
  
  # datos = data.frame(
  #   A = c(1, 2),
  #   B = c(3, 4)
  # )
  # datos =
  #     A  B
  #     1  3
  #     2  4
  
  # melt(datos) construye esta tabla:
  
  #      variable value
  # 1        A     1
  # 2        A     2
  # 3        B     3
  # 4        B     4
  
  
  nombres.de.filas = nombres_filas (datos, claves.a.mostrar)
  
  datos = scale(datos)
  datos.melted = melt(datos)
  colnames(datos.melted)[2]="Variables"
  colnames(datos.melted)[3]="zscore"
  factor.melted = colnames(datos.melted)[1]
  columna.factor = as.factor(datos.melted[,factor.melted])
  levels(columna.factor)[!levels(columna.factor) %in% nombres.de.filas] = ""  
  
  ggplot(data = datos.melted, 
         aes(x=Variables, y=zscore), 
         environment = environment()) + 
    ggtitle(titulo) + 
    geom_boxplot(outlier.shape = NA) + 
    geom_text(aes(label = columna.factor), size = 3) 
}






#######################################################################
# Muestra un biplot del conjunto de datos
# Se muestran los nombres de los registros indicados en claves.a.mostrar
# El color usado para dichos registros es el segundo del par?metro colores
# El t?tulo para el grupo de dichos registros es el especificado en titulo.grupo.a.mostrar
# El par?metro titulo especifica el t?tulo principal del gr?fico

biplot_2_colores = function (datos, 
                             claves.a.mostrar = c(), 
                             titulo = "",
                             titulo.grupo.a.mostrar = "Outliers",
                             colores = c("black","red")){
  nombres = rownames(datos)
  claves.datos = c(1:nrow(datos))
  son.a.mostrar = claves.datos %in% claves.a.mostrar
  nombres[!son.a.mostrar] = ''

  PCA.model = princomp(scale(datos))
  outlier.shapes = c(".","x") 
  biplot = ggbiplot(PCA.model,
                    obs.scale = 1,
                    var.scale = 1 ,
                    varname.size = 5,
                    groups =  son.a.mostrar,
                    alpha = 1/2) #alpha = 1/10
  biplot = biplot + labs(color = titulo.grupo.a.mostrar)
  biplot = biplot + scale_color_manual(values = colores)
  biplot = biplot + geom_text(label = nombres,
                              stat = "identity",
                              size = 3,
                              hjust=0,
                              vjust=0)
  biplot = biplot + ggtitle(titulo)
}



#######################################################################
# Muestra un biplot de un conjunto de datos diferenciados por color
# El color lo determina la asignaci?n de cada dato a un cluster 
# Las asignaciones de datos a cluster se indican en asignaciones.clustering
# Tambi?n se muestran los outliers cuyas claves vienen indicadas en claves.outliers
 
biplot_outliers_clustering = function(datos, 
                                      titulo = "Outliers por el m?todo de Clustering", 
                                      titulo.color = "Asignaciones Clustering",
                                      titulo.outlier = "Outliers",
                                      asignaciones.clustering,
                                      claves.outliers){
  son.outliers = rep(FALSE, nrow(datos))
  son.outliers[claves.outliers] = TRUE
  
  bip = biplot_colores_formas(datos, 
                              titulo, titulo.color, titulo.outlier,
                              asignaciones.clustering,
                              son.outliers,
                              claves.outliers)
  bip 
}

#######################################################################
# Muestra un biplot del conjunto de datos
# Los datos se muestran diferenciados por color y por forma
# Las asignaciones de cada dato a su color y forma vienen dadas por los vectores
# asignaciones.colores y asignaciones.formas 
# Tambi?n se muestran las etiquetas de los registros indicados
# en el par?metro opcional claves.a.mostrar 

biplot_colores_formas = function (datos, 
                                  titulo, titulo.color = '', titulo.forma = '', 
                                  asignaciones.colores, asignaciones.formas,
                                  claves.a.mostrar = c()){
  PCA.model = princomp(scale(datos))
  
  son.a.mostrar = rep(FALSE, nrow(datos))
  son.a.mostrar[claves.a.mostrar] = TRUE
  nombres.a.mostrar = rownames(datos)
  nombres.a.mostrar[!son.a.mostrar] = ''

  asignaciones.colores = factor(asignaciones.colores)
  asignaciones.formas  = factor(asignaciones.formas)

  
  bip = ggbiplot(PCA.model, obs.scale = 1, var.scale=1 , varname.size = 3, alpha = 0) +              
    geom_point(aes(shape = asignaciones.formas, colour = asignaciones.colores))  +
    labs(shape = titulo.forma) +
    labs(colour = titulo.color) +
    ggtitle(titulo) +
    geom_text(label = nombres.a.mostrar, stat = "identity", size = 3, hjust=0, vjust=0)      
  
  bip
}

#######################################################################
# Calcula las distancias de cada dato al centroide de su cluster
# Las asignaciones de cada dato a su cluster se indican en asignaciones.clustering
# Cada centroide es una fila del data frame datos.centroides.normalizados

distancias_a_centroides = function (datos.normalizados, 
                                    asignaciones.clustering, 
                                    datos.centroides.normalizados){
  
  sqrt(rowSums(   (datos.normalizados 
                   - 
                   datos.centroides.normalizados[asignaciones.clustering,])^2  ))
}


#######################################################################
# Revierte la funci?n de normalizaci?n (z-score)

desnormaliza = function(datos, filas.normalizadas){
  medias        = colMeans(datos)
  desviaciones  = apply(datos, 2, sd , na.rm = TRUE)
  
  filas.desnormalizadas  = sweep(filas.normalizadas, 2, desviaciones, "*")
  filas.desnormalizadas  = sweep(filas.desnormalizadas, 2, medias, "+")
  
  filas.desnormalizadas 
}




top_clustering_outliers = function(datos.norm, 
                                   asignaciones.clustering, 
                                   datos.centroides.norm, 
                                   num.outliers){
  
  dist_centroides = distancias_a_centroides (datos.norm, 
                                             asignaciones.clustering, 
                                             datos.centroides.norm)
  
  claves = order(dist_centroides, decreasing=T)[1:num.outliers]
  
  list(distancias = dist_centroides[claves]  , claves = claves)
}
```

# Dataset y Selección de Variables

En este guion usaremos el conjunto de datos __mtcars__ disponible directamente en R. Contiene los datos de un serie de vehículos. Puede encontrar en Internet una descripción completa de dicho dataset. Nosotros describimos aquí las columnas que serán el objetivo de nuestro estudio.

- Variables relativas a las características físicas

  - disp (displacement) Nos indica la cilindrada en pulgadas cúbicas. En España, lo normal es referirnos a la cilindrada en centímetros cúbicos.

  - hp (horse power) Es la potencia del motor

  - drat (Rear axle ratio) Es la relación del eje trasero. Un valor bajo nos permite unos desarrollos mayores con bajo consumo: es lo habitual en turismos. Un valor alto hace que el coche consuma más, pero permite enviar más fuerza, como por ejemplo en un todo terreno.

  - wt (weight) Peso del vehículo

- Variables relativas al rendimiento

  - mpg (miles per gallon) Nos indica el consumo del coche. Cuanto mayor sea, más combustible consume.

  - qsec (1/4 mile time) Mide el tiempo necesario para recorrer un cuarto de milla. Es una medida inversa a la aceleración: cuanto más acelere un coche, menor será el valor de qsec .

Para trabajar con dicho conjunto, vamos a construir los siguientes objetos:

  - datos: frame de datos que contendrá mtcars
  - datos.num: frame obtenido a partir de datos utilizando sólo las columnas de tipo numérico.
  - indice.columna: Índice de la columna de datos con la que se quiera trabajar.
  - columna: Contendrá la columna de datos correspondiente a indice.columna.
  - nombre.columna: Nombre de la columna correspondiente a indice.columna.

Trabajaremos únicamente sobre las variables numéricas. Por lo tanto procedemos de la siguiente forma:

1. Cargamos el conjunto de datos. En nuestro caso usaremos el conjunto de datos mtcars
2. Seleccionamos sólo las variables numéricas. Para ello usamos la función is.numeric. Aplicada sobre una columna, nos dice si 3. todos sus valores son numéricos. Por ejemplo, para ver si la tercera columna es numérica, pondríamos is.numeric(datos[, 3])
4. Vemos los valores que toman dichas variables y eliminamos aquellas que sean ordinales o con pocos valores distintos
5. Eliminamos también aquellos registros que tienen algún valor nulo en alguna columna. En aquellos casos en los que tenga sentido hacerlo, se puede aplicar un procedimiento de imputación de valores en vez de eliminar dichos registros.

Cargamos el conjunto de datos
```{r}
datos = mtcars
head(datos)
```

Construímos un dataframe con las columnas numéricas
```{r}
columnas.num = sapply(c(1:ncol(datos)) , function(x) is.numeric(datos[, x]))
columnas.num

datos.num = datos[, columnas.num]
```

Vemos información sobre cada variable
```{r}
head(datos)

# Medidas estadísticas
summary(datos)

# Ocurrencias
apply(mpg, 2, table)
```

Puede apreciar que las variables cyl, vs, am, gear, carb tienen muy pocos valores distintos por lo que las eliminamos del estudio.
```{r}
datos.num  = datos.num[,-c(2 , 8:11)]  
head(datos.num)
```

Finalmente, eliminamos todas aquellas filas que tengan algún valor nulo:
```{r}
datos.num = na.omit(datos.num)
```

# Detección de outliers en una dimensión
## Outliers IQR

Los métodos IQR teóricamente solo se deben aplicar a distribuciones normales, pero también pueden funcionar si la forma de la distribución no es rara (multimodal, uniforme...).

Mostramos histograma de cada variable
```{r}
par(mfrow = c(2,3))
c(1:ncol(datos.num)) %>% sapply(function(x) hist(datos.num[,x], 
                                                 main="", 
                                                 xlab=names(datos.num)[x]))
```

Comprobamos normalidad con el test de Shapiro
```{r}
# shapiro.test(datos.num[,-1])
# datos.num %>% apply(2, is.numeric)
```

Ninguna variable sigue una distribución __rara__ (quizás la variable _disp_ que parece uniforme), así que mantenemos todas las columnas.

A falta de más información, seleccionamos cualquiera de ellas (posteriormente trabajaremos con todas) Por ejemplo, seleccionamos _mpg_ (ya que junto a qsec, drat y hp son las que más se asemejan a una Normal) Establecemos las siguientes variables para reutilizarlas a lo largo de este apartado.

```{r}
indice.columna = 1
columna        = datos.num[, indice.columna]
nombre.columna = names(datos.num) [indice.columna]
```

### Obtención de los outliers IQR

1. En primer lugar debe calcular las siguiente variables:

  - cuartil.primero: Es el primer cuartil
  - cuartil.tercero: Es el tercer cuartil
  - iqr : Distancia intercuartil IQR
  
  Para ello, usamos las siguientes funciones:

  - quantile(columna, x) para obtener los cuartiles: x=0.25 para el primer cuartil, 0.5 para la mediana y 0.75 para el tercero.
  - IQR para obtener la distancia intercuartil (o bien reste directamente el cuartil tercero y el primero)
  
```{r}
cuartil.primero <- quantile(columna, .25, names = F)
cuartil.tercero <- quantile(columna, .75, names = F)
iqr <- IQR(columna)
```

```{r}
cat("Q1: ")
cuartil.primero
cat("\nQ3: ")
cuartil.tercero
cat("\nIQR: ")
iqr
```
  
2. A continuación debe calcular los extremos que delimitan los outliers:

  - extremo.superior.outlier.IQR se calcula como el cuartil tercero más 1.5 veces la distancia intercuartil.
  - extremo.inferior.outlier.IQR se calcula como el cuartil primero menos 1.5 veces 1.5 la distancia intercuartil.
  - extremo.superior.outlier.IQR.extremo se calcula como el cuartil tercero más 3 veces la distancia intercuartil.
  - extremo.inferior.outlier.IQR.extremo se calcula como el cuartil primero menos 3 veces la distancia intercuartil.

```{r}
extremo.superior.outlier.IQR <- cuartil.tercero + 1.5 * iqr
extremo.inferior.outlier.IQR <- cuartil.primero - 1.5 * iqr
extremo.superior.outlier.IQR.extremo <- cuartil.tercero + 3 * iqr
extremo.inferior.outlier.IQR.extremo <- cuartil.primero - 3 * iqr
```

```{r}
extremo.superior.outlier.IQR
extremo.inferior.outlier.IQR
extremo.superior.outlier.IQR.extremo
extremo.inferior.outlier.IQR.extremo
```


3. Finalmente, construya sendos vectores de valores lógicos TRUE/FALSE que nos dicen si cada registro es o no un outlier con respecto a la columna fijada:

  - son.outliers.IQR
  - son.outliers.IQR.extremos

Para ello, basta comparar con el operador relacional > o el operador relacional < la columna con alguno de los valores extremos anteriores (El operador lógico que debe usar es |)

```{r}
son.outliers.IQR <- columna < extremo.inferior.outlier.IQR | columna > extremo.superior.outlier.IQR
son.outliers.IQR.extremos <- columna < extremo.inferior.outlier.IQR.extremo | columna > extremo.superior.outlier.IQR.extremo
```

```{r}
head(son.outliers.IQR)
head(son.outliers.IQR.extremos)
sum(son.outliers.IQR)
sum(son.outliers.IQR.extremos)
```

### Índices y valores de los outliers IQR
```{r}
claves.outliers.IQR <- which(son.outliers.IQR)
df.outliers.IQR <- datos.num[claves.outliers.IQR,]
nombres.outliers.IQR <- row.names(df.outliers.IQR) 
valores.outliers.IQR <- columna[claves.outliers.IQR]

claves.outliers.IQR.extremos <- which(son.outliers.IQR.extremos)
df.outliers.IQR.extremos <- datos.num[claves.outliers.IQR.extremos,]
nombres.outliers.IQR.extremos <- row.names(df.outliers.IQR.extremos) 
valores.outliers.IQR.extremos <- columna[claves.outliers.IQR.extremos]
```

```{r}
claves.outliers.IQR
df.outliers.IQR
nombres.outliers.IQR
valores.outliers.IQR
```


```{r}
claves.outliers.IQR.extremos
df.outliers.IQR.extremos
nombres.outliers.IQR.extremos
valores.outliers.IQR.extremos
```

### Cómputo de los outliers IQR con funciones

ELIMINAR LO DE ARRIBA PARA LA MEMORIA (o incluírlo como subapartado)

```{r}
son.outliers.IQR     = son_outliers_IQR(datos.num, indice.columna)
head(son.outliers.IQR)

claves.outliers.IQR  = claves_outliers_IQR(datos.num, indice.columna)
claves.outliers.IQR

son.outliers.IQR.extremos    = son_outliers_IQR(datos.num, indice.columna, 3)
head(son.outliers.IQR.extremos)

claves.outliers.IQR.extremos = claves_outliers_IQR(datos.num, indice.columna, 3)
claves.outliers.IQR.extremos
```

### Desviación de los outliers con respecto a la media de la columna

Si partimos de una variable X cuya distribución no es normal, el método de z-score no obtiene una N(0,1), pero si la distribución de X no es demasiado rara, los datos que así obtengamos nos darán información útil sobre si los registros son usuales o no. Para ilustrarlo, apliquemos el método z-score a la variable mpg. Para ello, usamos la función scale:

```{r}
datos.num.norm = scale(datos.num)
head(datos.num.norm)

columna.norm   = datos.num.norm[, indice.columna]
```
Para ver los valores normalizados de los outliers, construya la la variable valores.outliers.IQR.norm. Para ello, debe usar la variable columna.norm junto con son.outliers.IQR (o bien claves.outliers.IQR). Le debe salir lo siguiente:
```{r}
valores.outliers.IQR.norm <- columna.norm[claves.outliers.IQR]

valores.outliers.IQR.norm
```

Vamos a ver ahora el comportamiento de los outliers en la columna seleccionada con respecto al resto de columnas. Para ello, basta con seleccionar los datos correspondientes del conjunto de datos normalizado. En nuestro caso, sólo tenemos un outlier IQR en la columna seleccionada. Nos debe salir lo siguiente:

```{r}
datos.num.norm.outliers.IQR <- datos.num.norm[claves.outliers.IQR,]

datos.num.norm.outliers.IQR
```
Podemos apreciar que el Toyota Corolla no tiene valores excesivamente grandes o pequeños en el resto de columnas (distintas de mpg)

### Gráfico

Mostramos en un gráfico los valores de los registros. Usaremos el color rojo para mostrar lo outliers. Para ello, llame a la siguiente función:
```{r}
plot_2_colores(datos.num.norm, claves.outliers.IQR)
```

```{r}
plot_2_colores(datos.num.norm, claves.outliers.IQR.extremos)
```

### Diagrama de cajas

Otro análisis exploratorio de los datos nos lo da los diagramas de cajas. Vamos a usar la función geom_boxplot definida en el paquete ggplot. En vez de usarla directamente, llamamos a la siguiente función (que llama internamente a geom_boxplot), disponible en el fichero

```{r}
diag_caja_outliers_IQR(datos.num.norm, 1)
```

Esta función se ha construido para mostrar un diagrama de cajas genérico. El diagrama también muestra las etiquetas de los registros cuyos índices se indican en el parámetro claves.a.mostrar. En nuestro caso, le pasamos como parámetro el vector que ya había construido anteriormente con los índices de los outliers IQR, es decir, el vector claves.outliers.IQR ( pero podría pasarle cualquier otro vector de índices). Nos debe salir lo siguiente:

```{r}
diag_caja(datos.num.norm, 1, claves.outliers.IQR)
```

Al igual que hicimos en el apartado anterior, vamos a analizar los valores que un outlier (con respecto a una columna seleccionada) toma en el resto de columnas. Para ello, vamos a mostrar de forma conjunta los diagramas de cajas de varias variables. Llamamos a la función diag_caja_juntos, disponible en el fichero OutliersFunciones_byCubero.R
```{r}
diag_caja_juntos(datos.num, "Outliers", claves.outliers.IQR)
```

Tal y como habíamos analizado anteriormente, el Toyota Corolla (que es un outlier IQR con respecto a mpg) no tiene valores anormales en el resto de columnas (aunque tal vez con la excepción de la variable disp).

## Test de hipótesis

En este apartado vamos a determinar con un test de hipótesis si el valor más alejado de la media puede considerarse como un outlier.
Así pues, la hipótesis nula es la siguiente:


H0:El valor más alejado de la media no es un outlier

O siendo más correctos:

H0:El valor más alejado de la media proviene de la misma distribución que el resto de datos

El método IQR que hemos visto anteriormente es un método que suele aplicarse con la única restricción de que el histograma de la variable no sea demasiado raro. Sin embargo, un test de hipótesis es un método de decisión cuya finalidad es rechazar una hipótesis con suficientes garantías, desde un punto de vista estadístico. Por tanto, debemos ser más cautelosos con las restricciones exigidas para aplicar el método. En nuestro caso, vamos a aplicar el test de Grubbs.

### Comprobación de la hipótesis de Normalidad

El test de Grubbs establece como hipótesis nula que el valor más alejado de la media (llamémosle O) no es un outlier. Por tanto, si el test rechaza, tendremos garantía estadística de que es un outlier. Ahora bien:

El test asume que los datos deben seguir una distribución Normal. Esta hipótesis se refiere al conjunto de datos sin tener en cuenta O. Por tanto, si el test de Grubbs decide rechazar y se acepta que O es un outlier, el siguiente paso que debemos dar es comprobar que los datos que quedan siguen una distribución Normal. Esto lo haremos aplicando un test específico de ajuste de distribuciones.

Si no se rechaza, sólo podremos decir que no hay evidencia de que O provenga de otra distribución distinta al resto de los datos.

En primer lugar pasamos a comprobar de una forma informal que los datos siguen una distribución Normal. Lo vamos a hacer visualmente analizando el histograma. Por simplicidad incluimos el posible outlier en el gráfico. Posteriormente, aplicaremos un test de hipótesis específico de ajuste de distribuciones (sin tener en cuenta el outlier), tal y como hemos indicado anteriormente.

Para ver la curva Normal que mejor se ajusta al histograma, usamos la función denscompdel paquete fitdistrplus y observamos que, efectivamente, podemos suponer que la distribución subyacente es una Normal.

```{r}
ajusteNormal = fitdist(columna , "norm")
denscomp (ajusteNormal,  xlab = nombre.columna)
```

### Test de Grubs

Una vez que hemos visto que los datos siguen una distribución no demasiado alejada de la Normal, procedemos a aplicar el test de Grubbs.
```{r}
test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)
test.de.Grubbs$p.value
```

El p-value es > 0.05, por lo que el test no puede rechazar. Así pues, aunque Toyota Corolla tiene un valor alto en mpg, no podemos deducir que realmente sea un outlier desde el punto de vista estadístico.

En el caso de que el estudio de los outliers lo hubiésemos empezado directamente con el test de Grubbs, la anterior función sólo nos dice si el valor más alejado de la media puede considerarse un outlier. ¿Pero a qué valor corresponde? Para responder esta pregunta, usamos la función outlier del paquete outliers. Es importante enfatizar que la función outlier no realiza ningún test. Simplemente nos da información referente a las diferencias de cada valor con respecto a la media. 

Para conocer el valor que toma el registro que más se aleja de la media, basta pasar como parámetro la columna de datos a la función outlier:
```{r}
valor.posible.outlier = outlier(columna)
valor.posible.outlier
```

Efectivamente, el valor del Toyota Corolla en la columna mpg es 33.9. Para obtener el identificador de dicho registro, pasamos como parámetro adicional a la función outlier el valor logical = TRUE: ésto nos devuelve un vector de bools en el que todos son FALSE excepto el valor que está más alejado de la media. Basta pues, usar which para ver su identificador:

```{r}
es.posible.outlier = outlier(columna, logical = TRUE)
clave.posible.outlier = which( es.posible.outlier == TRUE)
clave.posible.outlier
```

Lo que nos devuelve la clave 20 (la clave de Toyota Corolla).

### Test de Normalidad

Vamos a comprobar que los datos que quedan después de eliminar el outlier detectado por el test de Grubss siguen una distribución Normal. En el conjunto mtcars no hay ningún registro de ninguna variable que el test de Grubbs etiquete como outlier. Por lo tanto, para ilustrar el proceso que vamos a seguir, vamos a usar un conjunto de datos sintético. En el trabajo final que usted debe desarrollar (en su caso) use la misma variable que hubiese seleccionado al principio. Hágalo aunque el test de Grubbs no haya detectado ningún outlier, para así comprobar si la variable se distribuye según una distribución Normal.

El test de hipótesis que se plantea es el siguiente:

```
H0:La distribución subyacente de la variable es una Normal
```

Observe que el tipo de hipótesis nula es diferente que el del test de outliers. En este caso, la hipótesis nula es una afirmación (en el caso del test de Grubbs era una negación). Por lo tanto, si se rechaza, podemos afirmar que los datos no vienen de una Normal. En el caso de que no se pueda rechazar, sólo podremos afirmar que los datos no contradicen la hipótesis nula y por tanto, podremos asumir (pero sin garantía estadística) que se satisface el requisito de Normalidad de los datos.

Hay varios tests de hipótesis para comprobar el ajuste de una distribución (por orden de importancia):

- El test de Shapiro-Wilks (shapiro.test) es un test específico para la distribución Normal. Es el preferible cuando hay pocos datos (menos de 50)

- El test de Anderson-Darling es un test para cualquier distribución. Requiere que se conozcan los parámetros de la distribución, aunque suele utilizarse con las estimaciones de éstos. Está disponible a través de gofstat$adtest del paquete fitdistrplus

- El test de Kolomogorov-Smirnov (shapiro.test) es otro test genérico aplicable a cualquier distribución (sólo compara la mayor diferencia observada entre los datos y la media). Requiere conocer los parámetros de la distribución. En el caso de la Normal, se usa la variante de Lilliefors (lillie.test del paquete nortest) que no requiere el conocimiento de éstos.

Vamos a trabajar con los dos primeros tests. Construimos un dataset artificial

```{r}
datos.artificiales = c(45,56,54,34,32,45,67,45,67,65,140)
```

y lanzamos el mismo proceso anterior para detectar el posible outlier O:
```{r}
test.de.Grubbs = grubbs.test(datos.artificiales, two.sided = TRUE)
test.de.Grubbs$p.value

valor.posible.outlier = outlier(datos.artificiales)
valor.posible.outlier

es.posible.outlier = outlier(datos.artificiales, logical = TRUE)
es.posible.outlier

clave.posible.outlier = which(es.posible.outlier == TRUE)
clave.posible.outlier
```

Pasamos los tests de Normalidad al conjunto de datos eliminando previamente el outlier O:
```{r}
datos.artificiales.sin.outlier = datos.artificiales[-clave.posible.outlier]
datos.artificiales.sin.outlier

shapiro.test(datos.artificiales)

goodness_fit = gofstat(ajusteNormal)
goodness_fit$adtest
```

El test de Anderson-Darling no se ha podido aplicar porque hay pocos datos. El test de Shapiro no puede rechazar la hipótesis nula de Normalidad (p-value > 0.05) Así pues, podemos asumir que los datos no contradicen que la distribución subyacente sea una Normal.

En resumen, podemos concluir que los valores presentes en datos.artificiales son compatibles con una distribución Normal y que el registro 11 con un valor de 140 es el que más se aleja de la media y puede considerarse un outlier con garantía estadística según el test de Grubbs.

Construya una función con el nombre test_Grubbs que devuelva una lista con los cómputos anteriores. También debe lanzar el test de Normalidad sobre la columna elegida (una vez eliminado el posible outlier). Concretamente, la función pedida debe tener la siguiente cabecera:

```{r}
#######################################################################
# Aplica el test de Grubbs sobre la columna ind.col de datos y devuelve una lista con:

# nombre.columna: Nombre de la columna datos[, ind.col]
# clave.mas.alejado.media: Clave del valor O que está más alejado de la media
# valor.mas.alejado.media: Valor de O en datos[, ind.col]
# nombre.mas.alejado.media: Nombre de O en datos
# es.outlier: TRUE/FALSE dependiendo del resultado del test de Grubbs sobre O
# p.value:  p-value calculado por el test de Grubbs
# es.distrib.norm: Resultado de aplicar el test de Normalidad 
#    de Shapiro-Wilks sobre datos[, ind.col]
#    El test de normalidad se aplica sin tener en cuenta el 
#    valor más alejado de la media (el posible outlier O)
#    TRUE si el test no ha podido rechazar
#       -> Sólo podemos concluir que los datos no contradicen una Normal
#    FALSE si el test rechaza 
#       -> Los datos no siguen una Normal

# Requiere el paquete outliers

test_Grubbs = function(datos, ind.col, alpha = 0.05) {
  columna <- datos[,ind.col]
  res <- list()
  
  # Nombre columna
  res$nombre.columna <- colnames(datos)[ind.col]
    
  # Búsqueda del outlier
  es.posible.outlier <- outlier(columna, logical = TRUE)
  
  res$clave.mas.alejado.media <- which(es.posible.outlier == TRUE)
  res$valor.mas.alejado.media <- outlier(columna)
  res$nombre.mas.alejado.media <- rownames(datos)[res$clave.mas.alejado.media]
  
  # Test de Grubbs
  test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)

  res$es.outlier <- ifelse(test.de.Grubbs$p.value <= alpha, TRUE, FALSE)
  res$p.value <- test.de.Grubbs$p.value

  # Test de normalidad
  test.Normalidad <- shapiro.test(columna[-res$clave.mas.alejado.media])
  res$es.distrib.norm <- ifelse(test.Normalidad$p.value > alpha, TRUE, FALSE)
  
  res
}
  
df.datos.artificiales = as.data.frame(datos.artificiales)

test.Grubbs.datos.artificiales = test_Grubbs(df.datos.artificiales, 1)

test.Grubbs.datos.artificiales
```

```{r}
test.Grubbs.datos.num = test_Grubbs(datos.num, indice.columna)

test.Grubbs.datos.num
```

## Trabajando con varias columnas

### Outliers IQR

Empezamos con los outliers IQR: vamos a calcular los outliers IQR con respecto a cada una de las columnas. El conjunto de ellos nos dará aquellos registros que son outliers con respecto a alguna columna.
Para ello, llamamos a la siguiente función (disponible en OutliersFunciones_byCubero.R) y guardamos el resultado en la variable claves.outliers.IQR.en.alguna.columna (mire el código de la función para ver cómo utiliza sapply)

```{r}
claves.outliers.IQR.en.alguna.columna =
  claves_outliers_IQR_en_alguna_columna(datos.num, 1.5)

claves.outliers.IQR.en.alguna.columna
```

En este ejemplo, no hay registros duplicados pero podría haberlos. En ese caso, construimos sendas variables claves.outliers.IQR.en.mas.de.una.columna con todos aquellos registros que aparecen más de una vez y modificamos la variable claves.outliers.IQR.en.alguna.columna para que no aparezcan registros repetidos:

```{r}
claves.outliers.IQR.en.mas.de.una.columna = 
  unique(
    claves.outliers.IQR.en.alguna.columna[
      duplicated(claves.outliers.IQR.en.alguna.columna)])
claves.outliers.IQR.en.alguna.columna = 
  unique (claves.outliers.IQR.en.alguna.columna)


claves.outliers.IQR.en.mas.de.una.columna
claves.outliers.IQR.en.alguna.columna 
nombres_filas(datos.num, claves.outliers.IQR.en.mas.de.una.columna)
nombres_filas(datos.num, claves.outliers.IQR.en.alguna.columna)
```

Vamos a ver los valores normalizados de estos outliers. Nos debe salir lo siguiente:
```{r}
datos.num.norm[claves.outliers.IQR.en.alguna.columna,]
```

Vamos a ver esta misma información de forma gráfica. Para ello, utilice el vector claves.outliers.IQR.en.alguna.columna para pasarlo como parámetro a la función diag_caja_juntos. De esta forma, obtendremos los diagramas de cajas de todas las variables y se mostrarán los valores que toman los outliers con respecto a alguna columna. Hágalo con los outliers normales y con los extremos. En nuestro ejemplo, como no hay outliers extremos, mostraremos los resultados con los outliers normales. Debe salir lo siguiente:
```{r}
diag_caja_juntos(datos.num.norm, "Outliers en alguna columna", claves.outliers.IQR.en.alguna.columna)
```

Vemos, por ejemplo, que el Toyota Corolla se dispara (por arriba) en mpg pero no tanto en el resto de columnas. Parece por tanto un coche bastante equilibrado que consume muy poco.

Por otra parte, el Maserati Bora se dispara en hp (por arriba) y algo menos en qsec (por abajo): es un coche muy potente lo que le permite obtener una aceleración muy alta. Además, tiene un consumo (mpg) bastante moderado para ser un coche de esas características.

Es llamativo el caso del Merc 230 que tenga una aceleración tan baja, la menor de todos los coches. Habría que determinar si se trata de un error en la toma de datos o simplemente los ingenieros diseñaron el vehículo con esas características.

También es llamativo el bloque de coches Lincoln Continental, Chrysler Imperial, Cadillac Fletwood. Son coches muy pesados, con mucha cilindrada y que consumen mucho. Los típicos coches americanos.

### Test de Hipótesis

Vamos a ejecutar el test de Grubbs sobre las columnas de datos.num. En primer lugar, analizamos los histogramas de las variables para ver aquellas que se ajustan a una distribución Normal. Podemos usar los gráficos que generamos en el apartado Datasets y Selección de Variables o bien generarlos con las funciones fitdist y denscomp tal y como hicimos en el apartado Comprobación de la Hipótesis de Normalidad (tendrá que recorrer todas las columnas con sapply). Si lo hace de esta segunda forma, le debe salir lo siguiente:
```{r}
par(mfrow = c(2,3))
datos.num %>% apply(2, function(columna) {
  ajusteNormal = fitdist(columna , "norm")
  denscomp (ajusteNormal,  xlab = nombre.columna)
})
```

Tal y como vimos en el apartado Datasets y Selección de Variables, la variable disp es la que más se aleja de una Normal. En cualquier caso, la mantenemos por ahora. Pasamos el test de Grubbs a todas las columnas. Para ello, utilice sapply (también podría haber usado apply, pero los resultados no se muestran de una forma tan compacta). Debe obtener lo siguiente:
```{r}
sapply(1:ncol(datos.num), test_Grubbs, datos=datos.num)
```

En primer lugar, analizamos el test de Normalidad de Shapiro-Wilks. Recordemos que la función test_Grubbs la habíamos construido de forma que aplicaba el test después de haber eliminado el posible outlier de la columna correspondiente. El test rechaza en las variables disp (como ya habíamos supuesto) y drat. Así pues, podemos afirmar que dichas variables no siguen una distribución Normal. En cuanto al resto de variables, el test no puede rechazar por lo que concluimos que dichas variables puede considerarse que siguen una Normal. Recuerde que no tenemos ninguna garantía estadística ya que el test no ha rechazado y realmente lo único que podemos afirmar es que los datos no contradicen la hipótesis de Normalidad.

Por otra parte, vemos que ninguno de los outliers IQR pueden considerarse realmente outliers con garantía estadística. Los candidatos que han estado más cerca de considerarse outliers según el test de Grubbs son el Maserati Bora(columna hp, p-value 0.111) y Merc 230 (columna qsec, p-value = 0.08)

# Outliers Multivariantes

## Métodos estadísticos basados en la distancia de Mahalanobis

Para encontrar outliers multivariantes con técnicas estadísticas, vamos a aplicar las que se basan en la distancia de Mahalanobis. Es importante destacar que la finalidad de estas técnicas es ofrecer una garantía estadística de que si un valor se etiqueta como outlier, realmente lo es. Por lo tanto, la hipótesis nula establece que no lo es, de forma que si se rechaza, estaremos seguros de que sí es un outlier:

```
H0:El valor más alejado del centro de la distribución no es un outlier
```

### Hipótesis de Normalidad
Los métodos basados en la distancia de Mahalanobis asumen que la distribución conjunta es una distribución Normal multivariante. Por lo tanto, la hipótesis nula es realmente la siguiente:

```
H0:El valor con mayor distancia de Mahalanobis al centro de la distribución vienede la misma distribución Normal multivariante que el resto de datos
```

Una condición necesaria para que un conjunto de variables siga una distribución Normal multivariante es que cada una de ellas siga una distribución normal 1-variante. Por lo tanto, lo primero que vamos a hacer es trabajar únicamente con aquellas variables que siguen una Normal. Para ello, usamos la función test_Grubbs que ya habíamos construido previamente. Recuerde que esta función devuelve una lista que incluye la propiedad es.distrib.norm que es un bool que nos dice si la variable en cuestión puede considerarse que sigue una distribución Normal. Utilícela con sapply para obtener un vector de bools son.col.normales. Utilice dicho vector para construir el dataset datos.num.distrib.norm que contendrá aquellas variables Normales del conjunto de datos datos.num. En nuestro ejemplo, recuerde que disp y drat (índices de variables 2 y 4) no eran variables Normales. Debe salir lo siguiente:
```{r}
test <- sapply(1:ncol(datos.num), test_Grubbs, datos=datos.num)
son.col.normales <- apply(test, 2, function(x) {
  x$es.distrib.norm
})
datos.num.distrib.norm = datos.num[,son.col.normales]

son.col.normales
head(datos.num.distrib.norm)
```

Ahora bien, el que las variables sigan una distribución Normal 1-variante no garantiza que el conjunto de ellas siga una distribución Normal multivariante. Es una condición necesaria pero no suficiente. Por lo tanto, tenemos que lanzar un test de Normalidad multivariante. Para ello, lanzamos la función mvn de la librería MVN. Lo hacemos sobre el conjunto de datos datos.num.distrib.norm:
```{r}
test.MVN = mvn(datos.num.distrib.norm, mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
test.MVN$multivariateNormality["p value"]
```


El test nos dice que la distribución conjunta de las variables mpg, hp, wt, qsec no es una Normal multivariante. Por lo tanto, no deberíamos aplicar el método basado en la distancia de Mahalanobis. De todas formas, vamos a lanzarlo para ver si detectamos algún valor que, aunque no pueda considerarse un outlier con garantía estadística, al menos proporcione alguna información interesante.

### Tests de hipótesis para detectar outliers
Vamos a usar la función cerioli2010.fsrmcd.test del paquete CerioliOutlierDetection (el paquete ofrece otra función cerioli2010.irmcd.test que, por simplicidad, no la veremos) La función cerioli2010.fsrmcd.test obtiene los outliers calculando las distancias de Mahalanobis usando una estimación de la matriz de covarianzas, según el método robusto MCD -minimum covariance determinant (la distribución del estadístico es la obtenida en Hardin-Rocke o Green and Martin) A título informativo, estos métodos robustos no incluyen los valores alejados del centro de la distribución en la estimación de la matriz de covarianzas. Para verlo visualmente, lancemos la función corr.plot (del paquete mvoutlier) sobre las dos primeras variables (es sólo un ejemplo):

```{r}
corr.plot(datos.num[,1], datos.num[,2])
```

Observe cómo cambia la forma de las elipses determinadas por la distancia de Mahalanobis. En rojo se muestran los puntos de la derecha que están más alejados del centro y que, por tanto, no se han usado en la estimación de la matriz de covarianzas.

Tenemos dos formas de llamar a la función cerioli2010.fsrmcd.test dependiendo del tipo de test que queramos realizar:

1. Si queremos lanzar el test siguiente:

```
H0:El valor con mayor distancia de Mahalanobis viene de la misma distribución Normal multivariante que el resto de datos
```

  llamaremos a la función con un valor de significación de 0.05 (parámetro signif.alpha). Éste sería el equivalente al test  de Grubbs en el que sólo se establece como posible outlier el valor más alejado del centro de la distribución. Lo llamaremos test individual

2. Si queremos lanzar el conjunto de tests siguientes:

```
∀i=1⋯n,  H0i:El i-ésimo valor viene de la misma distribuciónNormal multivariante que el resto de datos
```

  llamaremos a la función con un valor de significación penalizado, por ejemplo usando la corrección de Sidak: 1−(1−α)1/n. Ésta sería la forma de comprobar si cada uno de los valores es un outlier o no. Al penalizar el error de significación, controlamos el error FWER (consulte las transparencias) pero el test será muy conservador. Lo llamaremos test de intersección

La función cerioli2010.fsrmcd.test devuelve una lista y podremos acceder a las siguientes propiedades:

- outliers: Es un vector de bools en la que indica si el dato i-ésimo es un outlier. En el caso de que hayamos aplicado el test individual , sólo tenemos garantía estadística de que es un outlier el valor con mayor distancia de Mahalanobis.

- mahdist.rw: Es un vector con las distancias de Mahalanobis de cada valor. Realmente, son las distancias de Mahalanobis modificadas por los autores del paquete. Si necesita conocer las distancias de Mahalanobis no modificadas, debe acceder a la propiedad mahdist.

Aplique el test individual con un valor de significación de 0.05 y el test de intersección con un valor de 1−(1−0.05)1/n (n es el número de registros del conjunto de datos). Obtenga las claves de los outliers encontrados por ambos métodos. Para ello tendrá que acceder al vector outliers devuelto por la función cerioli2010.fsrmcd.test. Obtenga también los nombres de las filas correspondientes usando la función nombres_filas disponible en OutliersFunciones_byCubero.R. Como este tipo de métodos robustos usan un método aleatorio para iniciar el proceso de elección de los datos que participarán en el cómputo final, es necesario que establezcamos el valor de semilla para que los resultados que veamos en esta ejecución sean siempre los mismos. Así pues pondremos, por ejemplo, set.seed(2). Debe salir lo siguiente:

```{r}
set.seed(2)

cerioli.individual <- cerioli2010.fsrmcd.test(datos.num, signif.alpha = 0.05)
claves.test.individual <- which(cerioli.individual$outliers)
nombres.test.individual <- nombres_filas(datos.num, claves.test.individual)

n <- nrow(datos.num)
alpha <- 0.05
cerioli.interseccion <- cerioli2010.fsrmcd.test(datos.num, signif.alpha = 1 - (1 - alpha)^(1/n))
claves.test.interseccion <- which(cerioli.interseccion$outliers)
nombres.test.interseccion <- nombres_filas(datos.num, claves.test.individual)

claves.test.individual
## [1]  9 17 29 31
nombres.test.individual
## [1] "Merc 230"          "Chrysler Imperial" "Ford Pantera L"    "Maserati Bora"
claves.test.interseccion
## integer(0)
nombres.test.interseccion
```

Observe que el test de intersección no devuelve ningún outlier, mientras que el test individual devuelve 4 outliers. Ya hemos explicado que sólo tenemos garantía estadística de que sea un outlier el que tiene mayor valor de distancia de Mahalanobis. Para ver cuál es ese valor, basta ordenar decrecientemente el vector mahdist.rw (use la función order con el parámetro decreasing = TRUE ) y seleccionar el primero. Muestre también un gráfico de todas las distancias de Mahlanobis obtenidas para que aprecie cuál es el mayor valor. Le debe salir lo siguiente:
```{r}
cerioli.individual$mahdist.rw %>% sort() %>% plot()
```


```{r}
clave.mayor.dist.Mah <- order(cerioli.individual$mahdist.rw , decreasing = TRUE)[1]
nombre.mayor.dist.Mah <- nombres_filas(datos.num, clave.mayor.dist.Mah)

cerioli.individual$mahdist
clave.mayor.dist.Mah
nombre.mayor.dist.Mah
```

Por lo tanto, podemos concluir que el test individual rechazaría la hipótesis de que el registro con clave 31 (Maserati Bora) no es un outlier. Así pues, lo aceptamos como outlier. Algunas consideraciones:

1. Recuerde que no hemos podido determinar que la distribución subyacente fuese una Normal, por lo que no tenemos garantía estadística de que, efectivamente, dicho registro sea un outlier (de que provenga de una distribución distinta del resto de los datos).

2. Bajo la premisa de lo dicho anteriormente, el test individual ha etiquetado al Maserati Bora como un outlier multivariante. Recuerde que dicho registro no fue etiquetado como outlier 1-variante en niguna variable por el test de Grubbs ya que tenía un valor muy alto en dos variables (hp y qsec), aunque no lo suficiente para que fuese un outlier. Sin embargo, al tener el mismo coche dos variables con valores muy altos, el test multivariante sí lo puede considerar como un outlier, ya que se suman las contribuciones de ambas variables.

## Visualización de datos con un Biplot
El BiPlot es una herramienta gráfica que nos permite tener una idea aproximada de los valores de los registros con respecto a todas las variables, así como las correlaciones entre dichas variables.

El Biplot muestra los registros (las filas del dataset) como puntos en un plano 2D (también podría usarse un gráfico tridimensional) En el mismo gráfico se representan las variables como flechas, indicando la dirección de crecimiento en dicha variable de los datos. Al pasar de n dimensiones a sólo 2, es obvio que se pierde información por lo que siempre debemos tener en cuenta que es una representación aproximada. La aproximación será mejor cuanto mayor sea la suma de los porcentajes explicados por cada eje del plano (componente principal).

Llamamos a la función biplot_2_colores disponible en OutliersFunciones_byCubero.R pasándole como primer parámetro el conjunto de datos y como segundo las claves de aquellos registros cuyos nombres queremos mostrar en el gráfico. En nuestro caso, le pasamos las claves de los outliers IQR.
```{r}
biplot.outliers.IQR = biplot_2_colores(datos.num, 
                                       claves.outliers.IQR.en.alguna.columna, 
                                       titulo.grupo.a.mostrar = "Outliers IQR",
                                       titulo ="Biplot Outliers IQR")
biplot.outliers.IQR
```

La suma de los porcentajes explicados es muy alta (19.1 + 69.8 = 88.9), por lo que la representación obtenida es una buena aproximación. Puede apreciarse en el gráfico que, efectivamente, Toyota Corolla se sitúa en la zona más alta de la variable mpg, al igual que Maserati Bora lo hace en la parte de valores muy altos de hp y en la de valores muy bajos de qsec (recuerde que las flechas indican la dirección de crecimiento) En la sección siguiente usaremos el biplot para mostrar los resultados de otros métodos de detección de outliers.

## Métodos basados en distancias: LOF

Los métodos estadísticos tienen como finalidad proporcionar garantía estadística de que los valores etiquetados como outliers efectivamente lo son. Para ello, presuponen que los datos siguen una distribución estadística concreta. Sin embargo, en las situaciones en las que este requisito no se cumple, no podemos aplicar dichos métodos. En estos casos, vamos a aplicar otros métodos que no ofrecen garantía estadística, pero son capaces de determinar cómo de alejado está cada punto al resto de los datos. Para ello, se usa una medida de distancia que, mientras no digamos lo contrario, será la distancia euclídea. Para que unas variables no dominen sobre otras tendremos que, obligatoriamente, normalizar los datos. Nosotros usaremos la normalización por z-score. De los métodos basados en distancia, aplicaremos uno de los más conocidos: LOF

En primer lugar, debemos determinar el número de vecinos más cercanos que usaremos en el cómputo del método LOF (consulte las transparencias de clase) A falta de más información, elegimos arbitrariamente el valor de 5. Llamamos a la función lofactor de la librería DMwR pasándole como parámetro el conjunto de datos numéricos, una vez normalizados (recuerde que era datos.num.norm):
```{r}
num.vecinos.lof = 5
lof.scores = lofactor(datos.num.norm, k = num.vecinos.lof)
```

La función lofactor asigna un score a cada dato, indicando hasta qué punto es un outlier. Ordenamos dicho vector de forma decreciente y mostramos en un gráfico los scores correspondientes. Nos debe salir lo siguiente: