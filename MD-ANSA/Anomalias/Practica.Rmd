---
title: "Practica"
author: "Ignacio Vellido"
date: "12/9/2020"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    toc: true
    highlight: github
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)

library(ggplot2)   # Gr?ficos
library(fitdistrplus)  # Ajuste de una distribuciÃ³n -> denscomp 
library(reshape)   # melt
library(ggbiplot)  # biplot
library(tidyverse)   
library(outliers)  # Grubbs
library(MVN)       # mvn: Test de normalidad multivariante  
library(CerioliOutlierDetection)  #MCD Hardin Rocke
library(mvoutlier) # corr.plot 
library(DMwR)      # lof
library(cluster)   # PAM
```

```{r include=FALSE}
# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada

###########################################################################
# Funciones utilizadas a lo largo del curso
###########################################################################

# rm(list=ls()) 


###########################################################################
# Realiza un plot de todos los registros
# Permite cambiar el color con el que se visualiza un conjunto de registros. 
# Los registros que se muestran con otro color se especifican en el par?metro
# claves.a.mostrar 

plot_2_colores = function (datos, 
                           claves.a.mostrar, 
                           titulo = "",
                           colores = c("black", "red")){
  
  num.datos = nrow(as.matrix(datos))
  seleccionados =  rep(FALSE, num.datos)
  seleccionados[claves.a.mostrar] = TRUE
  colores.a.mostrar = rep(colores[1], num.datos)
  colores.a.mostrar [seleccionados] = colores[2]
  
  plot(datos, col=colores.a.mostrar, main = titulo)
}



###########################################################################
# Funci?n an?loga a son_outliers_IQR, salvo que devuelve un vector
# de claves en vez de un vector de bools

claves_outliers_IQR = function(datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  son.outliers.IQR = son_outliers_IQR(datos, ind.columna, coef)
  return (which(son.outliers.IQR  == TRUE))
}



###########################################################################
# Calcula los outliers IQR con respecto a una columna 
# Devuelve un vector de bools indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a la columna ind.columna
# coef es 1.5 para los outliers normales y hay que pasarle 3 para los outliers extremos

son_outliers_IQR = function (datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  cuartil.primero = quantile(columna.datos)[2]  
  #quantile[1] es el m?nimo y quantile[5] el m?ximo.
  cuartil.tercero = quantile(columna.datos)[4] 
  iqr = cuartil.tercero - cuartil.primero
  extremo.superior.outlier = (iqr * coef) + cuartil.tercero
  extremo.inferior.outlier = cuartil.primero - (iqr * coef)
  son.outliers.IQR  = columna.datos > extremo.superior.outlier |
    columna.datos < extremo.inferior.outlier
  return (son.outliers.IQR)
}


###########################################################################
# Calcula los outliers IQR con respecto a ALGUNA columna
# Devuelve un vector de claves indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a ALGUNA columna
# coef es 1.5 para los outliers normales y  3 para los outliers extremos

claves_outliers_IQR_en_alguna_columna = function(datos, coef = 1.5){
  df.clave.columnas = data.frame()
  claves.outliers =  sapply(1:ncol(datos), 
                               function(x) claves_outliers_IQR(datos, x, coef)
  )
  claves.outliers.en.alguna.columna = unlist(claves.outliers)
  return (claves.outliers.en.alguna.columna)
}




#######################################################################
# Devuelve los nombres de aquellas filas especificadas en el par?metro claves
# filas es un vector de bools 

nombres_filas = function (datos, claves) {
  num.claves = length(claves)
  nombres.filas = row.names(as.data.frame(datos))[claves]
  
  return (nombres.filas)
}




#######################################################################
# funci?n base para diag_caja_outliers_IQR y diag_caja

diag_caja_grafico_base = function(datos, indice.columna){
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  nombre.columna = colnames(datos)[indice.columna]
  ggboxplot = ggplot(data = as.data.frame(datos), 
                     aes(x=factor(""), 
                         y = datos[,indice.columna]) , 
                     environment = environment()) + 
              xlab(nombre.columna) + ylab("") 
  return (ggboxplot)
}

#######################################################################
# Muestra un diagrama de caja
# Calcula los outliers IQR y los muestra como puntos en rojo en un BoxPlot

diag_caja_outliers_IQR = function (datos, ind.columna, coef.IQR = 1.5){
  # Si quisi?semos l?neas horizontales en los l?mites de las cajas
  # habr?a que a?adir 
  # + stat_boxplot(geom = 'errorbar')   
  
   outliers.IQR = son_outliers_IQR(datos, ind.columna, coef = coef.IQR)
   ggboxplot =  diag_caja_grafico_base(datos, ind.columna) + 
                stat_boxplot(coef = coef.IQR) +
                geom_boxplot(coef = coef.IQR, outlier.colour = "red") 
                # Importante: geom_boxplot debe ir despu?s de stat_boxplot
   
   return (ggboxplot)
}



#######################################################################
# Muestra un diagrama de caja
# Tambi?n muestra las etiquetas de los registros indicados en 
# el par?metro claves.a.mostrar 

diag_caja = function (datos, ind.columna, claves.a.mostrar = c()){
  num.filas = nrow(datos)
  num.claves = length(claves.a.mostrar)
  nombres.filas = vector (mode = "character", length = num.filas)
  nombres.filas = rep("", num.filas)
  nombres.claves = nombres_filas(datos, claves.a.mostrar)

  for (i in num.claves)
    nombres.filas[claves.a.mostrar[i]]  = nombres.claves[i]
  

  ggboxplot = diag_caja_grafico_base(datos, ind.columna) + 
    geom_boxplot(outlier.shape = NA) + # Para que no imprima los outliers IQR calculados dentro del mismo geom_boxplot
    geom_text(aes(label = nombres.filas)) 
  
  return (ggboxplot)
}






#######################################################################
# Muestra de forma conjunta todos los diagramas de caja de las variables de datos
# Para ello, normaliza previamente los datos.
# Tambi?n muestra las etiquetas de los registros indicados en claves.a.mostrar
# Requiere reshape

diag_caja_juntos = function (datos, titulo = "", claves.a.mostrar = c()){  
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  
  # Para hacerlo con ggplot, lamentablemente hay que construir antes una tabla 
  # que contenga en cada fila el valor que a cada tupla le da cada variable 
  # -> paquete reshape->melt
  
  # Por ejemplo, si tenemos el siguiente data frame
  
  # datos = data.frame(
  #   A = c(1, 2),
  #   B = c(3, 4)
  # )
  # datos =
  #     A  B
  #     1  3
  #     2  4
  
  # melt(datos) construye esta tabla:
  
  #      variable value
  # 1        A     1
  # 2        A     2
  # 3        B     3
  # 4        B     4
  
  
  nombres.de.filas = nombres_filas (datos, claves.a.mostrar)
  
  datos = scale(datos)
  datos.melted = melt(datos)
  colnames(datos.melted)[2]="Variables"
  colnames(datos.melted)[3]="zscore"
  factor.melted = colnames(datos.melted)[1]
  columna.factor = as.factor(datos.melted[,factor.melted])
  levels(columna.factor)[!levels(columna.factor) %in% nombres.de.filas] = ""  
  
  ggplot(data = datos.melted, 
         aes(x=Variables, y=zscore), 
         environment = environment()) + 
    ggtitle(titulo) + 
    geom_boxplot(outlier.shape = NA) + 
    geom_text(aes(label = columna.factor), size = 3) 
}






#######################################################################
# Muestra un biplot del conjunto de datos
# Se muestran los nombres de los registros indicados en claves.a.mostrar
# El color usado para dichos registros es el segundo del par?metro colores
# El t?tulo para el grupo de dichos registros es el especificado en titulo.grupo.a.mostrar
# El par?metro titulo especifica el t?tulo principal del gr?fico

biplot_2_colores = function (datos, 
                             claves.a.mostrar = c(), 
                             titulo = "",
                             titulo.grupo.a.mostrar = "Outliers",
                             colores = c("black","red")){
  nombres = rownames(datos)
  claves.datos = c(1:nrow(datos))
  son.a.mostrar = claves.datos %in% claves.a.mostrar
  nombres[!son.a.mostrar] = ''

  PCA.model = princomp(scale(datos))
  outlier.shapes = c(".","x") 
  biplot = ggbiplot(PCA.model,
                    obs.scale = 1,
                    var.scale = 1 ,
                    varname.size = 5,
                    groups =  son.a.mostrar,
                    alpha = 1/2) #alpha = 1/10
  biplot = biplot + labs(color = titulo.grupo.a.mostrar)
  biplot = biplot + scale_color_manual(values = colores)
  biplot = biplot + geom_text(label = nombres,
                              stat = "identity",
                              size = 3,
                              hjust=0,
                              vjust=0)
  biplot = biplot + ggtitle(titulo)
}



#######################################################################
# Muestra un biplot de un conjunto de datos diferenciados por color
# El color lo determina la asignaci?n de cada dato a un cluster 
# Las asignaciones de datos a cluster se indican en asignaciones.clustering
# Tambi?n se muestran los outliers cuyas claves vienen indicadas en claves.outliers
 
biplot_outliers_clustering = function(datos, 
                                      titulo = "Outliers por el m?todo de Clustering", 
                                      titulo.color = "Asignaciones Clustering",
                                      titulo.outlier = "Outliers",
                                      asignaciones.clustering,
                                      claves.outliers){
  son.outliers = rep(FALSE, nrow(datos))
  son.outliers[claves.outliers] = TRUE
  
  bip = biplot_colores_formas(datos, 
                              titulo, titulo.color, titulo.outlier,
                              asignaciones.clustering,
                              son.outliers,
                              claves.outliers)
  bip 
}

#######################################################################
# Muestra un biplot del conjunto de datos
# Los datos se muestran diferenciados por color y por forma
# Las asignaciones de cada dato a su color y forma vienen dadas por los vectores
# asignaciones.colores y asignaciones.formas 
# Tambi?n se muestran las etiquetas de los registros indicados
# en el par?metro opcional claves.a.mostrar 

biplot_colores_formas = function (datos, 
                                  titulo, titulo.color = '', titulo.forma = '', 
                                  asignaciones.colores, asignaciones.formas,
                                  claves.a.mostrar = c()){
  PCA.model = princomp(scale(datos))
  
  son.a.mostrar = rep(FALSE, nrow(datos))
  son.a.mostrar[claves.a.mostrar] = TRUE
  nombres.a.mostrar = rownames(datos)
  nombres.a.mostrar[!son.a.mostrar] = ''

  asignaciones.colores = factor(asignaciones.colores)
  asignaciones.formas  = factor(asignaciones.formas)

  
  bip = ggbiplot(PCA.model, obs.scale = 1, var.scale=1 , varname.size = 3, alpha = 0) +              
    geom_point(aes(shape = asignaciones.formas, colour = asignaciones.colores))  +
    labs(shape = titulo.forma) +
    labs(colour = titulo.color) +
    ggtitle(titulo) +
    geom_text(label = nombres.a.mostrar, stat = "identity", size = 3, hjust=0, vjust=0)      
  
  bip
}

#######################################################################
# Calcula las distancias de cada dato al centroide de su cluster
# Las asignaciones de cada dato a su cluster se indican en asignaciones.clustering
# Cada centroide es una fila del data frame datos.centroides.normalizados

distancias_a_centroides = function (datos.normalizados, 
                                    asignaciones.clustering, 
                                    datos.centroides.normalizados){
  
  sqrt(rowSums(   (datos.normalizados 
                   - 
                   datos.centroides.normalizados[asignaciones.clustering,])^2  ))
}


#######################################################################
# Revierte la funci?n de normalizaci?n (z-score)

desnormaliza = function(datos, filas.normalizadas){
  medias        = colMeans(datos)
  desviaciones  = apply(datos, 2, sd , na.rm = TRUE)
  
  filas.desnormalizadas  = sweep(filas.normalizadas, 2, desviaciones, "*")
  filas.desnormalizadas  = sweep(filas.desnormalizadas, 2, medias, "+")
  
  filas.desnormalizadas 
}




top_clustering_outliers = function(datos.norm, 
                                   asignaciones.clustering, 
                                   datos.centroides.norm, 
                                   num.outliers){
  
  dist_centroides = distancias_a_centroides (datos.norm, 
                                             asignaciones.clustering, 
                                             datos.centroides.norm)
  
  claves = order(dist_centroides, decreasing=T)[1:num.outliers]
  
  list(distancias = dist_centroides[claves]  , claves = claves)
}
```

# Dataset y SelecciÃ³n de Variables

En este guion usaremos el conjunto de datos __mtcars__ disponible directamente en R. Contiene los datos de un serie de vehÃ­culos. Puede encontrar en Internet una descripciÃ³n completa de dicho dataset. Nosotros describimos aquÃ­ las columnas que serÃ¡n el objetivo de nuestro estudio.

- Variables relativas a las caracterÃ­sticas fÃ­sicas

  - disp (displacement) Nos indica la cilindrada en pulgadas cÃºbicas. En EspaÃ±a, lo normal es referirnos a la cilindrada en centÃ­metros cÃºbicos.

  - hp (horse power) Es la potencia del motor

  - drat (Rear axle ratio) Es la relaciÃ³n del eje trasero. Un valor bajo nos permite unos desarrollos mayores con bajo consumo: es lo habitual en turismos. Un valor alto hace que el coche consuma mÃ¡s, pero permite enviar mÃ¡s fuerza, como por ejemplo en un todo terreno.

  - wt (weight) Peso del vehÃ­culo

- Variables relativas al rendimiento

  - mpg (miles per gallon) Nos indica el consumo del coche. Cuanto mayor sea, mÃ¡s combustible consume.

  - qsec (1/4 mile time) Mide el tiempo necesario para recorrer un cuarto de milla. Es una medida inversa a la aceleraciÃ³n: cuanto mÃ¡s acelere un coche, menor serÃ¡ el valor de qsec .

Para trabajar con dicho conjunto, vamos a construir los siguientes objetos:

  - datos: frame de datos que contendrÃ¡ mtcars
  - datos.num: frame obtenido a partir de datos utilizando sÃ³lo las columnas de tipo numÃ©rico.
  - indice.columna: Ãndice de la columna de datos con la que se quiera trabajar.
  - columna: ContendrÃ¡ la columna de datos correspondiente a indice.columna.
  - nombre.columna: Nombre de la columna correspondiente a indice.columna.

Trabajaremos Ãºnicamente sobre las variables numÃ©ricas. Por lo tanto procedemos de la siguiente forma:

1. Cargamos el conjunto de datos. En nuestro caso usaremos el conjunto de datos mtcars
2. Seleccionamos sÃ³lo las variables numÃ©ricas. Para ello usamos la funciÃ³n is.numeric. Aplicada sobre una columna, nos dice si 3. todos sus valores son numÃ©ricos. Por ejemplo, para ver si la tercera columna es numÃ©rica, pondrÃ­amos is.numeric(datos[, 3])
4. Vemos los valores que toman dichas variables y eliminamos aquellas que sean ordinales o con pocos valores distintos
5. Eliminamos tambiÃ©n aquellos registros que tienen algÃºn valor nulo en alguna columna. En aquellos casos en los que tenga sentido hacerlo, se puede aplicar un procedimiento de imputaciÃ³n de valores en vez de eliminar dichos registros.

Cargamos el conjunto de datos
```{r}
datos = mtcars
head(datos)
```

ConstruÃ­mos un dataframe con las columnas numÃ©ricas
```{r}
columnas.num = sapply(c(1:ncol(datos)) , function(x) is.numeric(datos[, x]))
columnas.num

datos.num = datos[, columnas.num]
```

Vemos informaciÃ³n sobre cada variable
```{r}
head(datos)

# Medidas estadÃ­sticas
summary(datos)

# Ocurrencias
apply(mpg, 2, table)
```

Puede apreciar que las variables cyl, vs, am, gear, carb tienen muy pocos valores distintos por lo que las eliminamos del estudio.
```{r}
datos.num  = datos.num[,-c(2 , 8:11)]  
head(datos.num)
```

Finalmente, eliminamos todas aquellas filas que tengan algÃºn valor nulo:
```{r}
datos.num = na.omit(datos.num)
```

# DetecciÃ³n de outliers en una dimensiÃ³n
## Outliers IQR

Los mÃ©todos IQR teÃ³ricamente solo se deben aplicar a distribuciones normales, pero tambiÃ©n pueden funcionar si la forma de la distribuciÃ³n no es rara (multimodal, uniforme...).

Mostramos histograma de cada variable
```{r}
par(mfrow = c(2,3))
c(1:ncol(datos.num)) %>% sapply(function(x) hist(datos.num[,x], 
                                                 main="", 
                                                 xlab=names(datos.num)[x]))
```

Comprobamos normalidad con el test de Shapiro
```{r}
# shapiro.test(datos.num[,-1])
# datos.num %>% apply(2, is.numeric)
```

Ninguna variable sigue una distribuciÃ³n __rara__ (quizÃ¡s la variable _disp_ que parece uniforme), asÃ­ que mantenemos todas las columnas.

A falta de mÃ¡s informaciÃ³n, seleccionamos cualquiera de ellas (posteriormente trabajaremos con todas) Por ejemplo, seleccionamos _mpg_ (ya que junto a qsec, drat y hp son las que mÃ¡s se asemejan a una Normal) Establecemos las siguientes variables para reutilizarlas a lo largo de este apartado.

```{r}
indice.columna = 1
columna        = datos.num[, indice.columna]
nombre.columna = names(datos.num) [indice.columna]
```

### ObtenciÃ³n de los outliers IQR

1. En primer lugar debe calcular las siguiente variables:

  - cuartil.primero: Es el primer cuartil
  - cuartil.tercero: Es el tercer cuartil
  - iqr : Distancia intercuartil IQR
  
  Para ello, usamos las siguientes funciones:

  - quantile(columna, x) para obtener los cuartiles: x=0.25 para el primer cuartil, 0.5 para la mediana y 0.75 para el tercero.
  - IQR para obtener la distancia intercuartil (o bien reste directamente el cuartil tercero y el primero)
  
```{r}
cuartil.primero <- quantile(columna, .25, names = F)
cuartil.tercero <- quantile(columna, .75, names = F)
iqr <- IQR(columna)
```

```{r}
cat("Q1: ")
cuartil.primero
cat("\nQ3: ")
cuartil.tercero
cat("\nIQR: ")
iqr
```
  
2. A continuaciÃ³n debe calcular los extremos que delimitan los outliers:

  - extremo.superior.outlier.IQR se calcula como el cuartil tercero mÃ¡s 1.5 veces la distancia intercuartil.
  - extremo.inferior.outlier.IQR se calcula como el cuartil primero menos 1.5 veces 1.5 la distancia intercuartil.
  - extremo.superior.outlier.IQR.extremo se calcula como el cuartil tercero mÃ¡s 3 veces la distancia intercuartil.
  - extremo.inferior.outlier.IQR.extremo se calcula como el cuartil primero menos 3 veces la distancia intercuartil.

```{r}
extremo.superior.outlier.IQR <- cuartil.tercero + 1.5 * iqr
extremo.inferior.outlier.IQR <- cuartil.primero - 1.5 * iqr
extremo.superior.outlier.IQR.extremo <- cuartil.tercero + 3 * iqr
extremo.inferior.outlier.IQR.extremo <- cuartil.primero - 3 * iqr
```

```{r}
extremo.superior.outlier.IQR
extremo.inferior.outlier.IQR
extremo.superior.outlier.IQR.extremo
extremo.inferior.outlier.IQR.extremo
```


3. Finalmente, construya sendos vectores de valores lÃ³gicos TRUE/FALSE que nos dicen si cada registro es o no un outlier con respecto a la columna fijada:

  - son.outliers.IQR
  - son.outliers.IQR.extremos

Para ello, basta comparar con el operador relacional > o el operador relacional < la columna con alguno de los valores extremos anteriores (El operador lÃ³gico que debe usar es |)

```{r}
son.outliers.IQR <- columna < extremo.inferior.outlier.IQR | columna > extremo.superior.outlier.IQR
son.outliers.IQR.extremos <- columna < extremo.inferior.outlier.IQR.extremo | columna > extremo.superior.outlier.IQR.extremo
```

```{r}
head(son.outliers.IQR)
head(son.outliers.IQR.extremos)
sum(son.outliers.IQR)
sum(son.outliers.IQR.extremos)
```

### Ãndices y valores de los outliers IQR
```{r}
claves.outliers.IQR <- which(son.outliers.IQR)
df.outliers.IQR <- datos.num[claves.outliers.IQR,]
nombres.outliers.IQR <- row.names(df.outliers.IQR) 
valores.outliers.IQR <- columna[claves.outliers.IQR]

claves.outliers.IQR.extremos <- which(son.outliers.IQR.extremos)
df.outliers.IQR.extremos <- datos.num[claves.outliers.IQR.extremos,]
nombres.outliers.IQR.extremos <- row.names(df.outliers.IQR.extremos) 
valores.outliers.IQR.extremos <- columna[claves.outliers.IQR.extremos]
```

```{r}
claves.outliers.IQR
df.outliers.IQR
nombres.outliers.IQR
valores.outliers.IQR
```


```{r}
claves.outliers.IQR.extremos
df.outliers.IQR.extremos
nombres.outliers.IQR.extremos
valores.outliers.IQR.extremos
```

### CÃ³mputo de los outliers IQR con funciones

ELIMINAR LO DE ARRIBA PARA LA MEMORIA (o incluÃ­rlo como subapartado)

```{r}
son.outliers.IQR     = son_outliers_IQR(datos.num, indice.columna)
head(son.outliers.IQR)

claves.outliers.IQR  = claves_outliers_IQR(datos.num, indice.columna)
claves.outliers.IQR

son.outliers.IQR.extremos    = son_outliers_IQR(datos.num, indice.columna, 3)
head(son.outliers.IQR.extremos)

claves.outliers.IQR.extremos = claves_outliers_IQR(datos.num, indice.columna, 3)
claves.outliers.IQR.extremos
```

### DesviaciÃ³n de los outliers con respecto a la media de la columna

Si partimos de una variable X cuya distribuciÃ³n no es normal, el mÃ©todo de z-score no obtiene una N(0,1), pero si la distribuciÃ³n de X no es demasiado rara, los datos que asÃ­ obtengamos nos darÃ¡n informaciÃ³n Ãºtil sobre si los registros son usuales o no. Para ilustrarlo, apliquemos el mÃ©todo z-score a la variable mpg. Para ello, usamos la funciÃ³n scale:

```{r}
datos.num.norm = scale(datos.num)
head(datos.num.norm)

columna.norm   = datos.num.norm[, indice.columna]
```
Para ver los valores normalizados de los outliers, construya la la variable valores.outliers.IQR.norm. Para ello, debe usar la variable columna.norm junto con son.outliers.IQR (o bien claves.outliers.IQR). Le debe salir lo siguiente:
```{r}
valores.outliers.IQR.norm <- columna.norm[claves.outliers.IQR]

valores.outliers.IQR.norm
```

Vamos a ver ahora el comportamiento de los outliers en la columna seleccionada con respecto al resto de columnas. Para ello, basta con seleccionar los datos correspondientes del conjunto de datos normalizado. En nuestro caso, sÃ³lo tenemos un outlier IQR en la columna seleccionada. Nos debe salir lo siguiente:

```{r}
datos.num.norm.outliers.IQR <- datos.num.norm[claves.outliers.IQR,]

datos.num.norm.outliers.IQR
```
Podemos apreciar que el Toyota Corolla no tiene valores excesivamente grandes o pequeÃ±os en el resto de columnas (distintas de mpg)

### GrÃ¡fico

Mostramos en un grÃ¡fico los valores de los registros. Usaremos el color rojo para mostrar lo outliers. Para ello, llame a la siguiente funciÃ³n:
```{r}
plot_2_colores(datos.num.norm, claves.outliers.IQR)
```

```{r}
plot_2_colores(datos.num.norm, claves.outliers.IQR.extremos)
```

### Diagrama de cajas

Otro anÃ¡lisis exploratorio de los datos nos lo da los diagramas de cajas. Vamos a usar la funciÃ³n geom_boxplot definida en el paquete ggplot. En vez de usarla directamente, llamamos a la siguiente funciÃ³n (que llama internamente a geom_boxplot), disponible en el fichero

```{r}
diag_caja_outliers_IQR(datos.num.norm, 1)
```

Esta funciÃ³n se ha construido para mostrar un diagrama de cajas genÃ©rico. El diagrama tambiÃ©n muestra las etiquetas de los registros cuyos Ã­ndices se indican en el parÃ¡metro claves.a.mostrar. En nuestro caso, le pasamos como parÃ¡metro el vector que ya habÃ­a construido anteriormente con los Ã­ndices de los outliers IQR, es decir, el vector claves.outliers.IQR ( pero podrÃ­a pasarle cualquier otro vector de Ã­ndices). Nos debe salir lo siguiente:

```{r}
diag_caja(datos.num.norm, 1, claves.outliers.IQR)
```

Al igual que hicimos en el apartado anterior, vamos a analizar los valores que un outlier (con respecto a una columna seleccionada) toma en el resto de columnas. Para ello, vamos a mostrar de forma conjunta los diagramas de cajas de varias variables. Llamamos a la funciÃ³n diag_caja_juntos, disponible en el fichero OutliersFunciones_byCubero.R
```{r}
diag_caja_juntos(datos.num, "Outliers", claves.outliers.IQR)
```

Tal y como habÃ­amos analizado anteriormente, el Toyota Corolla (que es un outlier IQR con respecto a mpg) no tiene valores anormales en el resto de columnas (aunque tal vez con la excepciÃ³n de la variable disp).

## Test de hipÃ³tesis

En este apartado vamos a determinar con un test de hipÃ³tesis si el valor mÃ¡s alejado de la media puede considerarse como un outlier.
AsÃ­ pues, la hipÃ³tesis nula es la siguiente:


H0:El valor mÃ¡s alejado de la media no es un outlier

O siendo mÃ¡s correctos:

H0:El valor mÃ¡s alejado de la media proviene de la misma distribuciÃ³n que el resto de datos

El mÃ©todo IQR que hemos visto anteriormente es un mÃ©todo que suele aplicarse con la Ãºnica restricciÃ³n de que el histograma de la variable no sea demasiado raro. Sin embargo, un test de hipÃ³tesis es un mÃ©todo de decisiÃ³n cuya finalidad es rechazar una hipÃ³tesis con suficientes garantÃ­as, desde un punto de vista estadÃ­stico. Por tanto, debemos ser mÃ¡s cautelosos con las restricciones exigidas para aplicar el mÃ©todo. En nuestro caso, vamos a aplicar el test de Grubbs.

### ComprobaciÃ³n de la hipÃ³tesis de Normalidad

El test de Grubbs establece como hipÃ³tesis nula que el valor mÃ¡s alejado de la media (llamÃ©mosle O) no es un outlier. Por tanto, si el test rechaza, tendremos garantÃ­a estadÃ­stica de que es un outlier. Ahora bien:

El test asume que los datos deben seguir una distribuciÃ³n Normal. Esta hipÃ³tesis se refiere al conjunto de datos sin tener en cuenta O. Por tanto, si el test de Grubbs decide rechazar y se acepta que O es un outlier, el siguiente paso que debemos dar es comprobar que los datos que quedan siguen una distribuciÃ³n Normal. Esto lo haremos aplicando un test especÃ­fico de ajuste de distribuciones.

Si no se rechaza, sÃ³lo podremos decir que no hay evidencia de que O provenga de otra distribuciÃ³n distinta al resto de los datos.

En primer lugar pasamos a comprobar de una forma informal que los datos siguen una distribuciÃ³n Normal. Lo vamos a hacer visualmente analizando el histograma. Por simplicidad incluimos el posible outlier en el grÃ¡fico. Posteriormente, aplicaremos un test de hipÃ³tesis especÃ­fico de ajuste de distribuciones (sin tener en cuenta el outlier), tal y como hemos indicado anteriormente.

Para ver la curva Normal que mejor se ajusta al histograma, usamos la funciÃ³n denscompdel paquete fitdistrplus y observamos que, efectivamente, podemos suponer que la distribuciÃ³n subyacente es una Normal.

```{r}
ajusteNormal = fitdist(columna , "norm")
denscomp (ajusteNormal,  xlab = nombre.columna)
```

### Test de Grubs

Una vez que hemos visto que los datos siguen una distribuciÃ³n no demasiado alejada de la Normal, procedemos a aplicar el test de Grubbs.
```{r}
test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)
test.de.Grubbs$p.value
```

El p-value es > 0.05, por lo que el test no puede rechazar. AsÃ­ pues, aunque Toyota Corolla tiene un valor alto en mpg, no podemos deducir que realmente sea un outlier desde el punto de vista estadÃ­stico.

En el caso de que el estudio de los outliers lo hubiÃ©semos empezado directamente con el test de Grubbs, la anterior funciÃ³n sÃ³lo nos dice si el valor mÃ¡s alejado de la media puede considerarse un outlier. Â¿Pero a quÃ© valor corresponde? Para responder esta pregunta, usamos la funciÃ³n outlier del paquete outliers. Es importante enfatizar que la funciÃ³n outlier no realiza ningÃºn test. Simplemente nos da informaciÃ³n referente a las diferencias de cada valor con respecto a la media. 

Para conocer el valor que toma el registro que mÃ¡s se aleja de la media, basta pasar como parÃ¡metro la columna de datos a la funciÃ³n outlier:
```{r}
valor.posible.outlier = outlier(columna)
valor.posible.outlier
```

Efectivamente, el valor del Toyota Corolla en la columna mpg es 33.9. Para obtener el identificador de dicho registro, pasamos como parÃ¡metro adicional a la funciÃ³n outlier el valor logical = TRUE: Ã©sto nos devuelve un vector de bools en el que todos son FALSE excepto el valor que estÃ¡ mÃ¡s alejado de la media. Basta pues, usar which para ver su identificador:

```{r}
es.posible.outlier = outlier(columna, logical = TRUE)
clave.posible.outlier = which( es.posible.outlier == TRUE)
clave.posible.outlier
```

Lo que nos devuelve la clave 20 (la clave de Toyota Corolla).

### Test de Normalidad

Vamos a comprobar que los datos que quedan despuÃ©s de eliminar el outlier detectado por el test de Grubss siguen una distribuciÃ³n Normal. En el conjunto mtcars no hay ningÃºn registro de ninguna variable que el test de Grubbs etiquete como outlier. Por lo tanto, para ilustrar el proceso que vamos a seguir, vamos a usar un conjunto de datos sintÃ©tico. En el trabajo final que usted debe desarrollar (en su caso) use la misma variable que hubiese seleccionado al principio. HÃ¡galo aunque el test de Grubbs no haya detectado ningÃºn outlier, para asÃ­ comprobar si la variable se distribuye segÃºn una distribuciÃ³n Normal.

El test de hipÃ³tesis que se plantea es el siguiente:

```
H0:La distribuciÃ³n subyacente de la variable es una Normal
```

Observe que el tipo de hipÃ³tesis nula es diferente que el del test de outliers. En este caso, la hipÃ³tesis nula es una afirmaciÃ³n (en el caso del test de Grubbs era una negaciÃ³n). Por lo tanto, si se rechaza, podemos afirmar que los datos no vienen de una Normal. En el caso de que no se pueda rechazar, sÃ³lo podremos afirmar que los datos no contradicen la hipÃ³tesis nula y por tanto, podremos asumir (pero sin garantÃ­a estadÃ­stica) que se satisface el requisito de Normalidad de los datos.

Hay varios tests de hipÃ³tesis para comprobar el ajuste de una distribuciÃ³n (por orden de importancia):

- El test de Shapiro-Wilks (shapiro.test) es un test especÃ­fico para la distribuciÃ³n Normal. Es el preferible cuando hay pocos datos (menos de 50)

- El test de Anderson-Darling es un test para cualquier distribuciÃ³n. Requiere que se conozcan los parÃ¡metros de la distribuciÃ³n, aunque suele utilizarse con las estimaciones de Ã©stos. EstÃ¡ disponible a travÃ©s de gofstat$adtest del paquete fitdistrplus

- El test de Kolomogorov-Smirnov (shapiro.test) es otro test genÃ©rico aplicable a cualquier distribuciÃ³n (sÃ³lo compara la mayor diferencia observada entre los datos y la media). Requiere conocer los parÃ¡metros de la distribuciÃ³n. En el caso de la Normal, se usa la variante de Lilliefors (lillie.test del paquete nortest) que no requiere el conocimiento de Ã©stos.

Vamos a trabajar con los dos primeros tests. Construimos un dataset artificial

```{r}
datos.artificiales = c(45,56,54,34,32,45,67,45,67,65,140)
```

y lanzamos el mismo proceso anterior para detectar el posible outlier O:
```{r}
test.de.Grubbs = grubbs.test(datos.artificiales, two.sided = TRUE)
test.de.Grubbs$p.value

valor.posible.outlier = outlier(datos.artificiales)
valor.posible.outlier

es.posible.outlier = outlier(datos.artificiales, logical = TRUE)
es.posible.outlier

clave.posible.outlier = which(es.posible.outlier == TRUE)
clave.posible.outlier
```

Pasamos los tests de Normalidad al conjunto de datos eliminando previamente el outlier O:
```{r}
datos.artificiales.sin.outlier = datos.artificiales[-clave.posible.outlier]
datos.artificiales.sin.outlier

shapiro.test(datos.artificiales)

goodness_fit = gofstat(ajusteNormal)
goodness_fit$adtest
```

El test de Anderson-Darling no se ha podido aplicar porque hay pocos datos. El test de Shapiro no puede rechazar la hipÃ³tesis nula de Normalidad (p-value > 0.05) AsÃ­ pues, podemos asumir que los datos no contradicen que la distribuciÃ³n subyacente sea una Normal.

En resumen, podemos concluir que los valores presentes en datos.artificiales son compatibles con una distribuciÃ³n Normal y que el registro 11 con un valor de 140 es el que mÃ¡s se aleja de la media y puede considerarse un outlier con garantÃ­a estadÃ­stica segÃºn el test de Grubbs.

Construya una funciÃ³n con el nombre test_Grubbs que devuelva una lista con los cÃ³mputos anteriores. TambiÃ©n debe lanzar el test de Normalidad sobre la columna elegida (una vez eliminado el posible outlier). Concretamente, la funciÃ³n pedida debe tener la siguiente cabecera:

```{r}
#######################################################################
# Aplica el test de Grubbs sobre la columna ind.col de datos y devuelve una lista con:

# nombre.columna: Nombre de la columna datos[, ind.col]
# clave.mas.alejado.media: Clave del valor O que estÃ¡ mÃ¡s alejado de la media
# valor.mas.alejado.media: Valor de O en datos[, ind.col]
# nombre.mas.alejado.media: Nombre de O en datos
# es.outlier: TRUE/FALSE dependiendo del resultado del test de Grubbs sobre O
# p.value:  p-value calculado por el test de Grubbs
# es.distrib.norm: Resultado de aplicar el test de Normalidad 
#    de Shapiro-Wilks sobre datos[, ind.col]
#    El test de normalidad se aplica sin tener en cuenta el 
#    valor mÃ¡s alejado de la media (el posible outlier O)
#    TRUE si el test no ha podido rechazar
#       -> SÃ³lo podemos concluir que los datos no contradicen una Normal
#    FALSE si el test rechaza 
#       -> Los datos no siguen una Normal

# Requiere el paquete outliers

test_Grubbs = function(datos, ind.col, alpha = 0.05) {
  columna <- datos[,ind.col]
  res <- list()
  
  # Nombre columna
  res$nombre.columna <- colnames(datos)[ind.col]
    
  # BÃºsqueda del outlier
  es.posible.outlier <- outlier(columna, logical = TRUE)
  
  res$clave.mas.alejado.media <- which(es.posible.outlier == TRUE)
  res$valor.mas.alejado.media <- outlier(columna)
  res$nombre.mas.alejado.media <- rownames(datos)[res$clave.mas.alejado.media]
  
  # Test de Grubbs
  test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)

  res$es.outlier <- ifelse(test.de.Grubbs$p.value <= alpha, TRUE, FALSE)
  res$p.value <- test.de.Grubbs$p.value

  # Test de normalidad
  test.Normalidad <- shapiro.test(columna[-res$clave.mas.alejado.media])
  res$es.distrib.norm <- ifelse(test.Normalidad$p.value > alpha, TRUE, FALSE)
  
  res
}
  
df.datos.artificiales = as.data.frame(datos.artificiales)

test.Grubbs.datos.artificiales = test_Grubbs(df.datos.artificiales, 1)

test.Grubbs.datos.artificiales
```

```{r}
test.Grubbs.datos.num = test_Grubbs(datos.num, indice.columna)

test.Grubbs.datos.num
```

## Trabajando con varias columnas

### Outliers IQR

Empezamos con los outliers IQR: vamos a calcular los outliers IQR con respecto a cada una de las columnas. El conjunto de ellos nos darÃ¡ aquellos registros que son outliers con respecto a alguna columna.
Para ello, llamamos a la siguiente funciÃ³n (disponible en OutliersFunciones_byCubero.R) y guardamos el resultado en la variable claves.outliers.IQR.en.alguna.columna (mire el cÃ³digo de la funciÃ³n para ver cÃ³mo utiliza sapply)

```{r}
claves.outliers.IQR.en.alguna.columna =
  claves_outliers_IQR_en_alguna_columna(datos.num, 1.5)

claves.outliers.IQR.en.alguna.columna
```

En este ejemplo, no hay registros duplicados pero podrÃ­a haberlos. En ese caso, construimos sendas variables claves.outliers.IQR.en.mas.de.una.columna con todos aquellos registros que aparecen mÃ¡s de una vez y modificamos la variable claves.outliers.IQR.en.alguna.columna para que no aparezcan registros repetidos:

```{r}
claves.outliers.IQR.en.mas.de.una.columna = 
  unique(
    claves.outliers.IQR.en.alguna.columna[
      duplicated(claves.outliers.IQR.en.alguna.columna)])
claves.outliers.IQR.en.alguna.columna = 
  unique (claves.outliers.IQR.en.alguna.columna)


claves.outliers.IQR.en.mas.de.una.columna
claves.outliers.IQR.en.alguna.columna 
nombres_filas(datos.num, claves.outliers.IQR.en.mas.de.una.columna)
nombres_filas(datos.num, claves.outliers.IQR.en.alguna.columna)
```

Vamos a ver los valores normalizados de estos outliers. Nos debe salir lo siguiente:
```{r}
datos.num.norm[claves.outliers.IQR.en.alguna.columna,]
```

Vamos a ver esta misma informaciÃ³n de forma grÃ¡fica. Para ello, utilice el vector claves.outliers.IQR.en.alguna.columna para pasarlo como parÃ¡metro a la funciÃ³n diag_caja_juntos. De esta forma, obtendremos los diagramas de cajas de todas las variables y se mostrarÃ¡n los valores que toman los outliers con respecto a alguna columna. HÃ¡galo con los outliers normales y con los extremos. En nuestro ejemplo, como no hay outliers extremos, mostraremos los resultados con los outliers normales. Debe salir lo siguiente:
```{r}
diag_caja_juntos(datos.num.norm, "Outliers en alguna columna", claves.outliers.IQR.en.alguna.columna)
```

Vemos, por ejemplo, que el Toyota Corolla se dispara (por arriba) en mpg pero no tanto en el resto de columnas. Parece por tanto un coche bastante equilibrado que consume muy poco.

Por otra parte, el Maserati Bora se dispara en hp (por arriba) y algo menos en qsec (por abajo): es un coche muy potente lo que le permite obtener una aceleraciÃ³n muy alta. AdemÃ¡s, tiene un consumo (mpg) bastante moderado para ser un coche de esas caracterÃ­sticas.

Es llamativo el caso del Merc 230 que tenga una aceleraciÃ³n tan baja, la menor de todos los coches. HabrÃ­a que determinar si se trata de un error en la toma de datos o simplemente los ingenieros diseÃ±aron el vehÃ­culo con esas caracterÃ­sticas.

TambiÃ©n es llamativo el bloque de coches Lincoln Continental, Chrysler Imperial, Cadillac Fletwood. Son coches muy pesados, con mucha cilindrada y que consumen mucho. Los tÃ­picos coches americanos.

### Test de HipÃ³tesis

Vamos a ejecutar el test de Grubbs sobre las columnas de datos.num. En primer lugar, analizamos los histogramas de las variables para ver aquellas que se ajustan a una distribuciÃ³n Normal. Podemos usar los grÃ¡ficos que generamos en el apartado Datasets y SelecciÃ³n de Variables o bien generarlos con las funciones fitdist y denscomp tal y como hicimos en el apartado ComprobaciÃ³n de la HipÃ³tesis de Normalidad (tendrÃ¡ que recorrer todas las columnas con sapply). Si lo hace de esta segunda forma, le debe salir lo siguiente:
```{r}
par(mfrow = c(2,3))
datos.num %>% apply(2, function(columna) {
  ajusteNormal = fitdist(columna , "norm")
  denscomp (ajusteNormal,  xlab = nombre.columna)
})
```

Tal y como vimos en el apartado Datasets y SelecciÃ³n de Variables, la variable disp es la que mÃ¡s se aleja de una Normal. En cualquier caso, la mantenemos por ahora. Pasamos el test de Grubbs a todas las columnas. Para ello, utilice sapply (tambiÃ©n podrÃ­a haber usado apply, pero los resultados no se muestran de una forma tan compacta). Debe obtener lo siguiente:
```{r}
sapply(1:ncol(datos.num), test_Grubbs, datos=datos.num)
```

En primer lugar, analizamos el test de Normalidad de Shapiro-Wilks. Recordemos que la funciÃ³n test_Grubbs la habÃ­amos construido de forma que aplicaba el test despuÃ©s de haber eliminado el posible outlier de la columna correspondiente. El test rechaza en las variables disp (como ya habÃ­amos supuesto) y drat. AsÃ­ pues, podemos afirmar que dichas variables no siguen una distribuciÃ³n Normal. En cuanto al resto de variables, el test no puede rechazar por lo que concluimos que dichas variables puede considerarse que siguen una Normal. Recuerde que no tenemos ninguna garantÃ­a estadÃ­stica ya que el test no ha rechazado y realmente lo Ãºnico que podemos afirmar es que los datos no contradicen la hipÃ³tesis de Normalidad.

Por otra parte, vemos que ninguno de los outliers IQR pueden considerarse realmente outliers con garantÃ­a estadÃ­stica. Los candidatos que han estado mÃ¡s cerca de considerarse outliers segÃºn el test de Grubbs son el Maserati Bora(columna hp, p-value 0.111) y Merc 230 (columna qsec, p-value = 0.08)

# Outliers Multivariantes

## MÃ©todos estadÃ­sticos basados en la distancia de Mahalanobis

Para encontrar outliers multivariantes con tÃ©cnicas estadÃ­sticas, vamos a aplicar las que se basan en la distancia de Mahalanobis. Es importante destacar que la finalidad de estas tÃ©cnicas es ofrecer una garantÃ­a estadÃ­stica de que si un valor se etiqueta como outlier, realmente lo es. Por lo tanto, la hipÃ³tesis nula establece que no lo es, de forma que si se rechaza, estaremos seguros de que sÃ­ es un outlier:

```
H0:El valor mÃ¡s alejado del centro de la distribuciÃ³n no es un outlier
```

### HipÃ³tesis de Normalidad
Los mÃ©todos basados en la distancia de Mahalanobis asumen que la distribuciÃ³n conjunta es una distribuciÃ³n Normal multivariante. Por lo tanto, la hipÃ³tesis nula es realmente la siguiente:

```
H0:El valor con mayor distancia de Mahalanobis al centro de la distribuciÃ³n vienede la misma distribuciÃ³n Normal multivariante que el resto de datos
```

Una condiciÃ³n necesaria para que un conjunto de variables siga una distribuciÃ³n Normal multivariante es que cada una de ellas siga una distribuciÃ³n normal 1-variante. Por lo tanto, lo primero que vamos a hacer es trabajar Ãºnicamente con aquellas variables que siguen una Normal. Para ello, usamos la funciÃ³n test_Grubbs que ya habÃ­amos construido previamente. Recuerde que esta funciÃ³n devuelve una lista que incluye la propiedad es.distrib.norm que es un bool que nos dice si la variable en cuestiÃ³n puede considerarse que sigue una distribuciÃ³n Normal. UtilÃ­cela con sapply para obtener un vector de bools son.col.normales. Utilice dicho vector para construir el dataset datos.num.distrib.norm que contendrÃ¡ aquellas variables Normales del conjunto de datos datos.num. En nuestro ejemplo, recuerde que disp y drat (Ã­ndices de variables 2 y 4) no eran variables Normales. Debe salir lo siguiente:
```{r}
test <- sapply(1:ncol(datos.num), test_Grubbs, datos=datos.num)
son.col.normales <- apply(test, 2, function(x) {
  x$es.distrib.norm
})
datos.num.distrib.norm = datos.num[,son.col.normales]

son.col.normales
head(datos.num.distrib.norm)
```

Ahora bien, el que las variables sigan una distribuciÃ³n Normal 1-variante no garantiza que el conjunto de ellas siga una distribuciÃ³n Normal multivariante. Es una condiciÃ³n necesaria pero no suficiente. Por lo tanto, tenemos que lanzar un test de Normalidad multivariante. Para ello, lanzamos la funciÃ³n mvn de la librerÃ­a MVN. Lo hacemos sobre el conjunto de datos datos.num.distrib.norm:
```{r}
test.MVN = mvn(datos.num.distrib.norm, mvnTest = "energy")
test.MVN$multivariateNormality["MVN"]
test.MVN$multivariateNormality["p value"]
```


El test nos dice que la distribuciÃ³n conjunta de las variables mpg, hp, wt, qsec no es una Normal multivariante. Por lo tanto, no deberÃ­amos aplicar el mÃ©todo basado en la distancia de Mahalanobis. De todas formas, vamos a lanzarlo para ver si detectamos algÃºn valor que, aunque no pueda considerarse un outlier con garantÃ­a estadÃ­stica, al menos proporcione alguna informaciÃ³n interesante.

### Tests de hipÃ³tesis para detectar outliers
Vamos a usar la funciÃ³n cerioli2010.fsrmcd.test del paquete CerioliOutlierDetection (el paquete ofrece otra funciÃ³n cerioli2010.irmcd.test que, por simplicidad, no la veremos) La funciÃ³n cerioli2010.fsrmcd.test obtiene los outliers calculando las distancias de Mahalanobis usando una estimaciÃ³n de la matriz de covarianzas, segÃºn el mÃ©todo robusto MCD -minimum covariance determinant (la distribuciÃ³n del estadÃ­stico es la obtenida en Hardin-Rocke o Green and Martin) A tÃ­tulo informativo, estos mÃ©todos robustos no incluyen los valores alejados del centro de la distribuciÃ³n en la estimaciÃ³n de la matriz de covarianzas. Para verlo visualmente, lancemos la funciÃ³n corr.plot (del paquete mvoutlier) sobre las dos primeras variables (es sÃ³lo un ejemplo):

```{r}
corr.plot(datos.num[,1], datos.num[,2])
```

Observe cÃ³mo cambia la forma de las elipses determinadas por la distancia de Mahalanobis. En rojo se muestran los puntos de la derecha que estÃ¡n mÃ¡s alejados del centro y que, por tanto, no se han usado en la estimaciÃ³n de la matriz de covarianzas.

Tenemos dos formas de llamar a la funciÃ³n cerioli2010.fsrmcd.test dependiendo del tipo de test que queramos realizar:

1. Si queremos lanzar el test siguiente:

```
H0:El valor con mayor distancia de Mahalanobis viene de la misma distribuciÃ³n Normal multivariante que el resto de datos
```

  llamaremos a la funciÃ³n con un valor de significaciÃ³n de 0.05 (parÃ¡metro signif.alpha). Ãste serÃ­a el equivalente al test  de Grubbs en el que sÃ³lo se establece como posible outlier el valor mÃ¡s alejado del centro de la distribuciÃ³n. Lo llamaremos test individual

2. Si queremos lanzar el conjunto de tests siguientes:

```
âi=1â¯n,  H0i:El i-Ã©simo valor viene de la misma distribuciÃ³nNormal multivariante que el resto de datos
```

  llamaremos a la funciÃ³n con un valor de significaciÃ³n penalizado, por ejemplo usando la correcciÃ³n de Sidak: 1â(1âÎ±)1/n. Ãsta serÃ­a la forma de comprobar si cada uno de los valores es un outlier o no. Al penalizar el error de significaciÃ³n, controlamos el error FWER (consulte las transparencias) pero el test serÃ¡ muy conservador. Lo llamaremos test de intersecciÃ³n

La funciÃ³n cerioli2010.fsrmcd.test devuelve una lista y podremos acceder a las siguientes propiedades:

- outliers: Es un vector de bools en la que indica si el dato i-Ã©simo es un outlier. En el caso de que hayamos aplicado el test individual , sÃ³lo tenemos garantÃ­a estadÃ­stica de que es un outlier el valor con mayor distancia de Mahalanobis.

- mahdist.rw: Es un vector con las distancias de Mahalanobis de cada valor. Realmente, son las distancias de Mahalanobis modificadas por los autores del paquete. Si necesita conocer las distancias de Mahalanobis no modificadas, debe acceder a la propiedad mahdist.

Aplique el test individual con un valor de significaciÃ³n de 0.05 y el test de intersecciÃ³n con un valor de 1â(1â0.05)1/n (n es el nÃºmero de registros del conjunto de datos). Obtenga las claves de los outliers encontrados por ambos mÃ©todos. Para ello tendrÃ¡ que acceder al vector outliers devuelto por la funciÃ³n cerioli2010.fsrmcd.test. Obtenga tambiÃ©n los nombres de las filas correspondientes usando la funciÃ³n nombres_filas disponible en OutliersFunciones_byCubero.R. Como este tipo de mÃ©todos robustos usan un mÃ©todo aleatorio para iniciar el proceso de elecciÃ³n de los datos que participarÃ¡n en el cÃ³mputo final, es necesario que establezcamos el valor de semilla para que los resultados que veamos en esta ejecuciÃ³n sean siempre los mismos. AsÃ­ pues pondremos, por ejemplo, set.seed(2). Debe salir lo siguiente:

```{r}
set.seed(2)

cerioli.individual <- cerioli2010.fsrmcd.test(datos.num, signif.alpha = 0.05)
claves.test.individual <- which(cerioli.individual$outliers)
nombres.test.individual <- nombres_filas(datos.num, claves.test.individual)

n <- nrow(datos.num)
alpha <- 0.05
cerioli.interseccion <- cerioli2010.fsrmcd.test(datos.num, signif.alpha = 1 - (1 - alpha)^(1/n))
claves.test.interseccion <- which(cerioli.interseccion$outliers)
nombres.test.interseccion <- nombres_filas(datos.num, claves.test.individual)

claves.test.individual
## [1]  9 17 29 31
nombres.test.individual
## [1] "Merc 230"          "Chrysler Imperial" "Ford Pantera L"    "Maserati Bora"
claves.test.interseccion
## integer(0)
nombres.test.interseccion
```

Observe que el test de intersecciÃ³n no devuelve ningÃºn outlier, mientras que el test individual devuelve 4 outliers. Ya hemos explicado que sÃ³lo tenemos garantÃ­a estadÃ­stica de que sea un outlier el que tiene mayor valor de distancia de Mahalanobis. Para ver cuÃ¡l es ese valor, basta ordenar decrecientemente el vector mahdist.rw (use la funciÃ³n order con el parÃ¡metro decreasing = TRUE ) y seleccionar el primero. Muestre tambiÃ©n un grÃ¡fico de todas las distancias de Mahlanobis obtenidas para que aprecie cuÃ¡l es el mayor valor. Le debe salir lo siguiente:
```{r}
cerioli.individual$mahdist.rw %>% sort() %>% plot()
```


```{r}
clave.mayor.dist.Mah <- order(cerioli.individual$mahdist.rw , decreasing = TRUE)[1]
nombre.mayor.dist.Mah <- nombres_filas(datos.num, clave.mayor.dist.Mah)

cerioli.individual$mahdist
clave.mayor.dist.Mah
nombre.mayor.dist.Mah
```

Por lo tanto, podemos concluir que el test individual rechazarÃ­a la hipÃ³tesis de que el registro con clave 31 (Maserati Bora) no es un outlier. AsÃ­ pues, lo aceptamos como outlier. Algunas consideraciones:

1. Recuerde que no hemos podido determinar que la distribuciÃ³n subyacente fuese una Normal, por lo que no tenemos garantÃ­a estadÃ­stica de que, efectivamente, dicho registro sea un outlier (de que provenga de una distribuciÃ³n distinta del resto de los datos).

2. Bajo la premisa de lo dicho anteriormente, el test individual ha etiquetado al Maserati Bora como un outlier multivariante. Recuerde que dicho registro no fue etiquetado como outlier 1-variante en niguna variable por el test de Grubbs ya que tenÃ­a un valor muy alto en dos variables (hp y qsec), aunque no lo suficiente para que fuese un outlier. Sin embargo, al tener el mismo coche dos variables con valores muy altos, el test multivariante sÃ­ lo puede considerar como un outlier, ya que se suman las contribuciones de ambas variables.

## VisualizaciÃ³n de datos con un Biplot
El BiPlot es una herramienta grÃ¡fica que nos permite tener una idea aproximada de los valores de los registros con respecto a todas las variables, asÃ­ como las correlaciones entre dichas variables.

El Biplot muestra los registros (las filas del dataset) como puntos en un plano 2D (tambiÃ©n podrÃ­a usarse un grÃ¡fico tridimensional) En el mismo grÃ¡fico se representan las variables como flechas, indicando la direcciÃ³n de crecimiento en dicha variable de los datos. Al pasar de n dimensiones a sÃ³lo 2, es obvio que se pierde informaciÃ³n por lo que siempre debemos tener en cuenta que es una representaciÃ³n aproximada. La aproximaciÃ³n serÃ¡ mejor cuanto mayor sea la suma de los porcentajes explicados por cada eje del plano (componente principal).

Llamamos a la funciÃ³n biplot_2_colores disponible en OutliersFunciones_byCubero.R pasÃ¡ndole como primer parÃ¡metro el conjunto de datos y como segundo las claves de aquellos registros cuyos nombres queremos mostrar en el grÃ¡fico. En nuestro caso, le pasamos las claves de los outliers IQR.
```{r}
biplot.outliers.IQR = biplot_2_colores(datos.num, 
                                       claves.outliers.IQR.en.alguna.columna, 
                                       titulo.grupo.a.mostrar = "Outliers IQR",
                                       titulo ="Biplot Outliers IQR")
biplot.outliers.IQR
```

La suma de los porcentajes explicados es muy alta (19.1 + 69.8 = 88.9), por lo que la representaciÃ³n obtenida es una buena aproximaciÃ³n. Puede apreciarse en el grÃ¡fico que, efectivamente, Toyota Corolla se sitÃºa en la zona mÃ¡s alta de la variable mpg, al igual que Maserati Bora lo hace en la parte de valores muy altos de hp y en la de valores muy bajos de qsec (recuerde que las flechas indican la direcciÃ³n de crecimiento) En la secciÃ³n siguiente usaremos el biplot para mostrar los resultados de otros mÃ©todos de detecciÃ³n de outliers.

## MÃ©todos basados en distancias: LOF

Los mÃ©todos estadÃ­sticos tienen como finalidad proporcionar garantÃ­a estadÃ­stica de que los valores etiquetados como outliers efectivamente lo son. Para ello, presuponen que los datos siguen una distribuciÃ³n estadÃ­stica concreta. Sin embargo, en las situaciones en las que este requisito no se cumple, no podemos aplicar dichos mÃ©todos. En estos casos, vamos a aplicar otros mÃ©todos que no ofrecen garantÃ­a estadÃ­stica, pero son capaces de determinar cÃ³mo de alejado estÃ¡ cada punto al resto de los datos. Para ello, se usa una medida de distancia que, mientras no digamos lo contrario, serÃ¡ la distancia euclÃ­dea. Para que unas variables no dominen sobre otras tendremos que, obligatoriamente, normalizar los datos. Nosotros usaremos la normalizaciÃ³n por z-score. De los mÃ©todos basados en distancia, aplicaremos uno de los mÃ¡s conocidos: LOF

En primer lugar, debemos determinar el nÃºmero de vecinos mÃ¡s cercanos que usaremos en el cÃ³mputo del mÃ©todo LOF (consulte las transparencias de clase) A falta de mÃ¡s informaciÃ³n, elegimos arbitrariamente el valor de 5. Llamamos a la funciÃ³n lofactor de la librerÃ­a DMwR pasÃ¡ndole como parÃ¡metro el conjunto de datos numÃ©ricos, una vez normalizados (recuerde que era datos.num.norm):
```{r}
num.vecinos.lof = 5
lof.scores = lofactor(datos.num.norm, k = num.vecinos.lof)
```

La funciÃ³n lofactor asigna un score a cada dato, indicando hasta quÃ© punto es un outlier. Ordenamos dicho vector de forma decreciente y mostramos en un grÃ¡fico los scores correspondientes. Nos debe salir lo siguiente: