---
title: "Practica"
author: "Ignacio Vellido"
date: "12/22/2020"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    toc: true
    highlight: github
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)

library(ggplot2)   # Gr?ficos
library(fitdistrplus)  # Ajuste de una distribución -> denscomp 
library(reshape)   # melt
library(ggbiplot)  # biplot
library(tidyverse)   
library(outliers)  # Grubbs
library(MVN)       # mvn: Test de normalidad multivariante  
library(CerioliOutlierDetection)  #MCD Hardin Rocke
library(mvoutlier) # corr.plot 
library(DMwR)      # lof
library(cluster)   # PAM
library(R.matlab)   # Read .mat files
```

```{r include=FALSE}
# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada

###########################################################################
# Funciones utilizadas a lo largo del curso
###########################################################################

# rm(list=ls()) 


###########################################################################
# Realiza un plot de todos los registros
# Permite cambiar el color con el que se visualiza un conjunto de registros. 
# Los registros que se muestran con otro color se especifican en el par?metro
# claves.a.mostrar 

plot_2_colores = function (datos, 
                           claves.a.mostrar, 
                           titulo = "",
                           colores = c("black", "red")){
  
  num.datos = nrow(as.matrix(datos))
  seleccionados =  rep(FALSE, num.datos)
  seleccionados[claves.a.mostrar] = TRUE
  colores.a.mostrar = rep(colores[1], num.datos)
  colores.a.mostrar [seleccionados] = colores[2]
  
  plot(datos, col=colores.a.mostrar, main = titulo)
}



###########################################################################
# Funci?n an?loga a son_outliers_IQR, salvo que devuelve un vector
# de claves en vez de un vector de bools

claves_outliers_IQR = function(datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  son.outliers.IQR = son_outliers_IQR(datos, ind.columna, coef)
  return (which(son.outliers.IQR  == TRUE))
}



###########################################################################
# Calcula los outliers IQR con respecto a una columna 
# Devuelve un vector de bools indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a la columna ind.columna
# coef es 1.5 para los outliers normales y hay que pasarle 3 para los outliers extremos

son_outliers_IQR = function (datos, ind.columna, coef = 1.5){
  columna.datos = datos[,ind.columna]
  cuartil.primero = quantile(columna.datos)[2]  
  #quantile[1] es el m?nimo y quantile[5] el m?ximo.
  cuartil.tercero = quantile(columna.datos)[4] 
  iqr = cuartil.tercero - cuartil.primero
  extremo.superior.outlier = (iqr * coef) + cuartil.tercero
  extremo.inferior.outlier = cuartil.primero - (iqr * coef)
  son.outliers.IQR  = columna.datos > extremo.superior.outlier |
    columna.datos < extremo.inferior.outlier
  return (son.outliers.IQR)
}


###########################################################################
# Calcula los outliers IQR con respecto a ALGUNA columna
# Devuelve un vector de claves indicando si el registro i-?simo 
# de datos es o no un outlier IQR con respecto a ALGUNA columna
# coef es 1.5 para los outliers normales y  3 para los outliers extremos

claves_outliers_IQR_en_alguna_columna = function(datos, coef = 1.5){
  df.clave.columnas = data.frame()
  claves.outliers =  sapply(1:ncol(datos), 
                               function(x) claves_outliers_IQR(datos, x, coef)
  )
  claves.outliers.en.alguna.columna = unlist(claves.outliers)
  return (claves.outliers.en.alguna.columna)
}




#######################################################################
# Devuelve los nombres de aquellas filas especificadas en el par?metro claves
# filas es un vector de bools 

nombres_filas = function (datos, claves) {
  num.claves = length(claves)
  nombres.filas = row.names(as.data.frame(datos))[claves]
  
  return (nombres.filas)
}




#######################################################################
# funci?n base para diag_caja_outliers_IQR y diag_caja

diag_caja_grafico_base = function(datos, indice.columna){
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  nombre.columna = colnames(datos)[indice.columna]
  ggboxplot = ggplot(data = as.data.frame(datos), 
                     aes(x=factor(""), 
                         y = datos[,indice.columna]) , 
                     environment = environment()) + 
              xlab(nombre.columna) + ylab("") 
  return (ggboxplot)
}

#######################################################################
# Muestra un diagrama de caja
# Calcula los outliers IQR y los muestra como puntos en rojo en un BoxPlot

diag_caja_outliers_IQR = function (datos, ind.columna, coef.IQR = 1.5){
  # Si quisi?semos l?neas horizontales en los l?mites de las cajas
  # habr?a que a?adir 
  # + stat_boxplot(geom = 'errorbar')   
  
   outliers.IQR = son_outliers_IQR(datos, ind.columna, coef = coef.IQR)
   ggboxplot =  diag_caja_grafico_base(datos, ind.columna) + 
                stat_boxplot(coef = coef.IQR) +
                geom_boxplot(coef = coef.IQR, outlier.colour = "red") 
                # Importante: geom_boxplot debe ir despu?s de stat_boxplot
   
   return (ggboxplot)
}



#######################################################################
# Muestra un diagrama de caja
# Tambi?n muestra las etiquetas de los registros indicados en 
# el par?metro claves.a.mostrar 

diag_caja = function (datos, ind.columna, claves.a.mostrar = c()){
  num.filas = nrow(datos)
  num.claves = length(claves.a.mostrar)
  nombres.filas = vector (mode = "character", length = num.filas)
  nombres.filas = rep("", num.filas)
  nombres.claves = nombres_filas(datos, claves.a.mostrar)

  for (i in num.claves)
    nombres.filas[claves.a.mostrar[i]]  = nombres.claves[i]
  

  ggboxplot = diag_caja_grafico_base(datos, ind.columna) + 
    geom_boxplot(outlier.shape = NA) + # Para que no imprima los outliers IQR calculados dentro del mismo geom_boxplot
    geom_text(aes(label = nombres.filas)) 
  
  return (ggboxplot)
}






#######################################################################
# Muestra de forma conjunta todos los diagramas de caja de las variables de datos
# Para ello, normaliza previamente los datos.
# Tambi?n muestra las etiquetas de los registros indicados en claves.a.mostrar
# Requiere reshape

diag_caja_juntos = function (datos, titulo = "", claves.a.mostrar = c()){  
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  
  # Para hacerlo con ggplot, lamentablemente hay que construir antes una tabla 
  # que contenga en cada fila el valor que a cada tupla le da cada variable 
  # -> paquete reshape->melt
  
  # Por ejemplo, si tenemos el siguiente data frame
  
  # datos = data.frame(
  #   A = c(1, 2),
  #   B = c(3, 4)
  # )
  # datos =
  #     A  B
  #     1  3
  #     2  4
  
  # melt(datos) construye esta tabla:
  
  #      variable value
  # 1        A     1
  # 2        A     2
  # 3        B     3
  # 4        B     4
  
  
  nombres.de.filas = nombres_filas (datos, claves.a.mostrar)
  
  datos = scale(datos)
  datos.melted = melt(datos)
  colnames(datos.melted)[2]="Variables"
  colnames(datos.melted)[3]="zscore"
  factor.melted = colnames(datos.melted)[1]
  columna.factor = as.factor(datos.melted[,factor.melted])
  levels(columna.factor)[!levels(columna.factor) %in% nombres.de.filas] = ""  
  
  ggplot(data = datos.melted, 
         aes(x=Variables, y=zscore), 
         environment = environment()) + 
    ggtitle(titulo) + 
    geom_boxplot(outlier.shape = NA) + 
    geom_text(aes(label = columna.factor), size = 3) 
}






#######################################################################
# Muestra un biplot del conjunto de datos
# Se muestran los nombres de los registros indicados en claves.a.mostrar
# El color usado para dichos registros es el segundo del par?metro colores
# El t?tulo para el grupo de dichos registros es el especificado en titulo.grupo.a.mostrar
# El par?metro titulo especifica el t?tulo principal del gr?fico

biplot_2_colores = function (datos, 
                             claves.a.mostrar = c(), 
                             titulo = "",
                             titulo.grupo.a.mostrar = "Outliers",
                             colores = c("black","red")){
  nombres = rownames(datos)
  claves.datos = c(1:nrow(datos))
  son.a.mostrar = claves.datos %in% claves.a.mostrar
  nombres[!son.a.mostrar] = ''

  PCA.model = princomp(scale(datos))
  outlier.shapes = c(".","x") 
  biplot = ggbiplot(PCA.model,
                    obs.scale = 1,
                    var.scale = 1 ,
                    varname.size = 5,
                    groups =  son.a.mostrar,
                    alpha = 1/2) #alpha = 1/10
  biplot = biplot + labs(color = titulo.grupo.a.mostrar)
  biplot = biplot + scale_color_manual(values = colores)
  biplot = biplot + geom_text(label = nombres,
                              stat = "identity",
                              size = 3,
                              hjust=0,
                              vjust=0)
  biplot = biplot + ggtitle(titulo)
}



#######################################################################
# Muestra un biplot de un conjunto de datos diferenciados por color
# El color lo determina la asignaci?n de cada dato a un cluster 
# Las asignaciones de datos a cluster se indican en asignaciones.clustering
# Tambi?n se muestran los outliers cuyas claves vienen indicadas en claves.outliers
 
biplot_outliers_clustering = function(datos, 
                                      titulo = "Outliers por el m?todo de Clustering", 
                                      titulo.color = "Asignaciones Clustering",
                                      titulo.outlier = "Outliers",
                                      asignaciones.clustering,
                                      claves.outliers){
  son.outliers = rep(FALSE, nrow(datos))
  son.outliers[claves.outliers] = TRUE
  
  bip = biplot_colores_formas(datos, 
                              titulo, titulo.color, titulo.outlier,
                              asignaciones.clustering,
                              son.outliers,
                              claves.outliers)
  bip 
}

#######################################################################
# Muestra un biplot del conjunto de datos
# Los datos se muestran diferenciados por color y por forma
# Las asignaciones de cada dato a su color y forma vienen dadas por los vectores
# asignaciones.colores y asignaciones.formas 
# Tambi?n se muestran las etiquetas de los registros indicados
# en el par?metro opcional claves.a.mostrar 

biplot_colores_formas = function (datos, 
                                  titulo, titulo.color = '', titulo.forma = '', 
                                  asignaciones.colores, asignaciones.formas,
                                  claves.a.mostrar = c()){
  PCA.model = princomp(scale(datos))
  
  son.a.mostrar = rep(FALSE, nrow(datos))
  son.a.mostrar[claves.a.mostrar] = TRUE
  nombres.a.mostrar = rownames(datos)
  nombres.a.mostrar[!son.a.mostrar] = ''

  asignaciones.colores = factor(asignaciones.colores)
  asignaciones.formas  = factor(asignaciones.formas)

  
  bip = ggbiplot(PCA.model, obs.scale = 1, var.scale=1 , varname.size = 3, alpha = 0) +              
    geom_point(aes(shape = asignaciones.formas, colour = asignaciones.colores))  +
    labs(shape = titulo.forma) +
    labs(colour = titulo.color) +
    ggtitle(titulo) +
    geom_text(label = nombres.a.mostrar, stat = "identity", size = 3, hjust=0, vjust=0)      
  
  bip
}

#######################################################################
# Calcula las distancias de cada dato al centroide de su cluster
# Las asignaciones de cada dato a su cluster se indican en asignaciones.clustering
# Cada centroide es una fila del data frame datos.centroides.normalizados

distancias_a_centroides = function (datos.normalizados, 
                                    asignaciones.clustering, 
                                    datos.centroides.normalizados){
  
  sqrt(rowSums(   (datos.normalizados 
                   - 
                   datos.centroides.normalizados[asignaciones.clustering,])^2  ))
}


#######################################################################
# Revierte la funci?n de normalizaci?n (z-score)

desnormaliza = function(datos, filas.normalizadas){
  medias        = colMeans(datos)
  desviaciones  = apply(datos, 2, sd , na.rm = TRUE)
  
  filas.desnormalizadas  = sweep(filas.normalizadas, 2, desviaciones, "*")
  filas.desnormalizadas  = sweep(filas.desnormalizadas, 2, medias, "+")
  
  filas.desnormalizadas 
}




top_clustering_outliers = function(datos.norm, 
                                   asignaciones.clustering, 
                                   datos.centroides.norm, 
                                   num.outliers){
  
  dist_centroides = distancias_a_centroides (datos.norm, 
                                             asignaciones.clustering, 
                                             datos.centroides.norm)
  
  claves = order(dist_centroides, decreasing=T)[1:num.outliers]
  
  list(distancias = dist_centroides[claves]  , claves = claves)
}
```

# Dataset y Selección de Variables

Vamos a usar el conjunto de datos ``wine``, un dataset orientado a la clasificación multiclase de vinos en base a 13 atributos. Estos atributos miden diferentes características químicas, siendo las siguientes:

1) Alcohol
2) Malic acid
3) Ash
4) Alcalinity of ash
5) Magnesium
6) Total phenols
7) Flavanoids
8) Nonflavanoid phenols
9) Proanthocyanins
10) Color intensity
11) Hue
12) OD280/OD315 of diluted wines
13) Proline

Todos las variables on numéricas y miden la cantidad encontrada de cada componente.
En nuestro caso ignoraremos la clase de prediccion y las etiquetas de valores anómalos proporcionadas en el dataset. 
(HACER COMPARATIVA AL FINAL CON LAS ETIQUETAS)

Referencias:
http://odds.cs.stonybrook.edu/wine-dataset/
https://archive.ics.uci.edu/ml/datasets/Wine

```{r}
datos <- readMat("./wine.mat") %>% as.data.frame()
nombres <- c("Alcohol", "Malic", "Ash", "Alcalinity", "Mag", "Phenols", "Flavanoids", "Non-flava", "Proantho", "Color", "Hue", "OD280", "Proline", "Anomaly")
colnames(datos) <- nombres

head(datos)
```

```{r}
# Nos guardamos las etiquetas de si es o no un outlier
etiquetas <- datos[,ncol(datos)]

# Y nos quedamos con las variables numéricas
datos.num <- datos[1:ncol(datos)-1]
```


Medidas estadísticas
```{r}
summary(datos.num)
```

Todas contienen valores reales por lo que no eliminamos ninguna más

Finalmente, eliminamos todas aquellas filas que tengan algún valor nulo (NO HABÍA):
```{r}
datos.num <- na.omit(datos.num)
```

# Detección de outliers en una dimensión
## Outliers IQR

Los métodos IQR teóricamente solo se deben aplicar a distribuciones normales, pero también pueden funcionar si la forma de la distribución no es rara (multimodal, uniforme...).

Mostramos histograma de cada variable
```{r}
par(mfrow = c(2,3))
c(1:ncol(datos.num)) %>% sapply(function(x) hist(datos.num[,x], 
                                                 main="", 
                                                 xlab=names(datos.num)[x]))
```

En general la mayoría de variables parecen seguir distribuciones no muy raras, excepto en X.12 que parece ser bimodal.

Comprobamos normalidad con el test de Shapiro
Lo hacemos aunque haya posibles outliers, solo es para hacernos una idea de si las variables que hemos visto que más se parecen son rechazadas por un test estadístico (posiblemente lo harían por outliers IQR)
```{r}
print("Shapiro test, p-values:")
sapply(datos.num, function(x) {
  shapiro.test(x)$p.value}
)
```

Puesto que en este apartado no vamos a usarlas todas, elegimos las que más se asemejan a una normal, o al menos, las que el test de Shapiro no puede asegurar que no son normales.
Por tanto, nos quedamos con X.8, Alcalinity, X.3, X.1 -> Definitivamente, Alcalinity, la que tiene el p-value más alto
```{r}
indice.columna <- 4
columna        <- datos.num[, indice.columna]
nombre.columna <- names(datos.num) [indice.columna]
```

### Obtención de los outliers IQR

Calculamos los cuartiles
```{r}
cuartil.primero <- quantile(columna, .25, names = F)
cuartil.tercero <- quantile(columna, .75, names = F)
iqr <- IQR(columna)
```

```{r}
cat("Q1: ")
cuartil.primero
cat("\nQ3: ")
cuartil.tercero
cat("\nIQR: ")
iqr
```

Calulamos los extremos
```{r}
extremo.superior.outlier.IQR <- cuartil.tercero + 1.5 * iqr
extremo.inferior.outlier.IQR <- cuartil.primero - 1.5 * iqr
extremo.superior.outlier.IQR.extremo <- cuartil.tercero + 3 * iqr
extremo.inferior.outlier.IQR.extremo <- cuartil.primero - 3 * iqr
```

```{r}
extremo.superior.outlier.IQR
extremo.inferior.outlier.IQR
extremo.superior.outlier.IQR.extremo
extremo.inferior.outlier.IQR.extremo
```


Construimos vectores lógicos indicando si cada instancia es o no un outlier (normal o extremo)
```{r}
son.outliers.IQR <- columna < extremo.inferior.outlier.IQR | columna > extremo.superior.outlier.IQR
son.outliers.IQR.extremos <- columna < extremo.inferior.outlier.IQR.extremo | columna > extremo.superior.outlier.IQR.extremo
```

```{r}
head(son.outliers.IQR)
head(son.outliers.IQR.extremos)
sum(son.outliers.IQR)
sum(son.outliers.IQR.extremos)
```

### Índices y valores de los outliers IQR
```{r}
son.outliers.IQR     = son_outliers_IQR(datos.num, indice.columna)
# head(son.outliers.IQR)

claves.outliers.IQR  = claves_outliers_IQR(datos.num, indice.columna)
claves.outliers.IQR

df.outliers.IQR <- datos.num[claves.outliers.IQR,]
df.outliers.IQR
# nombres.outliers.IQR <- row.names(df.outliers.IQR) 
# valores.outliers.IQR <- columna[claves.outliers.IQR]

son.outliers.IQR.extremos    = son_outliers_IQR(datos.num, indice.columna, 3)
# head(son.outliers.IQR.extremos)

claves.outliers.IQR.extremos = claves_outliers_IQR(datos.num, indice.columna, 3)
claves.outliers.IQR.extremos
```

```{r}
# claves.outliers.IQR
# nombres.outliers.IQR
# valores.outliers.IQR
```

### Desviación de los outliers con respecto a la media de la columna

Si partimos de una variable X cuya distribución no es normal, el método de z-score no obtiene una N(0,1), pero si la distribución de X no es demasiado rara, los datos que así obtengamos nos darán información útil sobre si los registros son usuales o no. Para ilustrarlo, apliquemos el método z-score a la variable mpg. Para ello, usamos la función scale:

```{r}
datos.num.norm = scale(datos.num)
head(datos.num.norm)

columna.norm   = datos.num.norm[, indice.columna]
```

Obtenemos los valores normalizados de los outliers
```{r}
valores.outliers.IQR.norm <- columna.norm[claves.outliers.IQR]

valores.outliers.IQR.norm
```

<!-- Son muy grandes, no? Estan por encima del 99% de lo que sería una normal -->

Vamos a ver ahora el comportamiento de los outliers en la columna seleccionada con respecto al resto de columnas. Para ello, basta con seleccionar los datos correspondientes del conjunto de datos normalizado. En nuestro caso, sólo tenemos un outlier IQR en la columna seleccionada. Nos debe salir lo siguiente:

```{r}
datos.num.norm.outliers.IQR <- datos.num.norm[claves.outliers.IQR,]

datos.num.norm.outliers.IQR
```

<!-- ANALIZAR -->

### Gráfico

Mostramos en un gráfico los valores de los registros respecto a diferentes variables.
```{r}
# plot_2_colores(datos.num.norm[], claves.outliers.IQR)
plot_2_colores(datos.num.norm[,c(4,1)], claves.outliers.IQR)
plot_2_colores(datos.num.norm[,c(4,3)], claves.outliers.IQR)
```

<!-- Con las variables X.1 y Alcalinity se nota como se alejan de la distribución -->

<!-- No tenemos extremos -->

### Diagrama de cajas

```{r}
diag_caja_outliers_IQR(datos.num.norm, 4)
```

```{r}
diag_caja(datos.num.norm, 4, claves.outliers.IQR)
```

En todas las variables
```{r}
diag_caja_juntos(datos.num, "Outliers", claves.outliers.IQR)
```
Vemos que solo la instancia 11 no tiene un valor anormal en al menos un par de variales

## Test de hipótesis

Ya hicimos el test de Shapiro anteriormente, pero podemos ver de forma gráfica que la distribución de la variable elegida 
```{r}
ajusteNormal = fitdist(columna , "norm")
denscomp(ajusteNormal,  xlab = nombre.columna)
```

### Test de Grubs

Sabiendo que la distribución se asemeja a una normal, podemos hacer el test de Grubs sobre el valor más alejado de la media, que sabemos que es ??:
```{r}
test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)
test.de.Grubbs$p.value
```

<!-- El p-value es > 0.05, por lo que el test no puede rechazar. Así pues, aunque Toyota Corolla tiene un valor alto en mpg, no podemos deducir que realmente sea un outlier desde el punto de vista estadístico. -->

NO HACE FALTA PORQUE SABEMOS QUE LA INSTANCIA QUE ES
```{r}
# valor.posible.outlier = outlier(columna)
# valor.posible.outlier
```

```{r}
# es.posible.outlier = outlier(columna, logical = TRUE)
# clave.posible.outlier = which( es.posible.outlier == TRUE)
# clave.posible.outlier
```

### Test de Normalidad

```{r}
#######################################################################
# Aplica el test de Grubbs sobre la columna ind.col de datos y devuelve una lista con:

# nombre.columna: Nombre de la columna datos[, ind.col]
# clave.mas.alejado.media: Clave del valor O que está más alejado de la media
# valor.mas.alejado.media: Valor de O en datos[, ind.col]
# nombre.mas.alejado.media: Nombre de O en datos
# es.outlier: TRUE/FALSE dependiendo del resultado del test de Grubbs sobre O
# p.value:  p-value calculado por el test de Grubbs
# es.distrib.norm: Resultado de aplicar el test de Normalidad 
#    de Shapiro-Wilks sobre datos[, ind.col]
#    El test de normalidad se aplica sin tener en cuenta el 
#    valor más alejado de la media (el posible outlier O)
#    TRUE si el test no ha podido rechazar
#       -> Sólo podemos concluir que los datos no contradicen una Normal
#    FALSE si el test rechaza 
#       -> Los datos no siguen una Normal

# Requiere el paquete outliers

test_Grubbs = function(datos, ind.col, alpha = 0.05) {
  columna <- datos[,ind.col]
  res <- list()
  
  # Nombre columna
  res$nombre.columna <- colnames(datos)[ind.col]
    
  # Búsqueda del outlier
  es.posible.outlier <- outlier(columna, logical = TRUE)
  
  res$clave.mas.alejado.media <- which(es.posible.outlier == TRUE)
  res$valor.mas.alejado.media <- outlier(columna)
  res$nombre.mas.alejado.media <- rownames(datos)[res$clave.mas.alejado.media]
  
  # Test de Grubbs
  test.de.Grubbs = grubbs.test(columna, two.sided = TRUE)

  res$es.outlier <- ifelse(test.de.Grubbs$p.value <= alpha, TRUE, FALSE)
  res$p.value <- test.de.Grubbs$p.value

  # Test de normalidad
  test.Normalidad <- shapiro.test(columna[-res$clave.mas.alejado.media])
  res$es.distrib.norm <- ifelse(test.Normalidad$p.value > alpha, TRUE, FALSE)
  
  res
}
```

```{r}
test.Grubbs.datos.num = test_Grubbs(datos.num, indice.columna)

test.Grubbs.datos.num
```
Hacemos notar que al eliminar el outlier al calcular el estadístico de normalidad ahora nos rechaza
<!-- POR QUÉ? -->

## Trabajando con varias columnas

### Outliers IQR

Empezamos con los outliers IQR: vamos a calcular los outliers IQR con respecto a cada una de las columnas. El conjunto de ellos nos dará aquellos registros que son outliers con respecto a alguna columna.
```{r}
claves.outliers.IQR.en.alguna.columna =
  claves_outliers_IQR_en_alguna_columna(datos.num, 1.5)

claves.outliers.IQR.en.mas.de.una.columna = 
  unique(
    claves.outliers.IQR.en.alguna.columna[
      duplicated(claves.outliers.IQR.en.alguna.columna)])
claves.outliers.IQR.en.alguna.columna = 
  unique (claves.outliers.IQR.en.alguna.columna)


claves.outliers.IQR.en.mas.de.una.columna
claves.outliers.IQR.en.alguna.columna 
```

Vamos a ver los valores normalizados de algunos de estos outliers:
```{r}
datos.num.norm[claves.outliers.IQR.en.alguna.columna,] %>% head() %>% as.data.frame()
```

De forma gráfica (como hay muchos cogemos unos pocos)
```{r}
diag_caja_juntos(datos.num.norm, "Outliers en alguna columna", claves.outliers.IQR.en.alguna.columna)
# diag_caja_juntos(datos.num.norm, "Outliers en alguna columna", claves.outliers.IQR.en.alguna.columna %>% head())
```

Notamos valores extremadamente altos en Mg y la instancia 11 que parece tener bajas cantidades de múltiples elementos (Alcalinity, Ash, Proantho...)


### Test de Hipótesis

Test de Grubs
```{r}
par(mfrow = c(2,3))
datos.num %>% apply(2, function(col) {
  ajusteNormal = fitdist(col, "norm")
  denscomp (ajusteNormal,  xlab = "")
})
```

Deberíamos quitar la variable 12 pues parece bimodal
La 2, 10, 13
Ante la duda, también la 8?
```{r}
# QUITAR VARIABLE 12
datos.num.reducidos <- datos.num[,-c(2,8,10,12,13)]
```


<!-- ?? -->
```{r}
sapply(1:ncol(datos.num.reducidos), test_Grubbs, datos=datos.num)
```

# Outliers Multivariantes

## Métodos estadísticos basados en la distancia de Mahalanobis

Para que un par de variables siga una distribución normal conjunta ambas deben estar normalmente distribuídas de forma indiviual.
Como el test de normalidad nos deja solo una (Ash), y para poder hacer el apartado, reducidos el nivel de significación a 0.025 para obtener otra variable más (esto no)
```{r}
test <- sapply(1:ncol(datos.num), test_Grubbs, datos=datos.num)
# test <- sapply(1:ncol(datos.num), test_Grubbs, alpha=0.025, datos=datos.num)
son.col.normales <- apply(test, 2, function(x) {
  x$es.distrib.norm
})
datos.num.distrib.norm = datos.num[,son.col.normales]

son.col.normales
head(datos.num.distrib.norm)
```













