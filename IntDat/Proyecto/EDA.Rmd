---
title: "EDA"
author: "Ignacio Vellido"
date: "11/13/2020"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    df_print: paged
---

```{r setup, include=FALSE}
# Para PDF output
# pdf_document: 
#     keep_tex: yes
#     df_print: kable

knitr::opts_chunk$set(echo = TRUE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)
library(tidyverse)
library(ggplot2)
library(cowplot)  # plot_grid
library(corrplot) # corr y corrplot
library(reshape2) # melt
library(dlookr) # normality
library(caret)  # preprocess
library(moments)  # skewness
library(car)  # scatterplotMatrix
library(MASS) # fit
# library(ISLR)
# library(HSAUR2)
# library(vcdExtra)
# library(cepp)
# library("dslabs")
```

# Intro
Para este trabajo contamos con dos datasets distintos: __autoMPG6__ para aplicar Regresión y __haberman__ para aplicar Clasificación.

## Descripciones de los problemas

### autoMPG6

http://lib.stat.cmu.edu/datasets/cars.desc

Este dataset codifica el consumo de gasolina de distintos coches (en millas por galón, Mpg) en base a las siguientes características:

1. Displacement: Indica la cilindrada del coche, la suma del volumen útil de los cilindros del motor, medido en pulgadas cúbicas.
2. Horse_power: Mide la potencia del coche.
3. Weight: Peso en libras.
4. Acceleration: Aceleración del coche de 0 a 60 millas por hora, medido en segundos.
5. Model_year: Indica las dos últimas cifras del año de producción.


El objetivo es poder predecir, en base a los cinco atributos, el consumo Mpg de un nuevo coche:

6. Mpg: Millas-por-galón, indica la cantidad de galones (1G ≈ 3,78L) de fuél que consume un vehículo al recorrer una milla (1m ≈ 1,6km).


El dataset contiene 392 instancias codificanto esta información.

---------------------------------------------------------------------------------------------------------------------

# Análisis Estadístico de Datos

### autoMPG6

La descripción del problema nos da alguna información adicional sobre las variables:

1. Displacement: Variable numérica continua, contamos con valores reales en el rango [68.0,455.0].
2. Horse_power: Variable numérica continua, contamos con valores enteros en el rango [46,230].
3. Weight: Variable numérica continua, contamos con valores enteros en el rango [1613,5140].
4. Acceleration: Variable numérica continua, contamos con valores reales en el rango [8.0,24.8].
5. Model_year: Variable numérica discreta, contamos con valores enteros en el rango [70,82].
6. Mpg: Variable numérica continua, contamos con valores reales en el rango [9.0,46.6].


#### Hipótesis de partida

- H.1: Horse_power puede influir en Mpg: A más potencia, más consumo.
- H.2: Weight debe influir en Mpg: Un coche más pesado debería consumir más.
- H.3: Debería haber correlación entre displacement (cilindrada) con horse y acceleration
- H.4: Horse y acceleration podrían estar relacionadas
- H.5: Viendo que contamos con un rango pequeño de años, no debería haber un cambio significativo de prestaciones entre años 
- H.6: Pero debería existir una tendencia de mejora de prestaciones con los años, incluyendo aumento de Displacement, Horse_power y Acceleration.
- H.7: Model_year podría no mostrar relación con Mpg: Pese al paso de los años si contamos con diferentes tipos de vehículos (todoterrenos, familiares, deportivos...) podría haber un consumo dispar. (Si existiera tendencia, viendo que los años son de las últimas décadas del siglo XX, podría ir el consumo hacia abajo)
- H.8: Esta última hipótesis se puede aplicar al resto de variables, indicándonos que Model_year no debería tener relevancia para este problema de regresión.
- H.9: Horse_power podría depender de las variables Displacement y Weight

---------------------------------------------------------------------------------------------------------------------

Cargamos los datos:
```{r}
names <- c("Displacement", "Horse_power", "Weight", "Acceleration", "Model_year", "Mpg")

auto <- read_csv("Data/autoMPG6/autoMPG6.dat", comment = "@", col_names = names)
```

Antes de comenzar a analizar las variables nos plantemos una cuestión:
¿Debemos considerar Model_year como una variable numérica o como un factor categórico?
Aunque por la hipótesis H.7 podríamos acabar no eligiendo la variable para el problema, es necesario plantearse esta cuestión antes de comenzar.

Sabemos que las observaciones para esta variable cuenta con valores entre 72 y 82, por lo que sabemos que tenemos información exacta del año (en comparación, por ejemplo, con la década).
El hecho de tratarla como categórica o quantitativa depende mucho del problema.
En este caso, tenemos interés en cuestionarnos por valores entre años, por ejemplo, el consumo entre los años 75 y 76 (por otro lado, no tenemos información más precisa para los meses dentro del año)

En un principio, el dataset está planteado para regresión, por lo que tendríamos dos opciones:
- Mantenerlo como categórico y generar variables dummy (Valores 0-1 para indicar si la instancia es de ese año). Suponiendo que tenemos al menos una instancia de cada año, esto nos generaría 12 variables nuevas.
- Mantenerlo como numérico, pero teniendo cuidado de cómo interpretar el año. 

Proseguimos con tanto dejando Model_year como variable numérica.

#### Análisis univariable

```{r}
head(auto)
```

Hacemos summary para sacar datos de relevancia
```{r}
summary(auto)
```

El dataset no cuenta con valores repetidos
```{r}
sum(duplicated(auto))
```

Ni missing values
```{r}
sum(is.na(auto))
```

Vamos a sacar plots de cada variable para verlo mejor
```{r}
ggplot(gather(auto), aes(value)) +
  geom_histogram(bins = 15, color="white") +
  facet_wrap(~key, scales = 'free_x') +
  theme_light() +
  theme(strip.background = element_rect(fill="grey", size=2))+
  theme(strip.text = element_text(colour = 'black')) +
  labs(title="Histogramas de cada variable", x = "")
```
Una a una
```{r}
colors <- c("chocolate", "deepskyblue1", "plum1", "hotpink4", "orange", "springgreen4")
bins <- c(10,10,15,15,14,18)
plt <- list(length = length(names))

for (i in 1:length(names)) {
  ggplot(auto, aes_string(x=names[i])) + 
    geom_histogram(aes(y=..density..), bins=bins[i], color="white", fill=colors[i]) +
    geom_density(alpha=.3, fill="black", size=1) +
    labs(title="", x="", y="") +
    theme_light() -> plt[[i]]
  
  print(plt[[i]] + labs(title=sprintf("%s", names[i]), x=""))
}

plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
```

```{r}
colors <- c("chocolate", "deepskyblue1", "plum1", "hotpink4", "orange", "springgreen4")
bins <- c(10,10,15,15,14,18)
plt <- list(length = length(names))

for (i in 1:length(names)) {
  ggplot(auto, aes_string(x=names[i])) + 
    geom_boxplot(fill = colors[i]) +
    labs(title="", x="", y="") +
    theme_light() -> plt[[i]]
  
  print(plt[[i]] + labs(title=sprintf("%s", names[i]), x=""))
}

plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
```

Podemos comparar los rangos intercuartiles si estandarizamos antes el dataset
```{r}
scale(auto) %>% apply(2, IQR)
```

También podemos ver la distancia entre mínimos y máximos
```{r}
scale(auto) %>% apply(2, range) %>% apply(2, dist)
```

##### Displacement:

(coger los plots de la variable sola)

La cilindrada vemos con una desviación grande y una gran concentración en los valores inferiores.
Desviado a la izquierda, no parece seguir una distribución normal.
Existe una alta concentración en torno al valor 125, muy por encima del recuento que alcanzan el resto de valores 

#### Horse_power

Similar a Displacement pero cuenta con una mayor dispersión y algunos valores muya altos. A día de hoy los coches suelen rondar los 120 en turismos y los 200 en SUVs. Aquí contamos con predominancia en el rango aproximado [70, 125] con algunas instancias por encima de los 200.
Desviado a la izquierda, no parece seguir una distribución normal.

#### Weight

Una distribución más achatada que las anteriores, también ladeada hacia la izquierda.
Un rango mayor 

#### Acceleration

Valores altamentes concentrados pero en general con un rango alto.
Parece seguir una distribución normal.

#### Model_year

Aunque no se vea bien en las gráficas, contammos con valores de todos los años, más o menos equitativamente
```{r}
table(auto$Model_year)
```


--------------------------------------------------------------------------------

### Análisis sobre las distribuciones

Hemos comentado antes que no apreciamos semejanzas con una distribución normal en algunas de las variables, lo comprobamos con un test estadístico (Shapiro-Wilk test):
```{r}
normality(auto) %>% filter(p_value < 0.05)
```
El test de Shapiro nos dice que ninguna variable sigue una distribución normal, con bastante certeza excepto en Acceleration.

Se muestra aquí como no hay que dejarse engañar por los gráficos, puesto que Acceleration parecía seguirla.
El p-value de Acceleration está muy cerca del umbral (0.03 vs 0.05). Es bastante probable de que la parte central derecha de la distribución sea la causante de no asegurar la normalidad.

Vamos a mostrarlo con gráficos Q-Q para verlo mejor:
```{r}
colors <- c("chocolate", "deepskyblue1", "plum1", "hotpink4", "orange", "springgreen4")
bins <- c(10,10,15,15,14,18)
plt <- list(length = length(names))

x<-rnorm(100, mean=0, sd=1)

for (i in 1:length(names)) {
  ggplot(auto, aes_string(sample=names[i])) + 
    stat_qq(alpha=.3, fill=colors[i], size=1) +
    stat_qq_line() +
    labs(title="", x="", y="") +
    theme_light() -> plt[[i]]
  
  print(plt[[i]] + labs(title=sprintf("%s", names[i]), x=""))
}

plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
```

Estos gráficos Q-Q nos muestran más claramente que las variables no siguen distribuciones normales.
La distribución de Acceleration es la que más se asemeja y eso lo vemos en el estadístico de Shapiro, pero en la cola superior existe una diferencia significativa que hace que el test rechace.

La variable Mpg parece seguir una distribución "exponencial" ??
```{r}
# ggplot(auto, aes(sample=Mpg)) + 
#     stat_qq(alpha=.3, size=1) +
#     stat_qq_line(distribution = stats::qchisq, dparams=(df=1)) +
#     labs(title="", x="", y="") +
#     theme_light()
```

Skewness:
```{r}
skewCols <- find_skewness(auto)
colnames(auto)[skewCols]
```


```{r}
cat("Displacement: ")
skewness(auto$Displacement)
cat("Horse_power: ")
skewness(auto$Horse_power)
cat("Weight: ")
skewness(auto$Weight)
cat("Mpg: ")
skewness(auto$Mpg)
```
Sobre la skewness, tal y como se había visto en las gráficas, algunas de las variables la tienen, en los 3 casos positivas (hacia la izquierda).

Los plots nos han dado idea de que Mpg tiene cierta skewness, pero cae por debajo del umbral de 0.5.

-------------------------------------------------------------

### Transformaciones

Las transformaciones necesarias para normalizar una distribución dependen de la variable en cuestion.
Primero debemos averiguar que tipo de distribución siguen.

Algunas parecen tener una distribución exponencial

<!-- Para normalizarlas podemos usar el paqueta carret, de forma que nos ajuste las variables a una distribución normal de media cero y desviación típica 1 -->

<!-- (Scale + center es estandarizar) -->
```{r}
# auto_transform <- preProcess(auto[,skewCols], method=c("YeoJohnson"))
# auto_norm <- predict(auto_transform, auto[,skewCols])

# auto_transform <- preProcess(auto[,1:6], method=c("scale", "center"))
auto_transform <- preProcess(auto[,1:6], method=c("YeoJohnson","scale", "center"))
# transform the dataset using the parameters
auto_norm <- predict(auto_transform, auto[,1:6])

summary(auto_norm)
```

Para la variable Acceleration aplicando una transformación de YeoJohnson es suficiente.

Aunque para regresión no es absolutamente necesario, podemos estandarizar los datos a media 0 y dev 1, facilitando un poco los cálculos. La inferencia estadística de la regresión no va a variar, por lo que es conveniente hacerlo.
Haciendo esto debemos tener cuidado a la hora de interpretar los resultados de la regresión para no confundirnos.

------------------------------

<!-- Algunas variables parecen seguir una distribución exponencial, lo comprobamos: -->
```{r}
# auto %>% apply(2, function(c) {
#   fit <- fitdistr(c, "exponential") 
# 
#   # goodness of fit test
#   ks.test(c, "pexp", fit$estimate) # p-value > 0.05 -> distribution not refused
# })
# 
# auto %>% apply(2, function(c) {
#   fit <- fitdistr(c, "chi-squared", start=list(df=3),method="Brent",lower=0.1,upper=100) 
# 
#   # goodness of fit test
#   # ks.test(c, "pexp", fit$estimate) # p-value > 0.05 -> distribution not refused
#   ks.test(c,pchisq,df=10)
# })


# hist(auto$Displacement, freq = FALSE, breaks = 100, xlim = c(0, quantile(auto$Displacement, 0.99)))
# curve(dexp(x, rate = fit1$estimate), from = 0, col = "red", add = TRUE)
```



<!-- Vamos a demostrar que las variables están normalizadas: -->
```{r}
# normality(auto_norm) %>% filter(p_value < 0.05)
```


```{r}
# colors <- c("chocolate", "deepskyblue1", "plum1", "hotpink4", "orange", "springgreen4")
# bins <- c(10,10,15,15,14,18)
# plt <- list(length = length(names))
# 
# x<-rnorm(100, mean=0, sd=1)
# 
# for (i in 1:length(names)) {
#   ggplot(auto_norm, aes_string(sample=names[i])) + 
#     stat_qq(alpha=.3, fill=colors[i], size=1) +
#     stat_qq_line() +
#     labs(title="", x="", y="") +
#     theme_light() -> plt[[i]]
#   
#   print(plt[[i]] + labs(title=sprintf("%s", names[i]), x=""))
# }
# 
# plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
```


```{r}
# shapiro.test(auto_norm$Acceleration)
# 
# ggplot(auto_norm, aes(sample=Acceleration)) +
#     stat_qq(alpha=.3, size=1) +
#     stat_qq_line() +
#     labs(title="", x="", y="") +
#     theme_light()

# colors <- c("chocolate", "deepskyblue1", "plum1", "hotpink4", "orange", "springgreen4")
# bins <- c(10,10,15,15,14,18)
# plt <- list(length = length(names))
# 
# for (i in 1:length(names)) {
#   ggplot(auto, aes_string(x=names[i])) + 
#     geom_histogram(aes(y=..density..), bins=bins[i], color="white", fill=colors[i]) +
#     geom_density(alpha=.3, fill="black", size=1) +
#     # labs(title=sprintf("%s", names[i]), x="") +
#     labs(title="", x="", y="") +
#     theme_light() -> plt[[i]]
#   
#   print(plt[i])
# }
# 
# plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
# 
# 
# # QQ-plots
# 
# x<-rnorm(100, mean=0, sd=1)
# 
# for (i in 1:length(names)) {
#   ggplot(auto_norm, aes_string(sample=names[i])) + 
#     stat_qq(alpha=.3, fill=colors[i], size=1) +
#     stat_qq_line() +
#     labs(title="", x="", y="") +
#     theme_light() -> plt[[i]]
#   
#   print(plt[i])
# }
# 
# plot_grid(plotlist=plt, ncol=2, labels = names, label_size = 8)
```

-----------------------------------------------------------

### Análisis de correlación

Tenemos que tener en cuenta que las variables no siguen distribuciones normales.
Aunque el coeficiente de Pearson no asume normalidad (si asume varianza y covarianza finitas), podemos usar el coeficiente de Kendall para los cálculos.
Independientemente del método usado vamos a obtener las mismas correlaciones en este dataset, solo varía la fuerza con la que se dan.
<!-- Las variables no siguen distribución normal, pero no pasa nada, Pearson no da problemas -->

Corrplot
```{r}
corrplot.mixed(cor(auto), tl.pos="lt", upper="color", title="Pearson")
corrplot.mixed(cor(auto, method="kendall"), tl.pos="lt", upper="color", title="Kendall")
```

Estas gráficas nos dicen que existe una alta correlación en el dataset, generalmente entre todas las variables (a excepción de Model_year), pero extremadamente fuerte en las parejas:

1. Horse_power & Displacement
2. Weight & Displacement
3. Weight & Horse_power
4. Acceleration & Horse_power
5. Mpg & Horse_power
6. Mpg & Displacement
7. Mpg & Weight

```{r}
scatterplotMatrix(auto, pch=20, col="deepskyblue")
```
El scatterplot anterior nos muestra mejor la forma de estas correlaciones.
Vemos que en todos los casos en los que se da una correlación positiva existe una tendencia lineal entre los datos de ambas variables, y en las negativas una tendencia logarítmica.

Vamos a mostrar algunas
Positivas
```{r}
ggplot(auto, aes(x=Horse_power, y=Displacement)) +
  geom_point() +
  geom_smooth(formula = y~x, method=glm) +
  theme_light()

ggplot(auto, aes(x=Weight, y=Displacement)) +
  geom_point() +
  geom_smooth(formula = y~x, method=glm) +
  theme_light()
```

Negativas
```{r}
ggplot(auto, aes(x=Displacement, y=Mpg)) +
  geom_point() +
  geom_smooth(formula = y~log(x), method=glm) +
  theme_light()

ggplot(auto, aes(x=Weight, y=Mpg)) +
  geom_point() +
  geom_smooth(formula = y~log(x), method=glm) +
  theme_light()
```

Previsualicación de las variables respecto a la salida
```{r}
ggplot(melt(auto, "Mpg"), aes(x=value, y=Mpg, color=variable)) +
  geom_point(alpha=0.3) +
  facet_wrap(.~variable, scale="free") +
  theme_light()
```
Se aprecia alta correlación entre Displacement, Horse_power, Weight respecto de la salida.

Como habíamos supuesto en la hipótesis H.9, Horse_power podría depender de Displacement y Weight.
Esta claro que la potencia de un motor va a depender de la cilindrada y el peso que tenga.

```{r}
auto %>%
  dplyr::select(Displacement, Horse_power, Weight) %>%  
  scatterplotMatrix(pch=20, col="deepskyblue")
```
Podemos apreciar como la función de densidad de Horse_power parece una ("MEDIANIZACIÓN") de las otras dos.

Vamos a intentar comprobarlo
```{r}
scale(auto) %>%
  as.data.frame() %>% 
  mutate(hp = (Displacement+Weight) / 2) %>% 
  dplyr::select(Horse_power, hp) %>%  
  scatterplotMatrix(pch=20, col="deepskyblue")
```
Viendo que no son tan similares como creíamos, buscamos diferentes fórmulas para el cálculo de los caballos de vapor, y vemos que las fórmulas son un poco más complejas y no tenemos exactamente los datos necesarios para utilizarlas (no se descarta que no se puedan deducir, pero no sería un cálculo evidente)

(poner fórmulas https://www.ajdesigner.com/phphorsepower/horsepower_equation_trap_speed_method_increase_horsepower.php#:~:text=Solving%20for%20the%20change%20in,the%20vehicle%2C%20driver%20and%20passenger.)

---------------------------------------------------------------------------

### Tratamiento de variables

Para este dataset, al ser casi todas las variables numéricas continuas, existen pocos tratamientos que aplicar.

No tenemos variables categóricas que transformar.


Para añadir interpretabilidad, podríamos agrupar la variable Weight en intervalos, pero puesto que vamos a aplicar regresión sería más conveniente realizarlo con los resultados finales.

--------------------------------------------------------------------------

### Ordenaciones

Volvemos a mostrar la cabecera de los datos:
```{r}
head(auto)
```

En este caso no es necesario aplicar ninguna reorganización.
Cada variable ocupa su propia columna, y contiene un único tipo de información, con unidades de observación diferentes
No existe ninguna relación entre variables sobre la información que codifican (en el sentido de que podrían agruparse).

<!-- Column headers are values, not variable names. -->
<!-- • Multiple variables are stored in one column. -->
<!-- • Variables are stored in both rows and columns. -->
<!-- • Multiple types of observational units are stored in the -->
<!-- same table. -->
<!-- • A single observational unit is stored in multiple tables. -->

--------------------------------------------------------------------------

#### Resolución de hipótesis

Nos habíamos planteado las siguientes hipótesis

- H.1: Horse_power puede influir en Mpg: A más potencia, más consumo.
```{r}
ggplot(auto, aes(x=Horse_power, y=Mpg)) +
  geom_point() +
  geom_smooth(formula = y~log(x), method=glm) +
  theme_light()
```
Con el plot y los resultados de la matriz de correlación queda claro que existe una correlación negativa entre estas dos variables.
Por tanto, podemos considerar Horse_power como un buen candidato para la regresión

- H.2: Weight debe influir en Mpg: Un coche más pesado debería consumir más
idem. a la hipótesis anterior, lo hemos visto anteriormente en la figura X

- H.3: Debería haber correlación entre displacement (cilindrada) con horse y acceleration
La hemos referenciado anteriormente

- H.4: Horse y acceleration podrían estar relacionadas
```{r}
ggplot(auto, aes(x=Horse_power, y=Acceleration)) +
  geom_point() +
  geom_smooth(formula = y~log(x), method=glm) +
  theme_light()
```
idem. se aprecia una correlación logarítmica entre las dos variables.
Similarmente a lo ocurrido con la hipótesis anterior, esto puede ser un problema para nuestro problema de regresión.

- H.5: Viendo que contamos con un rango pequeño de años, no debería haber un cambio significativo de prestaciones entre años.
```{r}
ggplot(melt(auto, "Model_year"), aes(y=value, x=Model_year, color=variable)) +
  geom_point(alpha=0.3) +
  facet_wrap(.~variable, scale="free") +
  theme_light()
```

Existe una alta dispersión de los datos en cada una de las variables, pero aún así se aprecia tendencias en las variables.
Acceleartion y Mpg tienden a aumentar, y Displacement, Horse_power y Weight tienden a disminuir.
También vemos que la dispersión en las prestaciones de los coches disminuyen ligeramente.

Podemos creer en principio que puede deberse a un decremento del número de instancias con el paso de los años, pero recordamos que en general los datos están repartidos equitativamente
```{r}
table(auto$Model_year)
```

Podemos ver cómo varían los rangos para cada año
```{r}
years <- auto %>% group_split(Model_year)

for (y in years) {
  cat("Year: ")
  y$Model_year[1] %>% cat()
  y %>% apply(2, range) %>% as.data.frame() %>% print()
}
```

O mejor, de manera gráfica
```{r}

```


- H.6: Pero debería existir una tendencia de mejora de prestaciones con los años, incluyendo aumento de Displacement, Horse_power y Acceleration.

Ciertamente. Se ha comprobado en la hipótesis anterior.

- H.7: Model_year podría no mostrar relación con Mpg: Pese al paso de los años si contamos con diferentes tipos de vehículos (todoterrenos, familiares, deportivos...) podría haber un consumo dispar. (Si existiera tendencia, viendo que los años son de las últimas décadas del siglo XX, podría ir el consumo hacia abajo)

Hemos visto que existe tendencia, lineal con gran dispersión, y positiva.
```{r}
ggplot(auto, aes(x=Model_year, y=Mpg)) +
  geom_point() +
  geom_smooth(formula = y~x, method=glm) +
  theme_light()
```

Por desgracia no contamos información sobre los modelos de los coches

Podemos ver como se ubican los diferentes años en un plot Horse_power vs Mpg
```{r}
ggplot(auto, aes(x=Horse_power, y=Mpg, color=Model_year)) +
  geom_point() +
  theme_light()
```

Y vemos que no se puede afirmar la hipótesis, los coches están entremezclados por diferentes años

- H.8: Esta última hipótesis se puede aplicar al resto de variables, indicándonos que Model_year no debería tener relevancia para este problema de regresión.

No podemos afirmar la hipótesis anterior y por consiguiente esta tampoco.

- H.9: Horse_power podría depender de las variables Displacement y Weight

Lo hemos comentado anteriormente

--------------------------------------------------------------------------

#### Conclusiones

Como conclusiones podemos decir que tenemos un dataset altamente correlacionado, distribuído de forma no normal pero con la información bien representada.
Existen relaciones fuertes entre las variables de entrada y de las de salida para la regresión que probablemente nos ayuden a solucionar con facilidad el problema.

A falta de descubrir las distribuciones que siguen las variables para ver si merece la pena transformarlas a una distribución normal, podemos sin ninguna duda aplicar una estandarización de los datos (puesto que sabemos que no afecta negativamente al problema de regresión), siempre y cuando lo tengamos en cuenta a la hora de analizar los resultados.

Se nos pide elegir 5 regresores para la regresión y contamos exactamente con ese número, por lo que no podemos descartar ninguna variable.
Aún así, hemos visto que tenemos algunas variables más interesentas que otras.
Varibles correladas con la salida nos aumentan las posibilidades de obtener un buen regresor, pero debemos evitar usar variables correladas entre sí para evitar la multicolinealidad. Sería conveniente evitarla para aumentar la interpretabilidad del modelo, pero la potencia en sí de este no cambia.
(https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/#:~:text=Multicollinearity%20occurs%20when%20independent%20variables,model%20and%20interpret%20the%20results.)
(referenciar esta frase en el apartado de regresión)