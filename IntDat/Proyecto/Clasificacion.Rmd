---
title: "Clasificacion"
author: "Ignacio Vellido"
date: "11/24/2020"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    df_print: paged
---

```{r setup, include=FALSE}
# Para PDF output
# pdf_document: 
#     keep_tex: yes
#     df_print: kable

knitr::opts_chunk$set(echo = TRUE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)
library(tidyverse)
library(ggplot2)
library(cowplot)  # plot_grid
library(corrplot) # corr y corrplot
library(reshape2) # melt
library(dlookr) # normality
library(caret)  # preprocess
library(moments)  # skewness
library(car)  # scatterplotMatrix
library(MASS) # fit
library(scatterplot3d)
# library(stats)  # barlett
# require(vcd)
# library(ISLR)
# library(HSAUR2)
# library(vcdExtra)
# library(cepp)
# library("dslabs")

set.seed(111)
```


Cargamos los datos
```{r}
names <- c("Age", "Year", "Positive", "Survival")

haberman <- read_csv("Data/haberman/haberman.dat", comment = "@", col_names = names)
haberman$Survival <- haberman$Survival %>% factor(levels = c("negative", "positive"), labels = c("No", "Yes"))
```

Los preprocesamos (estandarización)
```{r}
haberman_transform <- preProcess(haberman, method=c("scale", "center"))
haberman_norm <- predict(haberman_transform, haberman)
```


Creamos holdout del 90%
```{r}
# Create training and test data (holdout 90%-10%)
shuffle_ds <- sample(dim(haberman_norm)[1])

pct90 <- (dim(haberman_norm)[1] * 90) %/% 100

train <- haberman_norm[shuffle_ds[1:pct90], -4] %>% as.data.frame()
test <- haberman_norm[shuffle_ds[(pct90+1):dim(haberman_norm)[1]], -4] %>% as.data.frame()
```


Separamos los datos de las etiquetas
```{r}
train_labels <- haberman[shuffle_ds[1:pct90], 4] %>% unlist()
test_labels <- haberman[shuffle_ds[(pct90+1):dim(haberman)[1]], 4] %>% unlist()
```

--------------------------------------------------------------------------------

## Utilizar el algoritmo k-NN probando con diferentes valores de k. Elegir el que considere más adecuado para su conjunto de datos. Analice qué ocurre en los valores de precisión en training y test con los diferentes valores de k.

Recordamos los gráficos 1-1 con las clasificaciones, vistos en el EDA.
```{r}
haberman %>%
  ggplot(aes(x=Age, y=Year, color=Survival)) +
    geom_point() +
    labs(title="Plot Age-Year con su Survival") +
    theme_light()

haberman %>%
  ggplot(aes(y=Age, x=Positive, color=Survival)) +
    geom_point() +
    labs(title="Plot Age-Year con su Survival") +
    theme_light()

haberman %>%
  ggplot(aes(x=Year, y=Positive, color=Survival)) +
    geom_point() +
    labs(title="Plot Age-Year con su Survival") +
    theme_light()
```

```{r}
colors <- c("coral2", "deepskyblue")
colors <- colors[haberman$Survival]

scatterplot3d(haberman[,1:3], angle = 290,
              main = "3D plot",
              pch=20, color = colors)

scatterplot3d(haberman[,1:3], angle = 50,
              main = "3D plot",
              pch=20, color = colors)
```

De cara a un algoritmo KNN, apreciamos los datos muy entremezclados, con mayor tendencia a agruparse los no supervivientes que los que sí, pero nada que nos llame la atención.

Debido a esto vamos a empezar con un valor de K relativamente bajo y vamos a ir aumentándolo poco a poco.
Tenemos que tener cuidado con el overfitting, eso sí.

```{r}
knnModel <- train(train, y = train_labels,
                  method = "knn", 
                  trControl = trainControl(method = "cv"), 
                  tuneGrid = data.frame(.k=3:15))

knnModel
```

Recordamos que los datos ya estaban previamente preprocesados (estandarizados, concretamente)

```{r}
knnPred <- predict(knnModel, newdata = test)
ctable <- table(knnPred, test_labels)

ctable
postResample(pred = knnPred, obs = test_labels)
```

```{r}
fourfoldplot(ctable, color = c("#CC6666", "#99CC99"), std = "all.max",
             conf.level = 0, margin = 1, main = "Confusion Matrix KNN")
```
Vemos que al estar los datos tan entremezclados ni siquiera con un K pequeño sobreaprende, es ya con un K medianamente alto (= 13) donde obtiene mayor accuracy en train.

(HABLAR MÁS, DESCRIBIR KNN, ALGO)

```{r}
ggplot(train, aes(x = Age, y = Year, color=predict(knnModel, newdata = train))) +
  geom_point(show.legend = F) +
  labs(title="Prediction KNN") +
  theme_light() -> knnplot

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point() +
  labs(title="True values") +
  theme_light() -> trueplot

# Get legend
legend <- get_legend(trueplot)

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point(show.legend = F) +
  labs(title="True values") +
  theme_light() -> trueplot

plot_grid(plotlist=list(knnplot,trueplot,legend), ncol=2, label_size = 1)
```

Vemos que el uso de un K alto hace que perdamos puntos de Yes. Probablemente al ser minoría el error cometido clasificándolos como No es menor y por eso obtiene mejor accuracy.

--------------------------------------------------------------------------------

## Utilizar el algoritmo LDA para clasificar. No olvide comprobar las asunciones.

Comprobamos asunciones:

1- Distribución aleatoria: No nos queda más remedio que creer que sí

2- Cada predictor sigue una distribución normal: Ya vimos en el EDA que esto no era cierto. El test de Shapiro nos demostraba que no y los QQ-plots nos lo hacían ver claramente.
Técnicamente sabiendo esto no deberíamos usar LDA, pero puesto que esto es un proyecto seguimos igualmente.

3- Las clases siguen la misma matriz de covarianza:
```{r}
yes <- train %>% bind_cols(train_labels) %>% setNames(names) %>% filter(Survival == "Yes") %>% dplyr::select(-Survival)
no  <- train %>% bind_cols(train_labels) %>% setNames(names) %>% filter(Survival == "No") %>% dplyr::select(-Survival)
# 
# covariance <- as.data.frame(matrix(c(var(yes$Age), var(no$Age), 
#                                      var(yes$Year), var(no$Year)), 
#                                    nrow=2, byrow = TRUE))
# colnames(covariance) <- c("Yes", "No")
# rownames(covariance) <- c("Age", "Year")
# 
# covariance

# corrplot.mixed(cov(yes, method="kendall"), tl.pos="lt", upper="color", lower.col="black", title="Kendall")
# corrplot.mixed(cov(no, method="kendall"), tl.pos="lt", upper="color", lower.col="black", title="Kendall")

# Solo nos interesa la diagonal ?
cov(yes) %>% diag()
cov(no) %>% diag()
```

Puesto que nuestras variables no siguen distribución normal, no podemos hacer el test de homogeneidad de Barlett.
Utilizamos por tanto el de Levene
```{r}
cat("Age:\n")
leveneTest(Age ~ Survival, haberman)
cat("Year:\n")
leveneTest(Year ~ Survival, haberman)
cat("Positive:\n")
leveneTest(Positive ~ Survival, haberman)
```

Indicándonos que solo se puede asegurar que la variable Positive tiene homogeneidad entre clases diferentes.

Podemos verlo más claro gráficamente
```{r}
ggplot(haberman, aes(x = Year, color = Survival, fill=Survival)) + 
  geom_boxplot(color="black") + 
  labs(title = "Varianza entre clases para Year") +
  theme_light()

ggplot(haberman, aes(x = Age, color = Survival, fill=Survival)) + 
  geom_boxplot(color="black") + 
  labs(title = "Varianza entre clases para Age") +
  theme_light()

ggplot(haberman, aes(x = Positive, color = Survival, fill=Survival)) + 
  geom_boxplot(color="black") + 
  labs(title = "Varianza entre clases para Positive") +
  theme_light()
```


Podemos mostrar las varianzas en grafors de elipses:
```{r}
ggplot(haberman, aes(x = Year, y = Age, color = Survival)) + 
  geom_point() + 
  stat_ellipse() +
  theme_light()

ggplot(haberman, aes(x = Year, y = Positive, color = Survival)) + 
  geom_point() + 
  stat_ellipse() +
  theme_light()

ggplot(haberman, aes(x = Positive, y = Age, color = Survival)) + 
  geom_point() + 
  stat_ellipse() +
  theme_light()
```

Se nota que la causa de que no se rechace el test para esta variable es la gran cantidad de datos con Positive=0

<!-- http://thatdatatho.com/2018/02/19/assumption-checking-lda-vs-qda-r-tutorial-2/ -->

Por tanto para LDA no podemos hacer uso de la variable Positive, pero sí de las otras dos.
SEGURO?

### Aplicando LDA

```{r}
ldaModel <- train(train %>% dplyr::select(-Positive), y = train_labels,
                method = "lda",
                tuneLength = 10,
                trControl = trainControl(method = "cv"))

ldaModel$finalModel
confusionMatrix(ldaModel)
```

```{r}
ldaPred <- predict(ldaModel, newdata = test)
ctable <- table(ldaPred, test_labels)

ctable
postResample(pred = ldaPred, obs = test_labels)
```

```{r}
fourfoldplot(ctable, color = c("#CC6666", "#99CC99"), std = "all.max",
             conf.level = 0, margin = 1, main = "Confusion Matrix LDA")
```


Recordamos que teníamos muchos datos de no supervivencia antes que sí
```{r}
table(haberman$Survival)
```

En training
```{r}
ggplot(train, aes(x = Age, y = Year, color=predict(ldaModel, newdata = train))) +
  geom_point(show.legend = F) +
  labs(title="Prediction LDA") +
  theme_light() -> ldaplot

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point() +
  labs(title="True values") +
  theme_light() -> trueplot

# Get legend
legend <- get_legend(trueplot)

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point(show.legend = F) +
  labs(title="True values") +
  theme_light() -> trueplot

plot_grid(plotlist=list(ldaplot,trueplot,legend), ncol=2, label_size = 1)
```


Hacemos un plot del ajuste
```{r}
data <- train %>% bind_cols(train_labels) %>% setNames(names) 
ldafit <- lda(Survival~Age+Year, data = data)
plot(ldafit)
ldafit$post
```


```{r}
x <- seq(min(train$Age), max(train$Age), length.out=dim(train)[1])
y <- seq(min(train$Year), max(train$Year), length.out=dim(train)[1])

Xcon <- matrix(c(rep(x,length(y)), rep(y, rep(length(x), length(y)))),ncol=2) #Set all possible pairs of x and y on a grid

#posterior probabilities of a point belonging to each class
out <- predict(ldafit, data.frame(Age=Xcon[,1], Year=Xcon[,2]))$post

pr <- data.frame(x=rep(x, length(y)), 
                 y=rep(y, each=length(x)), 
                 z=as.vector(out))

ggplot(data, aes(x=Age, y=Year)) +
  geom_point(size = 2, aes(pch=Survival,  col=Survival)) +
  geom_contour(data = pr, aes(x=x, y=y, z=z)) +
  theme_light()
```



--------------------------------------------------------------------------------

## Utilizar el algoritmo QDA para clasificar. No olvide comprobar las asunciones.

QDA tiene las mismas asunciones de LDA salvo que relaja la norma de que las clases tengan igual covarianza.

Por tanto tenemos que:
- Distribución aleatoria
- Distribución normal

Técnicamente el no cumplir normalidad no imposibilita que se encuentre solución, pero ya no nos lo asegura.

Además tenemos que:
- El número de predictores debe ser menor que el número de instancias de cada clase.
Cosa que sabemos que sí por la tabla Yes/No
- Los predictores dentro de cada clase no deben estar correlacionados.

```{r}
corrplot.mixed(cor(yes), tl.pos="lt", upper="color", lower.col="black", title="Pearson")
corrplot.mixed(cor(yes, method="kendall"), tl.pos="lt", upper="color", lower.col="black", title="Kendall")
```


```{r}
corrplot.mixed(cor(no), tl.pos="lt", upper="color", lower.col="black", title="Pearson")
corrplot.mixed(cor(no, method="kendall"), tl.pos="lt", upper="color", lower.col="black", title="Kendall")
```

Cosa que tampoco se da.

--------------------------------------------------------------------------------

### Aplicando QDA

```{r}
qdaModel <- train(train %>% dplyr::select(-Positive), y = train_labels,
                method = "qda",
                tuneLength = 10,
                trControl = trainControl(method = "cv"))

qdaModel$finalModel
confusionMatrix(qdaModel)
```

```{r}
qdaPred <- predict(qdaModel, newdata = test)
ctable <- table(qdaPred, test_labels)

ctable
postResample(pred = qdaPred, obs = test_labels)
```

```{r}
fourfoldplot(ctable, color = c("#CC6666", "#99CC99"), std = "all.max",
             conf.level = 0, margin = 1, main = "Confusion Matrix QDA")
```

En training
```{r}
ggplot(train, aes(x = Age, y = Year, color=predict(qdaModel, newdata = train))) +
  geom_point(show.legend = F) +
  labs(title="Prediction QDA") +
  theme_light() -> qdaplot

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point() +
  labs(title="True values") +
  theme_light() -> trueplot

# Get legend
legend <- get_legend(trueplot)

ggplot(train, aes(x = Age, y = Year, color=train_labels)) +
  geom_point(show.legend = F) +
  labs(title="True values") +
  theme_light() -> trueplot

plot_grid(plotlist=list(qdaplot,trueplot,legend), ncol=2, label_size = 1)
```


Hacemos un plot del ajuste
```{r}
data <- train %>% bind_cols(train_labels) %>% setNames(names) 
qdafit <- qda(Survival~Age+Year, data = data)
plot(qdafit)
qdafit$post
```


```{r}
x <- seq(min(train$Age), max(train$Age), length.out=dim(train)[1])
y <- seq(min(train$Year), max(train$Year), length.out=dim(train)[1])

Xcon <- matrix(c(rep(x,length(y)), rep(y, rep(length(x), length(y)))),ncol=2) #Set all possible pairs of x and y on a grid

#posterior probabilities of a point belonging to each class
out <- predict(qdafit, data.frame(Age=Xcon[,1], Year=Xcon[,2]))$post

pr <- data.frame(x=rep(x, length(y)), 
                 y=rep(y, each=length(x)), 
                 z=as.vector(out))

ggplot(data, aes(x=Age, y=Year)) +
  geom_point(size = 2, aes(pch=Survival,  col=Survival)) +
  geom_contour(data = pr, aes(x=x, y=y, z=z)) +
  theme_light()
```


--------------------------------------------------------------------------------

## Comparar los resultados de los tres algoritmos

NECESITAMOS LAS MISMAS PARTICIONES DE CV

```{r}

```