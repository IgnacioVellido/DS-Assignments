---
title: "Clasificación ordinal"
author: "Ignacio Vellido Expósito"
date: "22/01/2021"
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    df_print: paged
---

```{r setup, include=FALSE}
# Configuración RMarkdown
knitr::opts_chunk$set(echo = TRUE, results="hold", fig.align="center", 
                      comment=NA, messages=FALSE)
# Librerías
library(tidyverse)
library(tree)
```


```{r}
# Leer datos
df <- read_csv("data/esl.arff", col_names = FALSE, skip = 43)

# Cada columna es categórica ordinal
for (i in 1:(ncol(df)-1)) {
  df[[i]] <- df[[i]] %>% as.factor()
}

df
```

```{r}
# Añadir nombre de columna a las etiquetas
colnames(df)[5] <- "labels"
df
```


```{r}
# Ordenar df por etiquetas
df <- df %>% arrange(labels)
df
```


```{r}
# Función para clasificar K-1 modelos
classify <- function(df) {
    # Realizar particiones
    labels <- as.integer(unique(df$labels))
    num_part <- length(labels) - 1
    
    partitions <- vector("list", length(num_part))
    
    for(i in 1:num_part) {
      partitions[[i]] <- df
      partitions[[i]] <- partitions[[i]] %>% mutate(labels = ifelse(labels <= i, 0, 1))
      
      # Para realizar el entrenamiento, necesitamos que las etiquetas se codifiquen
      # como factores
      partitions[[i]]$labels <- partitions[[i]]$labels %>% as.factor()
    }

    # Clasificar
    models <- vector("list", length(num_part))
    for (i in 1:num_part) {
        models[[i]] <- tree(labels ~ ., data = partitions[[i]])
    }

    # Devolver modelos
    models
}
```

```{r}
# Función para calcular probabilidades reales y hacer predicciones
make_predictions <- function(models, df) {
    # Calcular probabilidades del df para un modelo
    pr_list <- lapply(models,
                function(m,r) {
                  # Solo nos interesa la segunda probabilidad, que sea > i
                  predict(m,r)[,2] %>% as.data.frame() -> x
                  x %>% mutate(row = rownames(x))
                },
                df)
    
    
    # Juntar probabilidades por filas del df
    pr_list <- reduce(pr_list, left_join, by="row")
    

    # Mover la columna auxiliar row a la primera posición
    # y llenarla con unos, preparando el cálculo de las
    # probabilidades de cada clase
    pr_list <- pr_list[, c(2,1,3:ncol(pr_list))]
    pr_list$row <- 1
    

    # Calcular probabilidades reales de cada clase
    apply(pr_list, 1, function(row) {
      probs <- vector("integer", length(row))

      for(i in 2:length(row)) {
        probs[i-1] <- row[[i-1]] * (1 - row[[i]])
      }
      
      # Probabilidad última clase
      probs[length(row)] <- row[[length(row)]]

      # Devolver probabilidad máxima (y el índice)
      # Si hay varias clases con la misma probabilidad se elige una al azar
      m  <- max(probs)
      data.frame(class=which(probs == m)[1], prob = m)
    }) %>%
      reduce(bind_rows) # Juntar en un solo dataframe
}
```


```{r}
# Aplicar las funciones a nuestro dataset
models <- classify(df)
pred <- make_predictions(models, df %>% select(-labels))

pred
```


```{r}
# Ver medidas de aciertos (sobre entrenamiento)
f1_score <- function(predicted, expected, positive.class="1") {
    res <- list()
    
    cm = as.matrix(table(expected, predicted))
    res$cm <- cm
    
    tp <- diag(cm)
    fp <- cm[lower.tri(cm)]
    fn <- cm[upper.tri(cm)]

    res$precision <- tp / (tp + fp)
    res$recall <- tp / (tp + fn)
    
    
    f1 <-  ifelse(res$precision + res$recall == 0, 0,
                  2 * res$precision * res$recall / (res$precision + res$recall))

    #Assuming that F1 is zero when it's not possible compute it
    f1[is.na(f1)] <- 0
    res$precision[is.na(res$precision)] <- 0
    res$recall[is.na(res$recall)] <- 0

    #Binary F1 or Multi-class macro-averaged F1
    res$f1 <- ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))

    res
}

df$labels <- df$labels %>% as.factor()
pred$class <- factor(x = pred$class, levels = levels(df$labels))

f1_score(pred$class, df$labels)

# Vemos que los resultados obtenidos son mayormente buenos, donde los fallos
# cometidos solo se dan una o dos clases arriba o abajo.

# Notamos que la predicción de las clases extremas (la 1 y la 9) no es en ningún
# momento correcta. Es más, las probabilidades de estas clases son tan bajas en
# cada caso que nunca se predicen.
```

