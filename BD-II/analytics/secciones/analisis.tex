\section{Análisis de resultados}

En esta sección se pretenden analizar aquellos resultados más relevantes. Algunos argumentos también se sustentan sobre las tablas completas de experimentos (con información adicional sobre ellos) que se encuentran en la sección \textit{Tablas de resultados}.

% Hay que describir detalladamente todo el proceso algorítmico utilizado, mostrando los resultados de cada uno de los algoritmos utilizados para entrenamiento y test, analizando el comportamiento, y mostrando los flujos/combinaciones de algoritmos de preprocesamiento

\vspace{\baselineskip}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|r|}
    \hline
    \textbf{Algoritmo} & \textbf{\shortstack{Selección de \\ características}} & \textbf{\shortstack{Under/Over \\ sampling}} & \multicolumn{1}{l|}{\textbf{\shortstack{Filtrado \\ de ruido}}} & \multicolumn{1}{l|}{\textbf{\shortstack{Selección de \\ instancias}}} & \textbf{\shortstack{TPR \\ x \\ TNR}} \\ \hline
    Decision Tree      & No & RUS  & HME & FCNN  & 0.606 \\ \hline
    Random Forest      & No & RUS  & HME & FCNN  & 0.607 \\ \hline
    PCARD              & -  & RUS  & No  & No    & 0.598 \\ \hline
    kNN-IS             & No & RUS  & HME & No    & 0.526 \\ \hline
    \end{tabular}
    \caption{Flujos de preprocesamiento para los mejores resultados de cada algoritmo tras la optimización de parámetros.}
    \label{final}
\end{table}

Todos los valores de TPR x TNR mostrados son calculados sobre el conjunto de test.

\subsection{Sobre las técnicas de aprendizaje}

En términos de los algoritmos de clasificación, tal y como se muestra en la tabla \ref{final}, obtenemos prácticamente la misma calidad con cualquiera de ellos (con variación de milésimas), siendo ligeramente superiores Random Forest (RF) y Árboles de Decisión (DT). Para ambas técnicas el flujo de preprocesamiento coincide, con el que se reduce el tamaño del conjunto de datos a un 10\% del tamaño original.

Mediante las tablas \ref{dt} y \ref{rf} vemos que independientemente del preprocesamiento los resultados son muy similares para las dos técnicas, probablemente debido al estar un algoritmo formado como ensamblado del otro. A pesar de esto, vemos que en media RF es más robusto con RUS mientras que DT funciona mejor con ROS.

\vspace{\baselineskip}

Sobre PCARD, aunque la calidad máxima se alcanza con las mínimas técnicas de preprocesamiento (ajustar el desbalanceo es imprescindible en este problema, y los resultados lo demuestran) no llega a ser significativamente inferior que el resto. 

Además, a partir de la tabla \ref{pcard} notamos que las técnicas NCNEdit y FCNN empeoran los resultados frente a no usar ninguna reducción de instancias. Creemos que el motivo reside en que al aplicarse PCA antes de entrenar los árboles, se pierde demasiada información al haberse reducido el conjunto de datos con los algoritmos de filtrado de ruido y reducción de instancias.
% Qué pasa con HME ??

\vspace{\baselineskip}

Respecto a kNN, notamos peor calidad en comparación con el resto independientemente de la técnica y parámetros con los que se ha probado. Sin hacer un análisis de la distribución de los datos el razonamiento no está claro, pues al ser un algoritmo basado en distancias si existiera alto entremezclado entre las instancias de ambos clases es de esperar que con los pocos valores de k que se ha probado sea insuficiente.

\newpage

\begin{table}
    \centering
    \begin{tabular}{cc|c|c|c|}
    \cline{3-5}
    \multicolumn{1}{l}{\textbf{}} & \textbf{} & \multicolumn{1}{c|}{\textbf{Average}} & \multicolumn{1}{c|}{\textbf{STD}} & \textbf{Max} \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Filtrado de ruido}}       & No        & 0.282  & 0.234
    & 0.565    \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & HME       & 0.339   & 0.226    & 0.575        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & NCNEdit   & 0.273   & 0.249    & 0.564        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de instancias}} & No        & 0.321  & 0.244    & 0.575        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & FCNN      & 0.277   & 0.219    & 0.574        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de características}} & No        & 0.328  & 0.214    & 0.593        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & PCA      & 0.252    & 0.225    & 0.584        \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Balanceo de datos}}       & No        & 0.070  & 0.092    & 0.208        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & ROS       & 0.415   & 0.229    & 0.521        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS       & 0.373   & 0.210    & 0.575        \\ \hline
    \end{tabular}
    \caption{Media de resultados de las diferentes técnicas de preprocesamiento.}
    \label{avg}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{cc|c|c|c|}
    \cline{3-5}
    \multicolumn{1}{l}{\textbf{}} & \textbf{} & \multicolumn{1}{c|}{\textbf{Average}} & \multicolumn{1}{c|}{\textbf{STD}} & \textbf{Max} \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Filtrado de ruido}}       & No        & 0.288 & 0.253
    & 0.589    \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & HME       & 0.339 &  0.231
    & 0.593        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & NCNEdit   & 0.292 &  0.255
    & 0.584        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de instancias}} & No        & 0.333  & 0.256
    & 0.597        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & FCNN      & 0.289 &  0.231
    & 0.593        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de características}} & No        & 0.341  &  0.241
    & 0.593        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & PCA      & 0.272  & 0.242
    & 0.584        \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Balanceo de datos}}       & No        & 0.066  &  0.070
    & 0.215        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & ROS       & 0.426 &  0.136
    & 0.542        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS       & 0.284 &  0.273
    & 0.593        \\ \hline
    \end{tabular}
    \caption{Efectos de las diferentes técnicas de preprocesamiento para árboles de decisión.}
    \label{dt}
\end{table}

\subsection{Sobre las técnicas de selección de características}

Como se dijo anteriormente, hemos aplicado PCA únicamente a los algoritmos donde tiene sentido, pero podemos ver a partir de la tabla \ref{avg} y la de cada algoritmo que los resultados empeoran tras su uso.

\vspace{\baselineskip}

Hacemos notar que PCARD se comporta mejor que los árboles de decisión con PCA, a pesar de acabar teniendo un flujo similar. El razonamiento lo achacamos a la discretización aleatoria (RD) de PCARD, que elige un tamaño de intervalos mejor que el de 32 con el que se han entrenado los árboles.

\vspace{\baselineskip}

A pesar de todo, podríamos considerar si la reducción de dimensionalidad conseguida es aceptable a costa de esa cantidad de empeoramiento. En este problema, pasando de una media de 0,593 a 0,584, que corresponde a una clasificación errónea de $593.000 - 584.000 = 9.000$ instancias más, dada la semántica del problema no parece una pérdida substancial. Si por otro caso tratáramos con un problema médico habría que considerar independientemente el TPR y el TNR antes de aceptar esta conclusión.

\vspace{\baselineskip}

Por otro lado, hemos aplicado ChiSquareSelector sobre los mejores resultados de DT y RF (sobre kNN no ya que es un método basado en distancias y para aplicar ChiSq era necesario realizar una discretización de las variables continuas). 

Los resultados, mostrados en la tabla \ref{chisq}, nos indican una variación tanto por arriba como por abajo únicamente de milésimas, pero en media superiores a su equivalente con PCA (probablemente por la discretización). Aun así, puesto que la alteración en TPR x TNR es mínima, reincidimos en las conclusiones anteriores, añadiendo que además al haber reducido dimensionalidad hemos formado árboles más simples y, por tanto, más interpretables.

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|r|}
    \hline
    \textbf{\shortstack{Algoritmo}} & \textbf{\shortstack{Under/Over \\ sampling}} & \multicolumn{1}{l|}{\textbf{\shortstack{Filtrado \\ de ruido}}} & \multicolumn{1}{l|}{\textbf{\shortstack{Selección de \\ instancias}}} & \textbf{\shortstack{TPR x TNR}} \\ \hline
    \multicolumn{1}{|c|}{\multirow{4}{*}{DT}} & RUS  & HME      & FCNN  & 0.592 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS  & HME      & No    & 0.595 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS  & NCNEdit  & No    & 0.586 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS  & No       & No    & 0.590 \\ \hline
    \multicolumn{1}{|c|}{\multirow{4}{*}{RF}} & RUS  & HME      & FCNN  & 0.593 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}   & RUS  & HME      & No    & 0.596 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}   & RUS  & No       & No    & 0.594 \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}   & RUS  & NCNEdit  & No    & 0.594 \\ \hline
    \end{tabular}
    \caption{Resultandos combinando ChiSquareSelector con diferentes métodos de preprocesamiento en árboles de decisión y random forest.}
    \label{chisq}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{cc|c|c|c|}
    \cline{3-5}
    \multicolumn{1}{l}{\textbf{}} & \textbf{} & \multicolumn{1}{c|}{\textbf{Average}} & \multicolumn{1}{c|}{\textbf{STD}} & \textbf{Max} \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Filtrado de ruido}}       & No        & 0.239  & 0.250
    & 0.583    \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & HME       & 0.294  & 0.238
    & 0.587        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & NCNEdit   & 0.222  & 0.252
    & 0.585        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de instancias}} & No        & 0.278   & 0.257
    & 0.585        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & FCNN      & 0.224  & 0.229
    & 0.587        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de características}} & No        & 0.316  &  0.258
    & 0.587        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & PCA      & 0.187   & 0.211
    & 0.511        \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Balanceo de datos}}       & No        & 0.039  & 0.184
    & 0.196        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & ROS       & 0.353  & 0.273
    & 0.532        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS       & 0.362  & 0.179
    & 0.587        \\ \hline
    \end{tabular}
    \caption{Efectos de las diferentes técnicas de preprocesamiento para Random Forest.}
    \label{rf}
\end{table}

\subsection{Sobre las técnicas de balanceo de datos}

No solo RUS ayuda a acelerar la tarea de aprendizaje, también nos da los mejores resultados. Aún así, en media vemos que se comporta peor que ROS, debido probablemente a que su combinación con técnicas de selección de instancias reduce en algunos casos de manera excesiva el conjunto de datos.

\subsection{Sobre las técnicas de reducción de ruido}

Los resultados dan a entender de que el dataset no es de por sí bastante ruidoso, y el posible ruido introducido por las otras técnicas no resulta influyente. No por ello dejamos de apreciar que HME ayuda en la obtención de los mejores valores de TPR x TNR y funciona mejor en este dataset que NCNEdit.

\subsection{Sobre las técnicas de reducción de instancias}

Vemos que el uso de FCNN apenas altera los resultados, pero no por ello deja de ser útil, pues aplica una reducción en torno al 50\% del conjunto de datos. En una situación de big data como la que nos encontramos esto es totalmente deseable, ya que reducimos tiempo de cómputo y carga en el sistema.

\vspace{\baselineskip}

Finalmente, indicamos que aunque la técnica SSMA sobrepasa el límite de 4GB de memoria impuesto en la práctica, en base a las dos ejecuciones con las que contamos (de los primeros días cuando el límite estaba en 46GB) vemos que la reducción en el número de instancias es extremadamente grande, llegando a obtener subconjuntos de 12.000 y 20.000 instancias.
A pesar de ello en este caso los resultados sí son bastante inferiores respecto a FCNN o no aplicar nada, por lo que concluímos que su uso no es positivo en este conjunto de datos.

\begin{table}
    \centering
    \begin{tabular}{cc|c|c|c|}
    \cline{3-5}
    \multicolumn{1}{l}{\textbf{}} & \textbf{} & \multicolumn{1}{c|}{\textbf{Average}} & \multicolumn{1}{c|}{\textbf{STD}} & \textbf{Max} \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Filtrado de ruido}}       & No        & 0.309   & 0.273
    & 0.597        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & HME       & 0.369   &  0.241
    & 0.595        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & NCNEdit   & 0.286   &  0.290
    & 0.593        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de instancias}} & No        & 0.362   & 0.268
    & 0.597        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & FCNN      & 0.281   & 0.252
    & 0.595        \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Balanceo de datos}}       & No        & 0.072   & 0.076
    & 0.186        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & ROS       & 0.496   & 0.325
    & 0.542        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS       & 0.397   & 0.220
    & 0.597        \\ \hline
    \end{tabular}
    \caption{Efectos de las diferentes técnicas de preprocesamiento para PCARD.}
    \label{pcard}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{cc|c|c|c|}
    \cline{3-5}
    \multicolumn{1}{l}{\textbf{}} & \textbf{} & \multicolumn{1}{c|}{\textbf{Average}} & \multicolumn{1}{c|}{\textbf{STD}} & \textbf{Max} \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Filtrado de ruido}}       & No        & 0.292  & 0.159
    & 0.491    \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & HME       & 0.354   & 0.193
    & 0.525        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & NCNEdit   & 0.294  & 0.200
    & 0.492        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de instancias}} & No        & 0.313    &  0.195
    & 0.525        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & FCNN      & 0.313   &  0.165
    & 0.521        \\ \hline
    \multicolumn{1}{|c|}{\multirow{2}{*}{Selección de características}} & No        & 0.328    & 0.177
    & 0.525        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & PCA      & 0.299   & 0.188
    & 0.516        \\ \hline
    \multicolumn{1}{|c|}{\multirow{3}{*}{Balanceo de datos}}       & No        & 0.103     &  0.038
    & 0.235        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & ROS       & 0.386  & 0.180
    & 0.432        \\ \cline{2-5} 
    \multicolumn{1}{|c|}{}  & RUS       & 0.448  & 0.167
    & 0.525        \\ \hline
    \end{tabular}
    \caption{Efectos de las diferentes técnicas de preprocesamiento para kNN.}
    \label{knn}
\end{table}

\subsection{Algunas conclusiones generales}

% Objetivamente la calidad de los resultados es bastante superior a la baseline (cuánto ?), pero no por ello un tanto bajas. La práctica se ha enfocado en evaluar las diferentes combinaciones de técnicas (independientemente del resultado obtenido ?REALLY?). Una posible forma de mejorar sería un ajuste mayor de los hiperparámetros ???

\begin{itemize}
    \item La reducción de datos en problemas de big data es esencial. Debemos transformar el dataset en un conjunto manejable y representativo de forma que aprovechemos el tiempo y recursos disponibles al máximo.
    \item Lo mismo es aplicable a la selección de características, y debemos tener en cuenta que una mejora no es solo útil por el valor en la métrica que alcance, sino además por la reducción de complejidad que puede obtener. 

    También debemos tener en cuenta la simplificación de los modelos y resultados obtenidos, que suele ser indicio de una mayor generalización.

    \item No existe un único flujo de preprocesamiento para todos los algoritmos, dependerá del funcionamiento de cada técnica de aprendizaje para sacar el máximo potencial. Por ejemplo, el ruido es más influyente en kNN, donde en base al valor de k puede cambiar radicalmente la clase predicha, que en una técnica basada en árboles, donde la poda ayudará a generalizar.
    \item En algunos casos es más interesante reconsiderar y mejorar el flujo de preprocesamiento que optimizar una y otra vez los hipérparametros del algoritmo. Hemos visto mejoras de 2 o 3 milésimas cambiando los parámetros frente a mejoras en las decenas con flujos diferentes.
    
    No por ello hay que ignorar la etapa de optimización, pero resulta más eficiente aplicarla en último lugar.
\end{itemize}