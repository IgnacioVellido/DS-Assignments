{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"},"colab":{"name":"guionII.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"xL2GY7b7KHKF"},"source":["Ignacio Vellido Exp√≥sito"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdCV-g8BMIkO","executionInfo":{"status":"ok","timestamp":1616169788089,"user_tz":-60,"elapsed":27393,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"6b09d8d9-bd42-42f6-9152-90d23f23b50d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3_DvmXUKFOy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169747677,"user_tz":-60,"elapsed":4122,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"7b060132-1b2d-427e-c375-47d1694ac6b6"},"source":["################################################################################\n","# Libraries\n","################################################################################\n","\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Import layers\n","from keras import Sequential\n","from keras.layers import Dense\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Import the metrics from `sklearn.metrics`\n","from sklearn.metrics import r2_score\n","\n","################################################################################\n","\n","# Basic libraries\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"SyvdW1W6J5fx","executionInfo":{"status":"ok","timestamp":1616169814282,"user_tz":-60,"elapsed":2629,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"02b49de6-a954-4b74-adf1-9a88f5136b6c"},"source":["################################################################################\n","# Load data\n","################################################################################\n","\n","# Read in white wine data \n","white = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsc/winequality-white.csv', sep=';')\n","\n","# Read in red wine data \n","red = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsc/winequality-red.csv', sep=';')\n","\n","# Add `type` column to `red` with value 1\n","red['type'] = 1\n","\n","# Add `type` column to `white` with value 0\n","white['type'] = 0\n","\n","# Append `white` to `red`\n","wines = red.append(white, ignore_index=True)\n","\n","wines.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n","0            7.4              0.70         0.00             1.9      0.076   \n","1            7.8              0.88         0.00             2.6      0.098   \n","2            7.8              0.76         0.04             2.3      0.092   \n","3           11.2              0.28         0.56             1.9      0.075   \n","4            7.4              0.70         0.00             1.9      0.076   \n","\n","   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n","0                 11.0                  34.0   0.9978  3.51       0.56   \n","1                 25.0                  67.0   0.9968  3.20       0.68   \n","2                 15.0                  54.0   0.9970  3.26       0.65   \n","3                 17.0                  60.0   0.9980  3.16       0.58   \n","4                 11.0                  34.0   0.9978  3.51       0.56   \n","\n","   alcohol  quality  type  \n","0      9.4        5     1  \n","1      9.8        5     1  \n","2      9.8        5     1  \n","3      9.8        6     1  \n","4      9.4        5     1  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"14tWI3RtJ5gC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169836723,"user_tz":-60,"elapsed":722,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"9a842f74-aa3f-4503-ea36-99828d10c6cb"},"source":["################################################################################\n","# Train-test split\n","################################################################################\n","\n","# Specify the data\n","X = wines.iloc[:,0:12]\n","X = wines.drop('quality', axis=1) \n","\n","# Isolate target labels\n","#Y = wines.quality\n","Y = np.ravel(wines.quality)\n","\n","################################################################################\n","# Preprocessing data\n","################################################################################\n","\n","# Scale\n","X_train = StandardScaler().fit_transform(X)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n","  return self.partial_fit(X, y)\n","/usr/local/lib/python2.7/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n","  return self.fit(X, **fit_params).transform(X)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5n8uUr_J5gG","executionInfo":{"status":"ok","timestamp":1616154368188,"user_tz":-60,"elapsed":47335,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"61876d9b-d537-4af5-af9e-612c1c61b4ab"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 60\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(64, input_dim=12, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 60\n","MSE:    0.482037309573\n","MAE:    0.538521635532\n","R2:     0.367790048708\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TDrO2ouAM9ro"},"source":["Recoged los resultados anteriores en una tabla donde se indiquen los par√°metros, resultados y m√©tricas estudiados hasta el momento. Realizar estas ejecuciones para un n√∫mero mayor de iteraciones del algoritmo (por ejemplo 20, 30, 40, 50‚Ä¶) ver qu√© ocurre. Comentar conclusiones\n","\n","---\n","- Epochs: 10\n","- MSE:    0.524755685232\n","- MAE:    0.560977721214\n","- R2:     0.311729921596\n","---\n","- Epochs: 20\n","- MSE:    0.493214635154\n","- MAE:    0.543776381016\n","- R2:     0.353146244269\n","---\n","- Epochs: 30\n","- MSE:    0.478757350902\n","- MAE:    0.535899412632\n","- R2:     0.37209407945\n","---\n","- Epochs: 40\n","- MSE:    0.486252702039\n","- MAE:    0.543345427513\n","- R2:     0.362256719249\n","---\n","- Epochs: 50\n","- MSE:    0.479456772399\n","- MAE:    0.538513040543\n","- R2:     0.371175519533\n","---\n","- Epochs: 60\n","- MSE:    0.482037309573\n","- MAE:    0.538521635532\n","- R2:     0.367790048708\n","\n","---\n","\n","Conclusiones:\n","- Tenemos que fijarnos en las mil√©simas para observar diferencias.\n","Vemos que a partir de las 30 √©pocas comienza el sobreaprendizaje, a partir de ah√≠ el error comienza a fluctuar.\n","\n","- Respecto a la calidad en s√≠ de los resultados, los valores de MAE nos indican que el margen de error es peque√±o (equivocaci√≥n de medio punto arriba/abajo en la nota otorgada). \n","- A pesar de esto, los valores de R2 se ven bajos, aunque los resultados con clasificaci√≥n del gui√≥nI nos demonstraron que el problema es dif√≠cil de resolver (un tanto menor para regresi√≥n, puesto que la ausencia de datos de otras clases no penaliza de la misma forma)\n"]},{"cell_type":"code","metadata":{"id":"gpr6MeGzVdOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616170663213,"user_tz":-60,"elapsed":12133,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"07d5e969-cb57-4952-d184-4ba761c30d9e"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 10\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(64, input_dim=12, activation='relu'),\n","        Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 10\n","MSE:    0.551292880071\n","MAE:    0.578412055969\n","R2:     0.277023550101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z4wg1mHfVdmg"},"source":["a) Agregar m√°s capas. Probemos a a√±adir m√°s capas. Realizar la ejecuci√≥n con diferentes n√∫meros de capas y construir una tabla con los resultados. Mantened por el momento el mismo n√∫mero de neuronas, ya que veremos el resultado de cambiar el n√∫mero de las neuronas posteriormente. Construir una tabla con los par√°metros y m√©tricas utilizadas. Comentad los resultados y sacar conclusiones\n","\n","---\n","2 capas\n","\n","- Epochs: 10\n","- MSE:    0.551292880071\n","- MAE:    0.578412055969\n","- R2:     0.277023550101\n","\n","   \n","\n","- Epochs: 30\n","- MSE:    0.484528051438\n","- MAE:    0.539175724983\n","- R2:     0.36452036291\n","\n","   \n","\n","- Epochs: 50\n","- MSE:    0.505928785927\n","- MAE:    0.553491330147\n","- R2:     0.336542270749\n","\n","    \n","\n","- Epochs: 70\n","- MSE:    0.54414904517\n","- MAE:    0.564422738552\n","- R2:     0.286345643744\n","\n","---\n","3 capas\n","\n","- Epochs: 10\n","- MSE:    0.527808886028\n","- MAE:    0.563948392868\n","- R2:     0.307706186006\n","\n","    \n","\n","- Epochs: 30\n","- MSE:    0.517176227956\n","- MAE:    0.558221280575\n","- R2:     0.321760622194\n","\n","   \n","\n","- Epochs: 50\n","- MSE:    0.499126830202\n","- MAE:    0.540626513958\n","- R2:     0.345356619835\n","\n","---\n","4 capas\n","\n","- Epochs: 10\n","- MSE:    0.528152155888\n","- MAE:    0.56595979929\n","- R2:     0.307404602014\n","\n","   \n","\n","- Epochs: 30\n","- MSE:    0.548689993182\n","- MAE:    0.570972287655\n","- R2:     0.280310372135\n","\n","   \n","- Epochs: 50\n","- MSE:    0.512767980628\n","- MAE:    0.546047878265\n","- R2:     0.327576749344\n","\n","   \n","- Epochs: 60\n","- MSE:    0.55087068926\n","- MAE:    0.563467502594\n","- R2:     0.277443898965\n","---\n","\n","Conclusiones:\n","- El entrenamiento correcto depende totalmente de la arquitectura.\n","- Modelos con m√°s capas/unidades tienen a sobreajustar m√°s f√°cilmente."]},{"cell_type":"code","metadata":{"id":"qzzh-TRUVg6w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616171262049,"user_tz":-60,"elapsed":40048,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"13a5cf60-af92-4be0-96d3-0ddddbe57d1e"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 45\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(32, input_dim=12, activation='relu'),\n","        # Dense(128, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 45\n","MSE:    0.488181700038\n","MAE:    0.541019487381\n","R2:     0.35970041305\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mYtJl_ruVhUk"},"source":["Agregar m√°s unidades ocultas. Partiendo de la configuraci√≥n de una √∫nica capa y posteriormente de varias capas, probad con diferente n√∫mero de neuronas. Construir una tabla que recoja tanto los par√°metros utilizados, como las m√©tricas y resultados. Comentad los resultados y sacar conclusiones.\n","\n","---\n","1 capa, 128 unidades\n","\n","- Epochs: 30\n","- MSE:    0.476496205197\n","- MAE:    0.533239984512\n","- R2:     0.375050078186\n","\n","\n","- Epochs: 40\n","- MSE:    0.481751763494\n","- MAE:    0.541328597069\n","- R2:     0.368188363539\n","\n","---\n","2 capas, 128-64 unidades\n","\n","- Epochs: 30\n","- MSE:    0.505831441966\n","- MAE:    0.549794638157\n","- R2:     0.336568751678\n","    \n","\n","- Epochs: 40\n","- MSE:    0.496979997832\n","- MAE:    0.551348042488\n","- R2:     0.348121680966\n","\n","---\n","2 capas, 128-128 unidades\n","\n","- Epochs: 30\n","- MSE:    0.49993821629\n","- MAE:    0.545240473747\n","- R2:     0.344293806024\n","\n","   \n","- Epochs: 40\n","- MSE:    0.495013412726\n","- MAE:    0.545667314529\n","- R2:     0.350746151389\n","\n","---\n","1 capa, 32 unidades\n","\n","- Epochs: 35\n","- MSE:    0.494608682757\n","- MAE:    0.546375501156\n","- R2:     0.351316947111\n","\n","   \n","- Epochs: 40\n","- MSE:    0.487310701158\n","- MAE:    0.543989002705\n","- R2:     0.360886879304\n","\n","\n","- Epochs: 45\n","- MSE:    0.488181700038\n","- MAE:    0.541019487381\n","- R2:     0.35970041305\n","---\n","Conclusiones:\n","- Con una capa solo podemos modelar un hiperplano lineal, pero puede ser lo suficientenemente bueno para que la ausencia de flexibilidad en la funci√≥n generalice el modelo de mejor manera.\n","- El aumento del n√∫mero de unidades para una arquitectura que ya de por s√≠ tiene el potencial necesario para los datos complica el ajuste correcto de la red.\n","\n","---\n","IMPORTANTE: Recordad que hay que tener en cuenta que las redes tengan el menor n√∫mero de neuronas, por varios motivos, ¬øCu√°les son estos motivos?, ¬øCu√°ndo se considera que una red sobrepasa el tama√±o adecuado y deja de ser conveniente?\n","\n","---\n","El aumento en el espacio de b√∫squeda puede ser innecesario para el problema en cuesti√≥n. Un aumento de capas/unidades facilita al sobreaprendizaje y ralentiza el aprendizaje, adem√°s de acarrear mayores requisitos de memoria.\n","\n","Adicionalmente, muchas neuronas no permiten codificar nueva informaci√≥n sobre el problema, despu√©s de todo es m√°s importante la obtenci√≥n de un buen conjunto de datos."]},{"cell_type":"code","metadata":{"id":"BxOVF-SqVpK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616172728385,"user_tz":-60,"elapsed":107453,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"39111ab1-2b88-4706-96b0-82fbe7234db5"},"source":["from keras.optimizers import RMSprop, SGD\n","\n","seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 130\n","lr = 1e-3\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","# opt = RMSprop(lr=lr)\n","opt = SGD(lr=lr)\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(128, input_dim=12, activation='relu'),\n","        # Dense(128, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"LR:     {}\".format(lr))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 130\n","LR:     0.001\n","MSE:    0.480065194343\n","MAE:    0.538011682034\n","R2:     0.370371911403\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bmEqa7NTVpmj"},"source":["Podemos probar la importaci√≥n de RMSprop desde keras.models y ajustar la tasa de aprendizaje lr. Tambi√©n puede cambiar los valores predeterminados que se han establecido para los otros par√°metros RMSprop(), pero esto no es muy recomendable\n","\n","\n","Realiza los cambios que comentamos y, adem√°s, prueba experimentar con otros algoritmos de optimizaci√≥n, como el Descenso de gradiente estoc√°stico (SGD). ¬øQu√© efecto notas? Vuelve a recoger tus resultados en una tabla junto con los par√°metros utilizados y m√©tricas. Comenta resultados y saca conclusiones.\n","\n","---\n","RMSProp (el usado en las pruebas anteriores era de 0.001\n","\n","- Epochs: 45\n","- LR:     0.0001\n","- MSE:    0.53940390152\n","- MAE:    0.565697920322\n","- R2:     0.292503154678\n","\n","\n","- Epochs: 60\n","- LR:     0.0001\n","- MSE:    0.504027555261\n","- MAE:    0.54831776619\n","- R2:     0.338940050841\n","\n","\n","- Epochs: 80\n","- LR:     0.0001\n","- MSE:    0.488306410117\n","- MAE:    0.541552388668\n","- R2:     0.359566412447\n","\n","\n","- Epochs: 80\n","- LR:     0.0005\n","- MSE:    0.472229035967\n","- MAE:    0.534961915016\n","- R2:     0.380658607712\n","\n","\n","- Epochs: 90\n","- LR:     0.0005\n","- MSE:    0.465053232917\n","- MAE:    0.528471159935\n","- R2:     0.390073414644\n","\n","\n","- Epochs: 100\n","- LR:     0.0005\n","- MSE:    0.467848615046\n","- MAE:    0.532627475262\n","- R2:     0.386410437293\n","---\n","SGD\n","\n","- Epochs: 90\n","- LR:     0.0005\n","- MSE:    0.51598752198\n","- MAE:    0.557888400555\n","- R2:     0.323246607266\n","\n","\n","- Epochs: 70\n","- LR:     0.0005\n","- MSE:    0.549419874518\n","- MAE:    0.572193920612\n","- R2:     0.279420770722\n","\n","\n","- Epochs: 30\n","- LR:     0.001\n","- MSE:    0.575189663905\n","- MAE:    0.58444185257\n","- R2:     0.245607175414\n","\n","\n","- Epochs: 60\n","- LR:     0.001\n","- MSE:    0.503936645285\n","- MAE:    0.551231098175\n","- R2:     0.3390477713\n","\n","\n","- Epochs: 90\n","- LR:     0.001\n","- MSE:    0.488905689559\n","- MAE:    0.542665660381\n","- R2:     0.358766784739\n","\n","\n","- Epochs: 110\n","- LR:     0.001\n","- MSE:    0.479930756138\n","- MAE:    0.538722836971\n","- R2:     0.370559130682\n","\n","\n","- Epochs: 130\n","- LR:     0.001\n","- MSE:    0.480065194343\n","- MAE:    0.538011682034\n","- R2:     0.370371911403\n","---\n","Conclusiones:\n","- SGD es m√°s dif√≠cil de ajustar que RMSprop por tener un learning rate constante en toda la ejecuci√≥n.\n","- Siempre se puede probar con un learning rate bajo, pues ser√° m√°s f√°cil converger d√°ndole m√°s √©pocas, pero a costa de eso existe m√°s probabilidad de caer en un m√≠nimo local de peor calidad."]},{"cell_type":"markdown","metadata":{"id":"WWeh7kRbVvgd"},"source":["Finalmente, De todas las que has probado, ¬øCu√°l ser√≠a para ti la mejor configuraci√≥n del modelo que se adapta al problema? ¬øPor qu√©? Escoger otro problema de regresi√≥n y explorar el dise√±o que mejor se adapte al problema\n","\n","---\n","\n","El mejor ha sido RMSprop con 1 capa y 128 unidades. Creemos que obtiene estos resultados porque aunque sea un perceptr√≥n simple de una sola capa, la gran cantidad de unidades le otorga la potencia suficiente para el problema. Prevalece RMSprop sobre SGD por resultar m√°s sencillo de ajustar apropiadamente gracias al momentum, de forma que la funci√≥n de p√©rdida converja poco a poco con mayor facilidad a un m√≠nimo local.\n","\n","Viendo la baja diferencia en resultados, es probablemente que con una optimizaci√≥n de √©pocas con EarlyStopping muchos de los otros resultados sean capaces de obtener calidades similares."]}]}