{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.16"},"colab":{"name":"guionII.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"xL2GY7b7KHKF"},"source":["Ignacio Vellido Expósito"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdCV-g8BMIkO","executionInfo":{"status":"ok","timestamp":1616169788089,"user_tz":-60,"elapsed":27393,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"6b09d8d9-bd42-42f6-9152-90d23f23b50d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3_DvmXUKFOy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169747677,"user_tz":-60,"elapsed":4122,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"7b060132-1b2d-427e-c375-47d1694ac6b6"},"source":["################################################################################\n","# Libraries\n","################################################################################\n","\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Import layers\n","from keras import Sequential\n","from keras.layers import Dense\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Import the metrics from `sklearn.metrics`\n","from sklearn.metrics import r2_score\n","\n","################################################################################\n","\n","# Basic libraries\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"SyvdW1W6J5fx","executionInfo":{"status":"ok","timestamp":1616169814282,"user_tz":-60,"elapsed":2629,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"02b49de6-a954-4b74-adf1-9a88f5136b6c"},"source":["################################################################################\n","# Load data\n","################################################################################\n","\n","# Read in white wine data \n","white = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsc/winequality-white.csv', sep=';')\n","\n","# Read in red wine data \n","red = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tsc/winequality-red.csv', sep=';')\n","\n","# Add `type` column to `red` with value 1\n","red['type'] = 1\n","\n","# Add `type` column to `white` with value 0\n","white['type'] = 0\n","\n","# Append `white` to `red`\n","wines = red.append(white, ignore_index=True)\n","\n","wines.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n","0            7.4              0.70         0.00             1.9      0.076   \n","1            7.8              0.88         0.00             2.6      0.098   \n","2            7.8              0.76         0.04             2.3      0.092   \n","3           11.2              0.28         0.56             1.9      0.075   \n","4            7.4              0.70         0.00             1.9      0.076   \n","\n","   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n","0                 11.0                  34.0   0.9978  3.51       0.56   \n","1                 25.0                  67.0   0.9968  3.20       0.68   \n","2                 15.0                  54.0   0.9970  3.26       0.65   \n","3                 17.0                  60.0   0.9980  3.16       0.58   \n","4                 11.0                  34.0   0.9978  3.51       0.56   \n","\n","   alcohol  quality  type  \n","0      9.4        5     1  \n","1      9.8        5     1  \n","2      9.8        5     1  \n","3      9.8        6     1  \n","4      9.4        5     1  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"14tWI3RtJ5gC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616169836723,"user_tz":-60,"elapsed":722,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"9a842f74-aa3f-4503-ea36-99828d10c6cb"},"source":["################################################################################\n","# Train-test split\n","################################################################################\n","\n","# Specify the data\n","X = wines.iloc[:,0:12]\n","X = wines.drop('quality', axis=1) \n","\n","# Isolate target labels\n","#Y = wines.quality\n","Y = np.ravel(wines.quality)\n","\n","################################################################################\n","# Preprocessing data\n","################################################################################\n","\n","# Scale\n","X_train = StandardScaler().fit_transform(X)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n","  return self.partial_fit(X, y)\n","/usr/local/lib/python2.7/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n","  return self.fit(X, **fit_params).transform(X)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5n8uUr_J5gG","executionInfo":{"status":"ok","timestamp":1616154368188,"user_tz":-60,"elapsed":47335,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"61876d9b-d537-4af5-af9e-612c1c61b4ab"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 60\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(64, input_dim=12, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 60\n","MSE:    0.482037309573\n","MAE:    0.538521635532\n","R2:     0.367790048708\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TDrO2ouAM9ro"},"source":["Recoged los resultados anteriores en una tabla donde se indiquen los parámetros, resultados y métricas estudiados hasta el momento. Realizar estas ejecuciones para un número mayor de iteraciones del algoritmo (por ejemplo 20, 30, 40, 50…) ver qué ocurre. Comentar conclusiones\n","\n","---\n","- Epochs: 10\n","- MSE:    0.524755685232\n","- MAE:    0.560977721214\n","- R2:     0.311729921596\n","---\n","- Epochs: 20\n","- MSE:    0.493214635154\n","- MAE:    0.543776381016\n","- R2:     0.353146244269\n","---\n","- Epochs: 30\n","- MSE:    0.478757350902\n","- MAE:    0.535899412632\n","- R2:     0.37209407945\n","---\n","- Epochs: 40\n","- MSE:    0.486252702039\n","- MAE:    0.543345427513\n","- R2:     0.362256719249\n","---\n","- Epochs: 50\n","- MSE:    0.479456772399\n","- MAE:    0.538513040543\n","- R2:     0.371175519533\n","---\n","- Epochs: 60\n","- MSE:    0.482037309573\n","- MAE:    0.538521635532\n","- R2:     0.367790048708\n","\n","---\n","\n","Conclusiones:\n","- Tenemos que fijarnos en las milésimas para observar diferencias.\n","Vemos que a partir de las 30 épocas comienza el sobreaprendizaje, a partir de ahí el error comienza a fluctuar.\n","\n","- Respecto a la calidad en sí de los resultados, los valores de MAE nos indican que el margen de error es pequeño (equivocación de medio punto arriba/abajo en la nota otorgada). \n","- A pesar de esto, los valores de R2 se ven bajos, aunque los resultados con clasificación del guiónI nos demonstraron que el problema es difícil de resolver (un tanto menor para regresión, puesto que la ausencia de datos de otras clases no penaliza de la misma forma)\n"]},{"cell_type":"code","metadata":{"id":"gpr6MeGzVdOd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616170663213,"user_tz":-60,"elapsed":12133,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"07d5e969-cb57-4952-d184-4ba761c30d9e"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 10\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(64, input_dim=12, activation='relu'),\n","        Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 10\n","MSE:    0.551292880071\n","MAE:    0.578412055969\n","R2:     0.277023550101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z4wg1mHfVdmg"},"source":["a) Agregar más capas. Probemos a añadir más capas. Realizar la ejecución con diferentes números de capas y construir una tabla con los resultados. Mantened por el momento el mismo número de neuronas, ya que veremos el resultado de cambiar el número de las neuronas posteriormente. Construir una tabla con los parámetros y métricas utilizadas. Comentad los resultados y sacar conclusiones\n","\n","---\n","2 capas\n","\n","- Epochs: 10\n","- MSE:    0.551292880071\n","- MAE:    0.578412055969\n","- R2:     0.277023550101\n","\n","   \n","\n","- Epochs: 30\n","- MSE:    0.484528051438\n","- MAE:    0.539175724983\n","- R2:     0.36452036291\n","\n","   \n","\n","- Epochs: 50\n","- MSE:    0.505928785927\n","- MAE:    0.553491330147\n","- R2:     0.336542270749\n","\n","    \n","\n","- Epochs: 70\n","- MSE:    0.54414904517\n","- MAE:    0.564422738552\n","- R2:     0.286345643744\n","\n","---\n","3 capas\n","\n","- Epochs: 10\n","- MSE:    0.527808886028\n","- MAE:    0.563948392868\n","- R2:     0.307706186006\n","\n","    \n","\n","- Epochs: 30\n","- MSE:    0.517176227956\n","- MAE:    0.558221280575\n","- R2:     0.321760622194\n","\n","   \n","\n","- Epochs: 50\n","- MSE:    0.499126830202\n","- MAE:    0.540626513958\n","- R2:     0.345356619835\n","\n","---\n","4 capas\n","\n","- Epochs: 10\n","- MSE:    0.528152155888\n","- MAE:    0.56595979929\n","- R2:     0.307404602014\n","\n","   \n","\n","- Epochs: 30\n","- MSE:    0.548689993182\n","- MAE:    0.570972287655\n","- R2:     0.280310372135\n","\n","   \n","- Epochs: 50\n","- MSE:    0.512767980628\n","- MAE:    0.546047878265\n","- R2:     0.327576749344\n","\n","   \n","- Epochs: 60\n","- MSE:    0.55087068926\n","- MAE:    0.563467502594\n","- R2:     0.277443898965\n","---\n","\n","Conclusiones:\n","- El entrenamiento correcto depende totalmente de la arquitectura.\n","- Modelos con más capas/unidades tienen a sobreajustar más fácilmente."]},{"cell_type":"code","metadata":{"id":"qzzh-TRUVg6w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616171262049,"user_tz":-60,"elapsed":40048,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"13a5cf60-af92-4be0-96d3-0ddddbe57d1e"},"source":["seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 45\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(32, input_dim=12, activation='relu'),\n","        # Dense(128, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 45\n","MSE:    0.488181700038\n","MAE:    0.541019487381\n","R2:     0.35970041305\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mYtJl_ruVhUk"},"source":["Agregar más unidades ocultas. Partiendo de la configuración de una única capa y posteriormente de varias capas, probad con diferente número de neuronas. Construir una tabla que recoja tanto los parámetros utilizados, como las métricas y resultados. Comentad los resultados y sacar conclusiones.\n","\n","---\n","1 capa, 128 unidades\n","\n","- Epochs: 30\n","- MSE:    0.476496205197\n","- MAE:    0.533239984512\n","- R2:     0.375050078186\n","\n","\n","- Epochs: 40\n","- MSE:    0.481751763494\n","- MAE:    0.541328597069\n","- R2:     0.368188363539\n","\n","---\n","2 capas, 128-64 unidades\n","\n","- Epochs: 30\n","- MSE:    0.505831441966\n","- MAE:    0.549794638157\n","- R2:     0.336568751678\n","    \n","\n","- Epochs: 40\n","- MSE:    0.496979997832\n","- MAE:    0.551348042488\n","- R2:     0.348121680966\n","\n","---\n","2 capas, 128-128 unidades\n","\n","- Epochs: 30\n","- MSE:    0.49993821629\n","- MAE:    0.545240473747\n","- R2:     0.344293806024\n","\n","   \n","- Epochs: 40\n","- MSE:    0.495013412726\n","- MAE:    0.545667314529\n","- R2:     0.350746151389\n","\n","---\n","1 capa, 32 unidades\n","\n","- Epochs: 35\n","- MSE:    0.494608682757\n","- MAE:    0.546375501156\n","- R2:     0.351316947111\n","\n","   \n","- Epochs: 40\n","- MSE:    0.487310701158\n","- MAE:    0.543989002705\n","- R2:     0.360886879304\n","\n","\n","- Epochs: 45\n","- MSE:    0.488181700038\n","- MAE:    0.541019487381\n","- R2:     0.35970041305\n","---\n","Conclusiones:\n","- Con una capa solo podemos modelar un hiperplano lineal, pero puede ser lo suficientenemente bueno para que la ausencia de flexibilidad en la función generalice el modelo de mejor manera.\n","- El aumento del número de unidades para una arquitectura que ya de por sí tiene el potencial necesario para los datos complica el ajuste correcto de la red.\n","\n","---\n","IMPORTANTE: Recordad que hay que tener en cuenta que las redes tengan el menor número de neuronas, por varios motivos, ¿Cuáles son estos motivos?, ¿Cuándo se considera que una red sobrepasa el tamaño adecuado y deja de ser conveniente?\n","\n","---\n","El aumento en el espacio de búsqueda puede ser innecesario para el problema en cuestión. Un aumento de capas/unidades facilita al sobreaprendizaje y ralentiza el aprendizaje, además de acarrear mayores requisitos de memoria.\n","\n","Adicionalmente, muchas neuronas no permiten codificar nueva información sobre el problema, después de todo es más importante la obtención de un buen conjunto de datos."]},{"cell_type":"code","metadata":{"id":"BxOVF-SqVpK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616172728385,"user_tz":-60,"elapsed":107453,"user":{"displayName":"IGNACIO VELLIDO EXPOSITO","photoUrl":"","userId":"13106151031220761981"}},"outputId":"39111ab1-2b88-4706-96b0-82fbe7234db5"},"source":["from keras.optimizers import RMSprop, SGD\n","\n","seed = 7\n","np.random.seed(seed)\n","\n","# Parameters\n","splits = 5\n","epochs = 130\n","lr = 1e-3\n","\n","kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n","\n","mse = []\n","mae = []\n","r2 = []\n","\n","# opt = RMSprop(lr=lr)\n","opt = SGD(lr=lr)\n","\n","for train, test in kfold.split(X, Y):\n","  # Define model\n","  model = Sequential(\n","      [\n","        Dense(128, input_dim=12, activation='relu'),\n","        # Dense(128, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        # Dense(64, activation='relu'),\n","        Dense(1)         \n","      ]\n","  )\n","\n","  model.compile(optimizer=opt, loss='mse', metrics=['mae'])\n","  model.fit(X_train[train], Y[train], epochs=epochs,verbose=0)\n","\n","\n","  mse_value, mae_value = model.evaluate(X_train[test], Y[test], verbose=0)\n","  mse.append(mse_value)\n","  mae.append(mae_value)\n","\n","  y_pred = model.predict(X_train[test])\n","  r2score = r2_score(Y[test],y_pred)\n","  r2.append(r2score)\n","\n","# Average of results in each K-fold\n","mse_value = np.mean(mse)\n","mae_value = np.mean(mae)\n","r2score   = np.mean(r2)\n","\n","print(\"Epochs: {}\".format(epochs))\n","print(\"LR:     {}\".format(lr))\n","print(\"MSE:    {}\".format(mse_value))\n","print(\"MAE:    {}\".format(mae_value))\n","print(\"R2:     {}\".format(r2score))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 130\n","LR:     0.001\n","MSE:    0.480065194343\n","MAE:    0.538011682034\n","R2:     0.370371911403\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bmEqa7NTVpmj"},"source":["Podemos probar la importación de RMSprop desde keras.models y ajustar la tasa de aprendizaje lr. También puede cambiar los valores predeterminados que se han establecido para los otros parámetros RMSprop(), pero esto no es muy recomendable\n","\n","\n","Realiza los cambios que comentamos y, además, prueba experimentar con otros algoritmos de optimización, como el Descenso de gradiente estocástico (SGD). ¿Qué efecto notas? Vuelve a recoger tus resultados en una tabla junto con los parámetros utilizados y métricas. Comenta resultados y saca conclusiones.\n","\n","---\n","RMSProp (el usado en las pruebas anteriores era de 0.001\n","\n","- Epochs: 45\n","- LR:     0.0001\n","- MSE:    0.53940390152\n","- MAE:    0.565697920322\n","- R2:     0.292503154678\n","\n","\n","- Epochs: 60\n","- LR:     0.0001\n","- MSE:    0.504027555261\n","- MAE:    0.54831776619\n","- R2:     0.338940050841\n","\n","\n","- Epochs: 80\n","- LR:     0.0001\n","- MSE:    0.488306410117\n","- MAE:    0.541552388668\n","- R2:     0.359566412447\n","\n","\n","- Epochs: 80\n","- LR:     0.0005\n","- MSE:    0.472229035967\n","- MAE:    0.534961915016\n","- R2:     0.380658607712\n","\n","\n","- Epochs: 90\n","- LR:     0.0005\n","- MSE:    0.465053232917\n","- MAE:    0.528471159935\n","- R2:     0.390073414644\n","\n","\n","- Epochs: 100\n","- LR:     0.0005\n","- MSE:    0.467848615046\n","- MAE:    0.532627475262\n","- R2:     0.386410437293\n","---\n","SGD\n","\n","- Epochs: 90\n","- LR:     0.0005\n","- MSE:    0.51598752198\n","- MAE:    0.557888400555\n","- R2:     0.323246607266\n","\n","\n","- Epochs: 70\n","- LR:     0.0005\n","- MSE:    0.549419874518\n","- MAE:    0.572193920612\n","- R2:     0.279420770722\n","\n","\n","- Epochs: 30\n","- LR:     0.001\n","- MSE:    0.575189663905\n","- MAE:    0.58444185257\n","- R2:     0.245607175414\n","\n","\n","- Epochs: 60\n","- LR:     0.001\n","- MSE:    0.503936645285\n","- MAE:    0.551231098175\n","- R2:     0.3390477713\n","\n","\n","- Epochs: 90\n","- LR:     0.001\n","- MSE:    0.488905689559\n","- MAE:    0.542665660381\n","- R2:     0.358766784739\n","\n","\n","- Epochs: 110\n","- LR:     0.001\n","- MSE:    0.479930756138\n","- MAE:    0.538722836971\n","- R2:     0.370559130682\n","\n","\n","- Epochs: 130\n","- LR:     0.001\n","- MSE:    0.480065194343\n","- MAE:    0.538011682034\n","- R2:     0.370371911403\n","---\n","Conclusiones:\n","- SGD es más difícil de ajustar que RMSprop por tener un learning rate constante en toda la ejecución.\n","- Siempre se puede probar con un learning rate bajo, pues será más fácil converger dándole más épocas, pero a costa de eso existe más probabilidad de caer en un mínimo local de peor calidad."]},{"cell_type":"markdown","metadata":{"id":"WWeh7kRbVvgd"},"source":["Finalmente, De todas las que has probado, ¿Cuál sería para ti la mejor configuración del modelo que se adapta al problema? ¿Por qué? Escoger otro problema de regresión y explorar el diseño que mejor se adapte al problema\n","\n","---\n","\n","El mejor ha sido RMSprop con 1 capa y 128 unidades. Creemos que obtiene estos resultados porque aunque sea un perceptrón simple de una sola capa, la gran cantidad de unidades le otorga la potencia suficiente para el problema. Prevalece RMSprop sobre SGD por resultar más sencillo de ajustar apropiadamente gracias al momentum, de forma que la función de pérdida converja poco a poco con mayor facilidad a un mínimo local.\n","\n","Viendo la baja diferencia en resultados, es probablemente que con una optimización de épocas con EarlyStopping muchos de los otros resultados sean capaces de obtener calidades similares."]}]}